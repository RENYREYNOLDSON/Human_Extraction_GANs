{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWahx1jsKJyK"
      },
      "source": [
        "## 1. Human Feature Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsGdQBcETB4g",
        "outputId": "ecf146fb-06fb-496b-aed0-6eecc743044f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Setup\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from IPython import display\n",
        "from torchvision.transforms import transforms\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import csv\n",
        "drive.mount(\"/content/drive\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV8CunPyKTfD"
      },
      "source": [
        "### 1.1 Human Patch Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtDZ8T21GLU9",
        "outputId": "e52bafd3-aac3-4540-a9b5-205e8d988f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
            "100%|██████████| 170M/170M [00:02<00:00, 86.4MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MaskRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
              "    )\n",
              "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (mask_head): MaskRCNNHeads(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (mask_predictor): MaskRCNNPredictor(\n",
              "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The 91 COCO class names\n",
        "coco_names = ['__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
        "\n",
        "\n",
        "# Generate a set of color for drawing different classes\n",
        "COLORS = np.random.uniform(0, 255, size=(len(coco_names), 3))\n",
        "\n",
        "# Transform to convert the image to tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Initialize the model and set it to the evaluation mode\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True, progress=True, num_classes=91)\n",
        "model.to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgJjUhtEKsMR",
        "outputId": "37c18671-49de-473a-982b-a70f82dff039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/12945 Completed\n",
            "Current total yield: 0 images\n",
            "1000/12945 Completed\n",
            "Current total yield: 173 images\n",
            "2000/12945 Completed\n",
            "Current total yield: 291 images\n",
            "3000/12945 Completed\n",
            "Current total yield: 500 images\n",
            "4000/12945 Completed\n",
            "Current total yield: 678 images\n",
            "5000/12945 Completed\n",
            "Current total yield: 911 images\n",
            "6000/12945 Completed\n",
            "Current total yield: 1088 images\n",
            "7000/12945 Completed\n",
            "Current total yield: 1339 images\n",
            "8000/12945 Completed\n",
            "Current total yield: 1552 images\n",
            "9000/12945 Completed\n",
            "Current total yield: 1775 images\n",
            "10000/12945 Completed\n",
            "Current total yield: 1940 images\n",
            "11000/12945 Completed\n",
            "Current total yield: 2254 images\n",
            "12000/12945 Completed\n",
            "Current total yield: 2567 images\n",
            "0/51714 Completed\n",
            "Current total yield: 2 images\n",
            "1000/51714 Completed\n",
            "Current total yield: 170 images\n",
            "2000/51714 Completed\n",
            "Current total yield: 376 images\n",
            "3000/51714 Completed\n",
            "Current total yield: 600 images\n",
            "4000/51714 Completed\n",
            "Current total yield: 727 images\n",
            "5000/51714 Completed\n",
            "Current total yield: 897 images\n",
            "6000/51714 Completed\n",
            "Current total yield: 1136 images\n",
            "7000/51714 Completed\n",
            "Current total yield: 1388 images\n",
            "8000/51714 Completed\n",
            "Current total yield: 1538 images\n",
            "9000/51714 Completed\n",
            "Current total yield: 1766 images\n",
            "10000/51714 Completed\n",
            "Current total yield: 2046 images\n",
            "11000/51714 Completed\n",
            "Current total yield: 2261 images\n",
            "12000/51714 Completed\n",
            "Current total yield: 2417 images\n",
            "13000/51714 Completed\n",
            "Current total yield: 2650 images\n",
            "14000/51714 Completed\n",
            "Current total yield: 2877 images\n",
            "15000/51714 Completed\n",
            "Current total yield: 3052 images\n",
            "16000/51714 Completed\n",
            "Current total yield: 3241 images\n",
            "17000/51714 Completed\n",
            "Current total yield: 3471 images\n",
            "18000/51714 Completed\n",
            "Current total yield: 3670 images\n",
            "19000/51714 Completed\n",
            "Current total yield: 3845 images\n",
            "20000/51714 Completed\n",
            "Current total yield: 4115 images\n",
            "21000/51714 Completed\n",
            "Current total yield: 4334 images\n",
            "22000/51714 Completed\n",
            "Current total yield: 4545 images\n",
            "23000/51714 Completed\n",
            "Current total yield: 4685 images\n",
            "24000/51714 Completed\n",
            "Current total yield: 4960 images\n",
            "25000/51714 Completed\n",
            "Current total yield: 5201 images\n",
            "26000/51714 Completed\n",
            "Current total yield: 5406 images\n",
            "27000/51714 Completed\n",
            "Current total yield: 5567 images\n",
            "28000/51714 Completed\n",
            "Current total yield: 5718 images\n",
            "29000/51714 Completed\n",
            "Current total yield: 5769 images\n",
            "30000/51714 Completed\n",
            "Current total yield: 5821 images\n",
            "31000/51714 Completed\n",
            "Current total yield: 6075 images\n",
            "32000/51714 Completed\n",
            "Current total yield: 6254 images\n",
            "33000/51714 Completed\n",
            "Current total yield: 6485 images\n",
            "34000/51714 Completed\n",
            "Current total yield: 6588 images\n",
            "35000/51714 Completed\n",
            "Current total yield: 6715 images\n",
            "36000/51714 Completed\n",
            "Current total yield: 6903 images\n",
            "37000/51714 Completed\n",
            "Current total yield: 7100 images\n",
            "38000/51714 Completed\n",
            "Current total yield: 7231 images\n",
            "39000/51714 Completed\n",
            "Current total yield: 7478 images\n",
            "40000/51714 Completed\n",
            "Current total yield: 7701 images\n",
            "41000/51714 Completed\n",
            "Current total yield: 7863 images\n",
            "42000/51714 Completed\n",
            "Current total yield: 8091 images\n",
            "43000/51714 Completed\n",
            "Current total yield: 8347 images\n",
            "44000/51714 Completed\n",
            "Current total yield: 8497 images\n",
            "45000/51714 Completed\n",
            "Current total yield: 8607 images\n",
            "46000/51714 Completed\n",
            "Current total yield: 8775 images\n",
            "47000/51714 Completed\n",
            "Current total yield: 8864 images\n",
            "48000/51714 Completed\n",
            "Current total yield: 9048 images\n"
          ]
        }
      ],
      "source": [
        "#IDEAS\n",
        "# Firstly, only sample every 60 frames, as wont change too much frame to frame. Then only take frames near a human\n",
        "# Then we will use torch vision to do better detection on these\n",
        "# Use THREADING, especially around these patches!\n",
        "# Save all human patches into a file\n",
        "\n",
        "#RESTART WITH MORE ADVANCED LIBRARIES!\n",
        "\n",
        "# EXTRACTED PATCHES MUST BE SQUARE, CAN BE ANY SIZE. Scale after? 50x50px\n",
        "# Using PyTorch RCNN\n",
        "#Masked-RCNN with COCO\n",
        "\"\"\"\n",
        "def detect_humans(frame):\n",
        "      #Detect humans in the Images\n",
        "      # resizing for faster detection\n",
        "      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "      # Detect humans in the image\n",
        "      humans = human_cascade.detectMultiScale(frame, 1.08, minNeighbors=0 ,minSize=(200,200))\n",
        "      faces = face_cascade.detectMultiScale(gray, 1.10, minNeighbors = 8,minSize=(200,200))\n",
        "\n",
        "      #Return Image Patches in [(x,y,w,h),(x,y,w,h)]\n",
        "      return humans,faces\n",
        "\"\"\"\n",
        "\n",
        "def to_patch(x,y,w,h,max_w,max_h):\n",
        "    #Calculate the side length of the square patch\n",
        "    side_length = max(w, h)\n",
        "    new_x = x + (w - side_length) // 2\n",
        "    new_y = y + (h - side_length) // 2\n",
        "\n",
        "    #Ensure that the new patch fits within the image bounds\n",
        "    new_x = max(0, min(new_x, max_w - side_length))\n",
        "    new_y = max(0, min(new_y, max_h - side_length))\n",
        "\n",
        "    return [new_x, new_y, side_length, side_length]\n",
        "\n",
        "\n",
        "def detect_humans2(in_frame):\n",
        "  # Analyze the image\n",
        "  in_frame_processing = cv2.cvtColor(in_frame, cv2.COLOR_BGR2RGB) # Convert from CV2's BGR to RGB\n",
        "  in_frame_processing = transform(in_frame_processing) # Convert the image to tensor\n",
        "  in_frame_processing = in_frame_processing.unsqueeze(0).to(device) # add a batch dimension\n",
        "  with torch.no_grad():\n",
        "      outputs = model(in_frame_processing)\n",
        "\n",
        "  score_thresh = 0.99\n",
        "  if current_file==\"game/MafiaVideogame.mp4\":\n",
        "    score_thresh=0.98\n",
        "\n",
        "  # Get individual types of output from the outputs variable\n",
        "  scores = list(outputs[0]['scores'].detach().cpu().numpy()) # Get scores\n",
        "  #print(scores) # The scores are sorted from largest to the shortest\n",
        "  thresholded_objects = [scores.index(i) for i in scores if i > 0.99] # Get an index for the objects having the scores > a threshold of 0.965\n",
        "  thresholded_objects_count = len(thresholded_objects) # Total objects having scores > threshold\n",
        "  masks = (outputs[0]['masks']>0.5).squeeze().detach().cpu().numpy() # Get the segmentation masks\n",
        "  masks = masks[:thresholded_objects_count] # Discard masks for objects that are below threshold by only taking the beginning of the list\n",
        "  boxes = [[(i[0], i[1]), (i[2], i[3])]  for i in outputs[0]['boxes'].detach().cpu()] # Get the bounding boxes, in (x1, y1), (x2, y2) format\n",
        "  boxes = boxes[:thresholded_objects_count] # Discard bounding boxes for objects that are below threshold by only taking the beginning of the list\n",
        "  labels = [coco_names[i] for i in outputs[0]['labels']] # Get the classes labels\n",
        "\n",
        "  # Print all the detected objects\n",
        "  humans=[]\n",
        "  for i in range(0, len(outputs[0]['scores'])):\n",
        "    if coco_names[outputs[0][\"labels\"][i]]==\"person\":\n",
        "      x = int(outputs[0]['boxes'][i][0])\n",
        "      y = int(outputs[0]['boxes'][i][1])\n",
        "      w = int(outputs[0]['boxes'][i][2])-x\n",
        "      h = int(outputs[0]['boxes'][i][3])-y\n",
        "      #print(coco_names[outputs[0]['labels'][i]], \":\", float(outputs[0]['scores'][i]), \"(\", int(outputs[0]['boxes'][i][0]), int(outputs[0]['boxes'][i][1]), int(outputs[0]['boxes'][i][2]), int(outputs[0]['boxes'][i][3]) ,\")\")\n",
        "      if w>200 and h>200:\n",
        "        #SET A MINIMUM IMAGE SIZE\n",
        "        #humans.append([x,y,w,h])\n",
        "        #Try turning into square\n",
        "        humans.append(to_patch(x,y,w,h,len(in_frame),len(in_frame[0])))\n",
        "  #Get Human Patches here\n",
        "\n",
        "\n",
        "\n",
        "  return humans\n",
        "\n",
        "def save_detected(frame,humans):\n",
        "      global total_yield\n",
        "      #Get rectangles around the detected humans\n",
        "      for (x, y, w, h) in humans:\n",
        "          save_img = frame[y:y+h,x:x+w]\n",
        "          resized_img = cv2.resize(save_img, (500, 500))\n",
        "          cv2.imwrite(\"/content/drive/MyDrive/PATCHES/\"+str(current_file)[:-4]+\"%d.jpg\" % int(total_yield), resized_img)\n",
        "          total_yield+=1\n",
        "\n",
        "files = [\"movie/TheGodfather.mp4\",\n",
        "         \"movie/TheSopranos.mp4\"]\n",
        "\n",
        "for current_file in files:\n",
        "  #Open Test File\n",
        "  test1 = cv2.VideoCapture(\"/content/drive/MyDrive/Data/Train/\"+str(current_file))\n",
        "  frame_count = int(test1.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  # Used as counter variable\n",
        "  count = 0\n",
        "  # checks whether frames were extracted\n",
        "  success = 1\n",
        "\n",
        "\n",
        "  prevs=[]\n",
        "  total_yield = 0\n",
        "  #Iterate Over every frame and save the ones with high chance of people in\n",
        "  while success:\n",
        "      # vidObj object calls read\n",
        "      # function extract frames\n",
        "      success, frame = test1.read()\n",
        "      #prevs.append(frame)\n",
        "      if count%24==0:# Do for every second in the video\n",
        "        humans = detect_humans2(frame)\n",
        "        save_detected(frame,humans)\n",
        "\n",
        "        #If some humans have been detected at that second then:\n",
        "        \"\"\"\n",
        "        if len(humans)>0:\n",
        "          for f in [6,12,15,18,21]:#Also do for 5 frames in between\n",
        "            frame = prevs[f]\n",
        "            humans = detect_humans2(frame)\n",
        "            save_detected(frame,humans)\n",
        "        prevs=[]\n",
        "        \"\"\"\n",
        "\n",
        "      if count%1000==0:\n",
        "        print(str(count)+\"/\"+str(frame_count)+\" Completed\")\n",
        "        print(\"Current total yield: \"+str(total_yield)+\" images\")\n",
        "      count += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyL7-qXnDpYZ"
      },
      "outputs": [],
      "source": [
        "#SHOW 50 RANDOM IMAGE PATCHES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU2SThC1KVfg"
      },
      "source": [
        "### 1.2 Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFYEXFZaKsjh",
        "outputId": "361db307-3072-4e59-ab37-8f853d5c83a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=KeypointRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=KeypointRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "KeypointRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(640, 672, 704, 736, 768, 800), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "    (keypoint_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (keypoint_head): KeypointRCNNHeads(\n",
              "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): ReLU(inplace=True)\n",
              "      (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (9): ReLU(inplace=True)\n",
              "      (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "    )\n",
              "    (keypoint_predictor): KeypointRCNNPredictor(\n",
              "      (kps_score_lowres): ConvTranspose2d(512, 17, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#CLASSIFY the images into categories, get confidence scores and classify!\n",
        "\n",
        "#Human feature segmentation\n",
        "#Decide which features belong to which class\n",
        "\n",
        "#1. FULL-BODY FRONT VIEW\n",
        "#2. FULL-BODY BACK VIEW\n",
        "#3. HEAD-AND-SHOULDER FRONT VIEW\n",
        "#4. HEAD-AND-SHOULDER BACK VIEW\n",
        "coco_keypoints = [\n",
        "    \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\",\n",
        "    \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n",
        "    \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\",\n",
        "    \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\",\n",
        "]\n",
        "#IF IMAGE CONTAINS HIGH CONFIDENCE ON THE HIPS,KNEES or ANKLES THEN FULL BODY\n",
        "#IF IMAGE CONTAINS FACE INFORMATION THEN FRONT VIEW\n",
        "\n",
        "# Initialize the model and set it to the evaluation mode\n",
        "weights = torchvision.models.detection.KeypointRCNN_ResNet50_FPN_Weights.DEFAULT\n",
        "transforms = weights.transforms()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=weights, progress=True)\n",
        "model.to(device).eval()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6V5T8dHkWpqV",
        "outputId": "a24764bc-c333-4208-86e2-35f9987e54e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33246\n",
            "ETA: 0 minutes   0.0%   0/33246 TOTALS: [0, 0, 0, 0]\n",
            "ETA: 21 minutes   0.06015761294591831%   20/33246 TOTALS: [1, 12, 0, 0]\n",
            "ETA: 20 minutes   0.12031522589183662%   40/33246 TOTALS: [1, 23, 0, 0]\n",
            "ETA: 20 minutes   0.18047283883775492%   60/33246 TOTALS: [1, 34, 0, 0]\n",
            "ETA: 21 minutes   0.24063045178367323%   80/33246 TOTALS: [2, 43, 2, 0]\n",
            "ETA: 21 minutes   0.3007880647295915%   100/33246 TOTALS: [4, 53, 2, 2]\n",
            "ETA: 20 minutes   0.36094567767550984%   120/33246 TOTALS: [4, 61, 2, 3]\n",
            "ETA: 19 minutes   0.42110329062142815%   140/33246 TOTALS: [5, 66, 2, 3]\n",
            "ETA: 20 minutes   0.48126090356734647%   160/33246 TOTALS: [6, 72, 2, 5]\n",
            "ETA: 19 minutes   0.5414185165132648%   180/33246 TOTALS: [6, 82, 2, 5]\n",
            "ETA: 19 minutes   0.601576129459183%   200/33246 TOTALS: [6, 89, 2, 5]\n",
            "ETA: 20 minutes   0.6617337424051014%   220/33246 TOTALS: [9, 97, 2, 6]\n",
            "ETA: 19 minutes   0.7218913553510197%   240/33246 TOTALS: [9, 104, 2, 6]\n",
            "ETA: 20 minutes   0.782048968296938%   260/33246 TOTALS: [12, 112, 2, 6]\n",
            "ETA: 20 minutes   0.8422065812428563%   280/33246 TOTALS: [12, 123, 2, 7]\n",
            "ETA: 20 minutes   0.9023641941887746%   300/33246 TOTALS: [15, 131, 2, 8]\n",
            "ETA: 20 minutes   0.9625218071346929%   320/33246 TOTALS: [16, 141, 2, 9]\n",
            "ETA: 19 minutes   1.0226794200806113%   340/33246 TOTALS: [18, 148, 2, 9]\n",
            "ETA: 19 minutes   1.0828370330265296%   360/33246 TOTALS: [19, 155, 2, 9]\n",
            "ETA: 20 minutes   1.1429946459724478%   380/33246 TOTALS: [22, 164, 2, 10]\n",
            "ETA: 20 minutes   1.203152258918366%   400/33246 TOTALS: [23, 173, 2, 10]\n",
            "ETA: 20 minutes   1.2633098718642843%   420/33246 TOTALS: [25, 181, 2, 11]\n",
            "ETA: 18 minutes   1.3234674848102028%   440/33246 TOTALS: [25, 186, 2, 11]\n",
            "ETA: 23 minutes   1.383625097756121%   460/33246 TOTALS: [26, 196, 3, 12]\n",
            "ETA: 20 minutes   1.4437827107020393%   480/33246 TOTALS: [27, 208, 3, 12]\n",
            "ETA: 20 minutes   1.5039403236479576%   500/33246 TOTALS: [27, 220, 3, 12]\n",
            "ETA: 21 minutes   1.564097936593876%   520/33246 TOTALS: [27, 233, 3, 12]\n",
            "ETA: 18 minutes   1.6242555495397943%   540/33246 TOTALS: [28, 237, 3, 12]\n",
            "ETA: 20 minutes   1.6844131624857126%   560/33246 TOTALS: [29, 249, 3, 12]\n",
            "ETA: 21 minutes   1.7445707754316309%   580/33246 TOTALS: [30, 258, 3, 14]\n",
            "ETA: 19 minutes   1.8047283883775491%   600/33246 TOTALS: [30, 266, 3, 15]\n",
            "ETA: 20 minutes   1.8648860013234674%   620/33246 TOTALS: [32, 273, 4, 15]\n",
            "ETA: 20 minutes   1.9250436142693859%   640/33246 TOTALS: [32, 283, 4, 15]\n",
            "ETA: 20 minutes   1.9852012272153041%   660/33246 TOTALS: [34, 291, 4, 15]\n",
            "ETA: 18 minutes   2.0453588401612226%   680/33246 TOTALS: [35, 297, 4, 16]\n",
            "ETA: 20 minutes   2.105516453107141%   700/33246 TOTALS: [38, 306, 4, 16]\n",
            "ETA: 20 minutes   2.165674066053059%   720/33246 TOTALS: [38, 315, 4, 16]\n",
            "ETA: 21 minutes   2.2258316789989774%   740/33246 TOTALS: [38, 327, 5, 16]\n",
            "ETA: 21 minutes   2.2859892919448956%   760/33246 TOTALS: [39, 339, 5, 16]\n",
            "ETA: 19 minutes   2.346146904890814%   780/33246 TOTALS: [39, 347, 5, 17]\n",
            "ETA: 18 minutes   2.406304517836732%   800/33246 TOTALS: [39, 354, 5, 17]\n",
            "ETA: 20 minutes   2.4664621307826504%   820/33246 TOTALS: [42, 360, 5, 17]\n",
            "ETA: 18 minutes   2.5266197437285687%   840/33246 TOTALS: [42, 365, 5, 17]\n",
            "ETA: 20 minutes   2.586777356674487%   860/33246 TOTALS: [44, 373, 5, 17]\n",
            "ETA: 20 minutes   2.6469349696204056%   880/33246 TOTALS: [44, 382, 5, 17]\n",
            "ETA: 19 minutes   2.707092582566324%   900/33246 TOTALS: [44, 392, 5, 17]\n",
            "ETA: 19 minutes   2.767250195512242%   920/33246 TOTALS: [45, 398, 5, 17]\n",
            "ETA: 19 minutes   2.8274078084581604%   940/33246 TOTALS: [45, 406, 5, 17]\n",
            "ETA: 21 minutes   2.8875654214040787%   960/33246 TOTALS: [48, 416, 5, 17]\n",
            "ETA: 20 minutes   2.9477230343499974%   980/33246 TOTALS: [49, 424, 5, 18]\n",
            "ETA: 19 minutes   3.007880647295915%   1000/33246 TOTALS: [49, 431, 5, 19]\n",
            "ETA: 20 minutes   3.0680382602418335%   1020/33246 TOTALS: [51, 439, 5, 20]\n",
            "ETA: 18 minutes   3.128195873187752%   1040/33246 TOTALS: [52, 444, 5, 20]\n",
            "ETA: 21 minutes   3.18835348613367%   1060/33246 TOTALS: [54, 451, 5, 20]\n",
            "ETA: 20 minutes   3.2485110990795887%   1080/33246 TOTALS: [54, 461, 5, 21]\n",
            "ETA: 21 minutes   3.3086687120255065%   1100/33246 TOTALS: [54, 474, 5, 21]\n",
            "ETA: 18 minutes   3.368826324971425%   1120/33246 TOTALS: [56, 481, 5, 21]\n",
            "ETA: 20 minutes   3.428983937917343%   1140/33246 TOTALS: [57, 491, 5, 21]\n",
            "ETA: 18 minutes   3.4891415508632617%   1160/33246 TOTALS: [57, 497, 5, 22]\n",
            "ETA: 19 minutes   3.5492991638091804%   1180/33246 TOTALS: [57, 508, 5, 22]\n",
            "ETA: 19 minutes   3.6094567767550982%   1200/33246 TOTALS: [58, 517, 6, 22]\n",
            "ETA: 19 minutes   3.669614389701017%   1220/33246 TOTALS: [58, 525, 6, 22]\n",
            "ETA: 20 minutes   3.7297720026469348%   1240/33246 TOTALS: [59, 537, 6, 22]\n",
            "ETA: 18 minutes   3.7899296155928535%   1260/33246 TOTALS: [61, 541, 6, 24]\n",
            "ETA: 20 minutes   3.8500872285387717%   1280/33246 TOTALS: [61, 555, 6, 24]\n",
            "ETA: 20 minutes   3.91024484148469%   1300/33246 TOTALS: [62, 566, 6, 24]\n",
            "ETA: 19 minutes   3.9704024544306082%   1320/33246 TOTALS: [62, 574, 6, 24]\n",
            "ETA: 20 minutes   4.030560067376526%   1340/33246 TOTALS: [65, 584, 6, 24]\n",
            "ETA: 19 minutes   4.090717680322445%   1360/33246 TOTALS: [66, 590, 6, 24]\n",
            "ETA: 18 minutes   4.150875293268363%   1380/33246 TOTALS: [66, 593, 6, 25]\n",
            "ETA: 20 minutes   4.211032906214282%   1400/33246 TOTALS: [67, 601, 6, 27]\n",
            "ETA: 19 minutes   4.2711905191602%   1420/33246 TOTALS: [69, 607, 6, 28]\n",
            "ETA: 20 minutes   4.331348132106118%   1440/33246 TOTALS: [70, 614, 6, 29]\n",
            "ETA: 18 minutes   4.3915057450520365%   1460/33246 TOTALS: [70, 620, 6, 30]\n",
            "ETA: 18 minutes   4.451663357997955%   1480/33246 TOTALS: [71, 625, 6, 33]\n",
            "ETA: 19 minutes   4.511820970943873%   1500/33246 TOTALS: [71, 633, 6, 33]\n",
            "ETA: 18 minutes   4.571978583889791%   1520/33246 TOTALS: [72, 641, 6, 33]\n",
            "ETA: 19 minutes   4.6321361968357095%   1540/33246 TOTALS: [72, 647, 6, 34]\n",
            "ETA: 20 minutes   4.692293809781628%   1560/33246 TOTALS: [75, 655, 6, 35]\n",
            "ETA: 19 minutes   4.752451422727546%   1580/33246 TOTALS: [75, 665, 6, 37]\n",
            "ETA: 19 minutes   4.812609035673464%   1600/33246 TOTALS: [75, 676, 6, 37]\n",
            "ETA: 19 minutes   4.8727666486193835%   1620/33246 TOTALS: [75, 686, 6, 37]\n",
            "ETA: 19 minutes   4.932924261565301%   1640/33246 TOTALS: [76, 695, 6, 37]\n",
            "ETA: 19 minutes   4.99308187451122%   1660/33246 TOTALS: [77, 708, 6, 37]\n",
            "ETA: 20 minutes   5.053239487457137%   1680/33246 TOTALS: [78, 722, 6, 37]\n",
            "ETA: 19 minutes   5.1133971004030565%   1700/33246 TOTALS: [81, 731, 6, 37]\n",
            "ETA: 20 minutes   5.173554713348974%   1720/33246 TOTALS: [82, 740, 6, 39]\n",
            "ETA: 19 minutes   5.233712326294892%   1740/33246 TOTALS: [84, 750, 6, 39]\n",
            "ETA: 19 minutes   5.293869939240811%   1760/33246 TOTALS: [87, 755, 6, 39]\n",
            "ETA: 19 minutes   5.354027552186729%   1780/33246 TOTALS: [89, 763, 6, 40]\n",
            "ETA: 18 minutes   5.414185165132648%   1800/33246 TOTALS: [90, 769, 6, 40]\n",
            "ETA: 19 minutes   5.474342778078565%   1820/33246 TOTALS: [92, 778, 6, 40]\n",
            "ETA: 18 minutes   5.534500391024484%   1840/33246 TOTALS: [94, 781, 6, 41]\n",
            "ETA: 19 minutes   5.594658003970403%   1860/33246 TOTALS: [96, 790, 6, 42]\n",
            "ETA: 20 minutes   5.654815616916321%   1880/33246 TOTALS: [98, 798, 6, 42]\n",
            "ETA: 19 minutes   5.714973229862239%   1900/33246 TOTALS: [99, 808, 6, 42]\n",
            "ETA: 18 minutes   5.775130842808157%   1920/33246 TOTALS: [100, 815, 6, 42]\n",
            "ETA: 19 minutes   5.835288455754076%   1940/33246 TOTALS: [101, 821, 6, 42]\n",
            "ETA: 19 minutes   5.895446068699995%   1960/33246 TOTALS: [102, 830, 6, 42]\n",
            "ETA: 19 minutes   5.955603681645912%   1980/33246 TOTALS: [102, 839, 6, 43]\n",
            "ETA: 18 minutes   6.01576129459183%   2000/33246 TOTALS: [102, 848, 6, 43]\n",
            "ETA: 20 minutes   6.075918907537749%   2020/33246 TOTALS: [103, 860, 7, 44]\n",
            "ETA: 19 minutes   6.136076520483667%   2040/33246 TOTALS: [104, 867, 7, 45]\n",
            "ETA: 18 minutes   6.196234133429585%   2060/33246 TOTALS: [105, 872, 7, 45]\n",
            "ETA: 19 minutes   6.256391746375504%   2080/33246 TOTALS: [106, 883, 7, 45]\n",
            "ETA: 19 minutes   6.316549359321422%   2100/33246 TOTALS: [107, 895, 7, 45]\n",
            "ETA: 19 minutes   6.37670697226734%   2120/33246 TOTALS: [110, 902, 7, 46]\n",
            "ETA: 18 minutes   6.436864585213259%   2140/33246 TOTALS: [111, 909, 7, 46]\n",
            "ETA: 18 minutes   6.497022198159177%   2160/33246 TOTALS: [111, 913, 7, 47]\n",
            "ETA: 19 minutes   6.557179811105095%   2180/33246 TOTALS: [111, 925, 7, 47]\n",
            "ETA: 18 minutes   6.617337424051013%   2200/33246 TOTALS: [111, 932, 7, 48]\n",
            "ETA: 20 minutes   6.677495036996932%   2220/33246 TOTALS: [114, 941, 7, 48]\n",
            "ETA: 19 minutes   6.73765264994285%   2240/33246 TOTALS: [114, 950, 7, 49]\n",
            "ETA: 18 minutes   6.797810262888769%   2260/33246 TOTALS: [116, 955, 7, 49]\n",
            "ETA: 19 minutes   6.857967875834686%   2280/33246 TOTALS: [117, 965, 7, 49]\n",
            "ETA: 19 minutes   6.918125488780605%   2300/33246 TOTALS: [118, 974, 8, 49]\n",
            "ETA: 19 minutes   6.978283101726523%   2320/33246 TOTALS: [119, 981, 8, 50]\n",
            "ETA: 18 minutes   7.038440714672442%   2340/33246 TOTALS: [120, 986, 8, 51]\n",
            "ETA: 19 minutes   7.098598327618361%   2360/33246 TOTALS: [123, 993, 8, 51]\n",
            "ETA: 18 minutes   7.158755940564278%   2380/33246 TOTALS: [127, 996, 8, 52]\n",
            "ETA: 19 minutes   7.2189135535101965%   2400/33246 TOTALS: [127, 1006, 8, 52]\n",
            "ETA: 19 minutes   7.279071166456115%   2420/33246 TOTALS: [128, 1011, 8, 54]\n",
            "ETA: 18 minutes   7.339228779402034%   2440/33246 TOTALS: [130, 1017, 8, 56]\n",
            "ETA: 18 minutes   7.399386392347952%   2460/33246 TOTALS: [130, 1022, 8, 56]\n",
            "ETA: 19 minutes   7.4595440052938695%   2480/33246 TOTALS: [130, 1033, 8, 56]\n",
            "ETA: 19 minutes   7.519701618239788%   2500/33246 TOTALS: [131, 1044, 8, 58]\n",
            "ETA: 17 minutes   7.579859231185707%   2520/33246 TOTALS: [132, 1051, 8, 58]\n",
            "ETA: 19 minutes   7.640016844131625%   2540/33246 TOTALS: [132, 1063, 9, 58]\n",
            "ETA: 18 minutes   7.700174457077543%   2560/33246 TOTALS: [133, 1071, 9, 58]\n",
            "ETA: 19 minutes   7.760332070023461%   2580/33246 TOTALS: [135, 1079, 9, 58]\n",
            "ETA: 19 minutes   7.82048968296938%   2600/33246 TOTALS: [139, 1088, 9, 58]\n",
            "ETA: 19 minutes   7.880647295915298%   2620/33246 TOTALS: [139, 1098, 9, 59]\n",
            "ETA: 18 minutes   7.9408049088612165%   2640/33246 TOTALS: [141, 1105, 10, 59]\n",
            "ETA: 18 minutes   8.000962521807136%   2660/33246 TOTALS: [141, 1111, 10, 59]\n",
            "ETA: 20 minutes   8.061120134753052%   2680/33246 TOTALS: [142, 1122, 10, 60]\n",
            "ETA: 18 minutes   8.12127774769897%   2700/33246 TOTALS: [142, 1131, 10, 60]\n",
            "ETA: 17 minutes   8.18143536064489%   2720/33246 TOTALS: [143, 1136, 10, 61]\n",
            "ETA: 18 minutes   8.241592973590809%   2740/33246 TOTALS: [145, 1142, 10, 61]\n",
            "ETA: 18 minutes   8.301750586536725%   2760/33246 TOTALS: [146, 1150, 10, 61]\n",
            "ETA: 18 minutes   8.361908199482643%   2780/33246 TOTALS: [147, 1158, 10, 61]\n",
            "ETA: 19 minutes   8.422065812428563%   2800/33246 TOTALS: [149, 1167, 10, 62]\n",
            "ETA: 17 minutes   8.482223425374482%   2820/33246 TOTALS: [149, 1174, 10, 62]\n",
            "ETA: 17 minutes   8.5423810383204%   2840/33246 TOTALS: [151, 1178, 10, 62]\n",
            "ETA: 17 minutes   8.602538651266316%   2860/33246 TOTALS: [151, 1185, 10, 62]\n",
            "ETA: 18 minutes   8.662696264212236%   2880/33246 TOTALS: [152, 1191, 10, 63]\n",
            "ETA: 17 minutes   8.722853877158155%   2900/33246 TOTALS: [153, 1194, 10, 63]\n",
            "ETA: 19 minutes   8.783011490104073%   2920/33246 TOTALS: [155, 1203, 10, 63]\n",
            "ETA: 18 minutes   8.843169103049991%   2940/33246 TOTALS: [157, 1211, 10, 64]\n",
            "ETA: 18 minutes   8.90332671599591%   2960/33246 TOTALS: [158, 1215, 10, 66]\n",
            "ETA: 18 minutes   8.963484328941828%   2980/33246 TOTALS: [158, 1226, 10, 66]\n",
            "ETA: 18 minutes   9.023641941887746%   3000/33246 TOTALS: [161, 1232, 10, 67]\n",
            "ETA: 18 minutes   9.083799554833664%   3020/33246 TOTALS: [162, 1239, 10, 68]\n",
            "ETA: 18 minutes   9.143957167779583%   3040/33246 TOTALS: [162, 1249, 10, 69]\n",
            "ETA: 18 minutes   9.2041147807255%   3060/33246 TOTALS: [164, 1255, 10, 71]\n",
            "ETA: 18 minutes   9.264272393671419%   3080/33246 TOTALS: [166, 1261, 10, 71]\n",
            "ETA: 18 minutes   9.324430006617337%   3100/33246 TOTALS: [166, 1271, 10, 71]\n",
            "ETA: 19 minutes   9.384587619563256%   3120/33246 TOTALS: [167, 1282, 11, 72]\n",
            "ETA: 17 minutes   9.444745232509174%   3140/33246 TOTALS: [167, 1289, 11, 72]\n",
            "ETA: 18 minutes   9.504902845455092%   3160/33246 TOTALS: [167, 1298, 11, 72]\n",
            "ETA: 18 minutes   9.56506045840101%   3180/33246 TOTALS: [167, 1308, 11, 72]\n",
            "ETA: 18 minutes   9.625218071346929%   3200/33246 TOTALS: [169, 1315, 12, 73]\n",
            "ETA: 18 minutes   9.685375684292847%   3220/33246 TOTALS: [169, 1324, 12, 74]\n",
            "ETA: 19 minutes   9.745533297238767%   3240/33246 TOTALS: [173, 1333, 13, 74]\n",
            "ETA: 18 minutes   9.805690910184683%   3260/33246 TOTALS: [176, 1343, 13, 75]\n",
            "ETA: 19 minutes   9.865848523130602%   3280/33246 TOTALS: [177, 1354, 13, 76]\n",
            "ETA: 18 minutes   9.92600613607652%   3300/33246 TOTALS: [178, 1359, 13, 78]\n",
            "ETA: 19 minutes   9.98616374902244%   3320/33246 TOTALS: [179, 1368, 13, 80]\n",
            "ETA: 18 minutes   10.046321361968358%   3340/33246 TOTALS: [179, 1378, 14, 80]\n",
            "ETA: 18 minutes   10.106478974914275%   3360/33246 TOTALS: [179, 1387, 14, 80]\n",
            "ETA: 18 minutes   10.166636587860193%   3380/33246 TOTALS: [180, 1395, 14, 80]\n",
            "ETA: 19 minutes   10.226794200806113%   3400/33246 TOTALS: [181, 1405, 15, 80]\n",
            "ETA: 18 minutes   10.286951813752031%   3420/33246 TOTALS: [182, 1413, 15, 80]\n",
            "ETA: 17 minutes   10.347109426697948%   3440/33246 TOTALS: [182, 1424, 15, 81]\n",
            "ETA: 17 minutes   10.407267039643866%   3460/33246 TOTALS: [184, 1429, 15, 81]\n",
            "ETA: 19 minutes   10.467424652589784%   3480/33246 TOTALS: [185, 1438, 15, 83]\n",
            "ETA: 18 minutes   10.527582265535704%   3500/33246 TOTALS: [185, 1447, 15, 83]\n",
            "ETA: 16 minutes   10.587739878481623%   3520/33246 TOTALS: [185, 1452, 15, 83]\n",
            "ETA: 16 minutes   10.647897491427539%   3540/33246 TOTALS: [186, 1456, 15, 83]\n",
            "ETA: 18 minutes   10.708055104373457%   3560/33246 TOTALS: [187, 1464, 15, 83]\n",
            "ETA: 17 minutes   10.768212717319377%   3580/33246 TOTALS: [188, 1472, 15, 83]\n",
            "ETA: 18 minutes   10.828370330265296%   3600/33246 TOTALS: [189, 1479, 15, 83]\n",
            "ETA: 17 minutes   10.888527943211214%   3620/33246 TOTALS: [190, 1487, 15, 83]\n",
            "ETA: 18 minutes   10.94868555615713%   3640/33246 TOTALS: [191, 1494, 15, 84]\n",
            "ETA: 19 minutes   11.00884316910305%   3660/33246 TOTALS: [193, 1506, 15, 85]\n",
            "ETA: 17 minutes   11.069000782048969%   3680/33246 TOTALS: [193, 1510, 16, 86]\n",
            "ETA: 17 minutes   11.129158394994887%   3700/33246 TOTALS: [194, 1516, 17, 86]\n",
            "ETA: 18 minutes   11.189316007940805%   3720/33246 TOTALS: [195, 1524, 17, 88]\n",
            "ETA: 18 minutes   11.249473620886723%   3740/33246 TOTALS: [195, 1531, 17, 89]\n",
            "ETA: 18 minutes   11.309631233832642%   3760/33246 TOTALS: [195, 1540, 17, 90]\n",
            "ETA: 17 minutes   11.36978884677856%   3780/33246 TOTALS: [196, 1544, 17, 92]\n",
            "ETA: 18 minutes   11.429946459724478%   3800/33246 TOTALS: [199, 1551, 17, 93]\n",
            "ETA: 17 minutes   11.490104072670396%   3820/33246 TOTALS: [200, 1557, 17, 93]\n",
            "ETA: 17 minutes   11.550261685616315%   3840/33246 TOTALS: [201, 1565, 17, 93]\n",
            "ETA: 17 minutes   11.610419298562233%   3860/33246 TOTALS: [202, 1572, 17, 94]\n",
            "ETA: 17 minutes   11.670576911508151%   3880/33246 TOTALS: [202, 1580, 17, 94]\n",
            "ETA: 18 minutes   11.73073452445407%   3900/33246 TOTALS: [203, 1587, 17, 94]\n",
            "ETA: 17 minutes   11.79089213739999%   3920/33246 TOTALS: [203, 1593, 17, 94]\n",
            "ETA: 18 minutes   11.851049750345906%   3940/33246 TOTALS: [203, 1601, 17, 97]\n",
            "ETA: 18 minutes   11.911207363291824%   3960/33246 TOTALS: [203, 1614, 17, 97]\n",
            "ETA: 18 minutes   11.971364976237743%   3980/33246 TOTALS: [203, 1626, 17, 97]\n",
            "ETA: 18 minutes   12.03152258918366%   4000/33246 TOTALS: [204, 1637, 17, 97]\n",
            "ETA: 18 minutes   12.091680202129579%   4020/33246 TOTALS: [205, 1645, 17, 98]\n",
            "ETA: 18 minutes   12.151837815075497%   4040/33246 TOTALS: [208, 1653, 17, 98]\n",
            "ETA: 19 minutes   12.211995428021416%   4060/33246 TOTALS: [209, 1664, 17, 98]\n",
            "ETA: 18 minutes   12.272153040967334%   4080/33246 TOTALS: [213, 1670, 17, 98]\n",
            "ETA: 18 minutes   12.332310653913254%   4100/33246 TOTALS: [213, 1681, 17, 98]\n",
            "ETA: 17 minutes   12.39246826685917%   4120/33246 TOTALS: [215, 1687, 17, 98]\n",
            "ETA: 18 minutes   12.452625879805089%   4140/33246 TOTALS: [215, 1695, 18, 99]\n",
            "ETA: 17 minutes   12.512783492751009%   4160/33246 TOTALS: [215, 1705, 18, 100]\n",
            "ETA: 17 minutes   12.572941105696925%   4180/33246 TOTALS: [218, 1711, 18, 101]\n",
            "ETA: 17 minutes   12.633098718642843%   4200/33246 TOTALS: [218, 1719, 19, 102]\n",
            "ETA: 18 minutes   12.693256331588762%   4220/33246 TOTALS: [221, 1727, 21, 102]\n",
            "ETA: 17 minutes   12.75341394453468%   4240/33246 TOTALS: [224, 1732, 21, 102]\n",
            "ETA: 16 minutes   12.8135715574806%   4260/33246 TOTALS: [226, 1736, 21, 102]\n",
            "ETA: 18 minutes   12.873729170426518%   4280/33246 TOTALS: [227, 1746, 21, 102]\n",
            "ETA: 17 minutes   12.933886783372436%   4300/33246 TOTALS: [227, 1756, 21, 104]\n",
            "ETA: 18 minutes   12.994044396318355%   4320/33246 TOTALS: [227, 1766, 22, 104]\n",
            "ETA: 17 minutes   13.054202009264273%   4340/33246 TOTALS: [229, 1772, 22, 104]\n",
            "ETA: 17 minutes   13.11435962221019%   4360/33246 TOTALS: [230, 1776, 22, 104]\n",
            "ETA: 17 minutes   13.174517235156108%   4380/33246 TOTALS: [231, 1783, 22, 105]\n",
            "ETA: 18 minutes   13.234674848102026%   4400/33246 TOTALS: [231, 1792, 22, 105]\n",
            "ETA: 17 minutes   13.294832461047946%   4420/33246 TOTALS: [233, 1800, 22, 105]\n",
            "ETA: 17 minutes   13.354990073993864%   4440/33246 TOTALS: [234, 1808, 22, 105]\n",
            "ETA: 17 minutes   13.415147686939783%   4460/33246 TOTALS: [234, 1816, 23, 105]\n",
            "ETA: 17 minutes   13.4753052998857%   4480/33246 TOTALS: [235, 1822, 23, 105]\n",
            "ETA: 17 minutes   13.535462912831619%   4500/33246 TOTALS: [237, 1832, 23, 106]\n",
            "ETA: 17 minutes   13.595620525777537%   4520/33246 TOTALS: [238, 1838, 23, 108]\n",
            "ETA: 17 minutes   13.655778138723457%   4540/33246 TOTALS: [241, 1845, 23, 108]\n",
            "ETA: 16 minutes   13.715935751669372%   4560/33246 TOTALS: [242, 1851, 23, 108]\n",
            "ETA: 17 minutes   13.77609336461529%   4580/33246 TOTALS: [242, 1861, 23, 109]\n",
            "ETA: 18 minutes   13.83625097756121%   4600/33246 TOTALS: [243, 1872, 23, 110]\n",
            "ETA: 17 minutes   13.896408590507129%   4620/33246 TOTALS: [245, 1880, 23, 110]\n",
            "ETA: 17 minutes   13.956566203453047%   4640/33246 TOTALS: [246, 1889, 23, 110]\n",
            "ETA: 16 minutes   14.016723816398965%   4660/33246 TOTALS: [247, 1895, 23, 110]\n",
            "ETA: 17 minutes   14.076881429344883%   4680/33246 TOTALS: [249, 1899, 23, 110]\n",
            "ETA: 18 minutes   14.137039042290803%   4700/33246 TOTALS: [249, 1907, 23, 114]\n",
            "ETA: 17 minutes   14.197196655236722%   4720/33246 TOTALS: [249, 1917, 23, 114]\n",
            "ETA: 17 minutes   14.25735426818264%   4740/33246 TOTALS: [249, 1927, 23, 114]\n",
            "ETA: 17 minutes   14.317511881128556%   4760/33246 TOTALS: [250, 1937, 23, 115]\n",
            "ETA: 17 minutes   14.377669494074475%   4780/33246 TOTALS: [250, 1946, 23, 117]\n",
            "ETA: 16 minutes   14.437827107020393%   4800/33246 TOTALS: [252, 1951, 23, 117]\n",
            "ETA: 17 minutes   14.497984719966311%   4820/33246 TOTALS: [252, 1961, 23, 117]\n",
            "ETA: 18 minutes   14.55814233291223%   4840/33246 TOTALS: [254, 1969, 23, 117]\n",
            "ETA: 16 minutes   14.618299945858148%   4860/33246 TOTALS: [255, 1975, 23, 117]\n",
            "ETA: 16 minutes   14.678457558804068%   4880/33246 TOTALS: [255, 1981, 23, 118]\n",
            "ETA: 17 minutes   14.738615171749986%   4900/33246 TOTALS: [255, 1991, 23, 118]\n",
            "ETA: 17 minutes   14.798772784695904%   4920/33246 TOTALS: [257, 2000, 23, 118]\n",
            "ETA: 17 minutes   14.85893039764182%   4940/33246 TOTALS: [260, 2007, 23, 118]\n",
            "ETA: 17 minutes   14.919088010587739%   4960/33246 TOTALS: [260, 2014, 23, 120]\n",
            "ETA: 16 minutes   14.979245623533657%   4980/33246 TOTALS: [260, 2022, 23, 121]\n",
            "ETA: 16 minutes   15.039403236479576%   5000/33246 TOTALS: [261, 2028, 23, 122]\n",
            "ETA: 17 minutes   15.099560849425494%   5020/33246 TOTALS: [262, 2036, 23, 122]\n",
            "ETA: 17 minutes   15.159718462371414%   5040/33246 TOTALS: [263, 2043, 24, 122]\n",
            "ETA: 17 minutes   15.219876075317332%   5060/33246 TOTALS: [264, 2052, 25, 123]\n",
            "ETA: 16 minutes   15.28003368826325%   5080/33246 TOTALS: [264, 2058, 25, 123]\n",
            "ETA: 17 minutes   15.340191301209169%   5100/33246 TOTALS: [265, 2066, 25, 123]\n",
            "ETA: 16 minutes   15.400348914155087%   5120/33246 TOTALS: [266, 2073, 25, 123]\n",
            "ETA: 18 minutes   15.460506527101003%   5140/33246 TOTALS: [267, 2082, 25, 125]\n",
            "ETA: 17 minutes   15.520664140046922%   5160/33246 TOTALS: [268, 2089, 26, 127]\n",
            "ETA: 17 minutes   15.58082175299284%   5180/33246 TOTALS: [270, 2096, 26, 127]\n",
            "ETA: 17 minutes   15.64097936593876%   5200/33246 TOTALS: [270, 2106, 26, 128]\n",
            "ETA: 18 minutes   15.701136978884678%   5220/33246 TOTALS: [273, 2117, 26, 128]\n",
            "ETA: 16 minutes   15.761294591830596%   5240/33246 TOTALS: [273, 2127, 26, 129]\n",
            "ETA: 16 minutes   15.821452204776515%   5260/33246 TOTALS: [274, 2132, 26, 130]\n",
            "ETA: 16 minutes   15.881609817722433%   5280/33246 TOTALS: [275, 2140, 26, 130]\n",
            "ETA: 17 minutes   15.941767430668353%   5300/33246 TOTALS: [276, 2147, 26, 132]\n",
            "ETA: 16 minutes   16.00192504361427%   5320/33246 TOTALS: [277, 2158, 26, 132]\n",
            "ETA: 16 minutes   16.062082656560186%   5340/33246 TOTALS: [277, 2164, 26, 134]\n",
            "ETA: 17 minutes   16.122240269506104%   5360/33246 TOTALS: [277, 2174, 26, 135]\n",
            "ETA: 17 minutes   16.182397882452022%   5380/33246 TOTALS: [278, 2182, 26, 136]\n",
            "ETA: 18 minutes   16.24255549539794%   5400/33246 TOTALS: [279, 2192, 27, 136]\n",
            "ETA: 17 minutes   16.302713108343863%   5420/33246 TOTALS: [279, 2202, 27, 138]\n",
            "ETA: 17 minutes   16.36287072128978%   5440/33246 TOTALS: [279, 2209, 27, 141]\n",
            "ETA: 17 minutes   16.4230283342357%   5460/33246 TOTALS: [279, 2221, 27, 141]\n",
            "ETA: 16 minutes   16.483185947181617%   5480/33246 TOTALS: [280, 2228, 27, 141]\n",
            "ETA: 17 minutes   16.543343560127536%   5500/33246 TOTALS: [281, 2235, 27, 141]\n",
            "ETA: 18 minutes   16.60350117307345%   5520/33246 TOTALS: [283, 2244, 28, 141]\n",
            "ETA: 17 minutes   16.66365878601937%   5540/33246 TOTALS: [284, 2254, 28, 142]\n",
            "ETA: 16 minutes   16.723816398965287%   5560/33246 TOTALS: [284, 2262, 28, 142]\n",
            "ETA: 16 minutes   16.783974011911205%   5580/33246 TOTALS: [284, 2267, 28, 142]\n",
            "ETA: 17 minutes   16.844131624857127%   5600/33246 TOTALS: [285, 2275, 28, 143]\n",
            "ETA: 16 minutes   16.904289237803045%   5620/33246 TOTALS: [285, 2284, 28, 144]\n",
            "ETA: 16 minutes   16.964446850748963%   5640/33246 TOTALS: [286, 2291, 28, 144]\n",
            "ETA: 16 minutes   17.02460446369488%   5660/33246 TOTALS: [286, 2299, 28, 145]\n",
            "ETA: 18 minutes   17.0847620766408%   5680/33246 TOTALS: [286, 2313, 28, 145]\n",
            "ETA: 16 minutes   17.144919689586718%   5700/33246 TOTALS: [287, 2319, 28, 145]\n",
            "ETA: 17 minutes   17.205077302532633%   5720/33246 TOTALS: [288, 2330, 28, 145]\n",
            "ETA: 17 minutes   17.26523491547855%   5740/33246 TOTALS: [288, 2339, 28, 146]\n",
            "ETA: 16 minutes   17.325392528424473%   5760/33246 TOTALS: [288, 2347, 29, 147]\n",
            "ETA: 16 minutes   17.38555014137039%   5780/33246 TOTALS: [288, 2353, 29, 148]\n",
            "ETA: 17 minutes   17.44570775431631%   5800/33246 TOTALS: [289, 2365, 29, 149]\n",
            "ETA: 16 minutes   17.505865367262228%   5820/33246 TOTALS: [289, 2374, 29, 149]\n",
            "ETA: 16 minutes   17.566022980208146%   5840/33246 TOTALS: [290, 2382, 29, 151]\n",
            "ETA: 17 minutes   17.626180593154064%   5860/33246 TOTALS: [291, 2393, 29, 152]\n",
            "ETA: 17 minutes   17.686338206099983%   5880/33246 TOTALS: [291, 2403, 30, 153]\n",
            "ETA: 16 minutes   17.7464958190459%   5900/33246 TOTALS: [293, 2413, 30, 153]\n",
            "ETA: 16 minutes   17.80665343199182%   5920/33246 TOTALS: [295, 2423, 30, 153]\n",
            "ETA: 16 minutes   17.866811044937737%   5940/33246 TOTALS: [296, 2432, 31, 154]\n",
            "ETA: 17 minutes   17.926968657883656%   5960/33246 TOTALS: [298, 2442, 33, 155]\n",
            "ETA: 17 minutes   17.987126270829574%   5980/33246 TOTALS: [299, 2451, 33, 156]\n",
            "ETA: 17 minutes   18.047283883775492%   6000/33246 TOTALS: [300, 2461, 33, 157]\n",
            "ETA: 16 minutes   18.10744149672141%   6020/33246 TOTALS: [302, 2467, 33, 157]\n",
            "ETA: 18 minutes   18.16759910966733%   6040/33246 TOTALS: [302, 2478, 33, 158]\n",
            "ETA: 17 minutes   18.227756722613247%   6060/33246 TOTALS: [305, 2486, 33, 159]\n",
            "ETA: 16 minutes   18.287914335559165%   6080/33246 TOTALS: [307, 2493, 33, 159]\n",
            "ETA: 16 minutes   18.348071948505083%   6100/33246 TOTALS: [308, 2500, 33, 159]\n",
            "ETA: 16 minutes   18.408229561451%   6120/33246 TOTALS: [309, 2509, 33, 159]\n",
            "ETA: 16 minutes   18.46838717439692%   6140/33246 TOTALS: [311, 2516, 33, 159]\n",
            "ETA: 15 minutes   18.528544787342838%   6160/33246 TOTALS: [312, 2521, 34, 159]\n",
            "ETA: 16 minutes   18.588702400288756%   6180/33246 TOTALS: [313, 2528, 34, 160]\n",
            "ETA: 16 minutes   18.648860013234675%   6200/33246 TOTALS: [313, 2533, 34, 162]\n",
            "ETA: 16 minutes   18.709017626180593%   6220/33246 TOTALS: [314, 2539, 34, 162]\n",
            "ETA: 16 minutes   18.76917523912651%   6240/33246 TOTALS: [315, 2546, 34, 163]\n",
            "ETA: 17 minutes   18.82933285207243%   6260/33246 TOTALS: [318, 2556, 34, 164]\n",
            "ETA: 16 minutes   18.889490465018348%   6280/33246 TOTALS: [321, 2560, 34, 164]\n",
            "ETA: 16 minutes   18.949648077964266%   6300/33246 TOTALS: [321, 2569, 34, 164]\n",
            "ETA: 17 minutes   19.009805690910184%   6320/33246 TOTALS: [322, 2581, 34, 165]\n",
            "ETA: 18 minutes   19.069963303856102%   6340/33246 TOTALS: [323, 2593, 34, 167]\n",
            "ETA: 16 minutes   19.13012091680202%   6360/33246 TOTALS: [324, 2600, 34, 167]\n",
            "ETA: 17 minutes   19.19027852974794%   6380/33246 TOTALS: [325, 2612, 34, 168]\n",
            "ETA: 16 minutes   19.250436142693857%   6400/33246 TOTALS: [325, 2618, 34, 168]\n",
            "ETA: 15 minutes   19.310593755639776%   6420/33246 TOTALS: [327, 2621, 35, 168]\n",
            "ETA: 16 minutes   19.370751368585694%   6440/33246 TOTALS: [327, 2629, 35, 169]\n",
            "ETA: 16 minutes   19.430908981531616%   6460/33246 TOTALS: [328, 2640, 35, 169]\n",
            "ETA: 16 minutes   19.491066594477534%   6480/33246 TOTALS: [330, 2646, 35, 169]\n",
            "ETA: 15 minutes   19.55122420742345%   6500/33246 TOTALS: [330, 2652, 35, 170]\n",
            "ETA: 15 minutes   19.611381820369367%   6520/33246 TOTALS: [331, 2658, 35, 171]\n",
            "ETA: 15 minutes   19.671539433315285%   6540/33246 TOTALS: [333, 2664, 35, 171]\n",
            "ETA: 16 minutes   19.731697046261203%   6560/33246 TOTALS: [334, 2673, 35, 171]\n",
            "ETA: 16 minutes   19.79185465920712%   6580/33246 TOTALS: [334, 2682, 35, 171]\n",
            "ETA: 16 minutes   19.85201227215304%   6600/33246 TOTALS: [334, 2689, 35, 172]\n",
            "ETA: 16 minutes   19.912169885098958%   6620/33246 TOTALS: [337, 2697, 35, 173]\n",
            "ETA: 16 minutes   19.97232749804488%   6640/33246 TOTALS: [337, 2708, 35, 173]\n",
            "ETA: 16 minutes   20.032485110990798%   6660/33246 TOTALS: [339, 2717, 35, 173]\n",
            "ETA: 17 minutes   20.092642723936716%   6680/33246 TOTALS: [340, 2725, 35, 173]\n",
            "ETA: 16 minutes   20.15280033688263%   6700/33246 TOTALS: [340, 2733, 35, 174]\n",
            "ETA: 16 minutes   20.21295794982855%   6720/33246 TOTALS: [340, 2740, 35, 175]\n",
            "ETA: 17 minutes   20.273115562774468%   6740/33246 TOTALS: [341, 2750, 35, 175]\n",
            "ETA: 15 minutes   20.333273175720386%   6760/33246 TOTALS: [342, 2757, 35, 175]\n",
            "ETA: 17 minutes   20.393430788666304%   6780/33246 TOTALS: [345, 2768, 35, 175]\n",
            "ETA: 16 minutes   20.453588401612226%   6800/33246 TOTALS: [345, 2778, 35, 177]\n",
            "ETA: 16 minutes   20.513746014558144%   6820/33246 TOTALS: [346, 2787, 35, 177]\n",
            "ETA: 16 minutes   20.573903627504063%   6840/33246 TOTALS: [348, 2795, 35, 178]\n",
            "ETA: 16 minutes   20.63406124044998%   6860/33246 TOTALS: [348, 2803, 35, 178]\n",
            "ETA: 16 minutes   20.694218853395896%   6880/33246 TOTALS: [348, 2814, 35, 178]\n",
            "ETA: 17 minutes   20.754376466341814%   6900/33246 TOTALS: [349, 2826, 35, 178]\n",
            "ETA: 16 minutes   20.814534079287732%   6920/33246 TOTALS: [350, 2836, 35, 178]\n",
            "ETA: 16 minutes   20.87469169223365%   6940/33246 TOTALS: [352, 2845, 35, 178]\n",
            "ETA: 15 minutes   20.93484930517957%   6960/33246 TOTALS: [354, 2850, 35, 178]\n",
            "ETA: 16 minutes   20.99500691812549%   6980/33246 TOTALS: [355, 2859, 35, 178]\n",
            "ETA: 16 minutes   21.05516453107141%   7000/33246 TOTALS: [356, 2864, 35, 178]\n",
            "ETA: 17 minutes   21.115322144017327%   7020/33246 TOTALS: [356, 2877, 35, 179]\n",
            "ETA: 16 minutes   21.175479756963245%   7040/33246 TOTALS: [356, 2888, 35, 180]\n",
            "ETA: 15 minutes   21.235637369909163%   7060/33246 TOTALS: [357, 2895, 35, 180]\n",
            "ETA: 15 minutes   21.295794982855078%   7080/33246 TOTALS: [357, 2902, 35, 181]\n",
            "ETA: 16 minutes   21.355952595800996%   7100/33246 TOTALS: [357, 2912, 35, 182]\n",
            "ETA: 16 minutes   21.416110208746915%   7120/33246 TOTALS: [359, 2920, 35, 182]\n",
            "ETA: 17 minutes   21.476267821692836%   7140/33246 TOTALS: [360, 2931, 35, 184]\n",
            "ETA: 15 minutes   21.536425434638755%   7160/33246 TOTALS: [361, 2941, 35, 185]\n",
            "ETA: 16 minutes   21.596583047584673%   7180/33246 TOTALS: [363, 2947, 35, 186]\n",
            "ETA: 15 minutes   21.65674066053059%   7200/33246 TOTALS: [365, 2952, 35, 187]\n",
            "ETA: 15 minutes   21.71689827347651%   7220/33246 TOTALS: [365, 2959, 35, 188]\n",
            "ETA: 16 minutes   21.777055886422428%   7240/33246 TOTALS: [366, 2972, 35, 188]\n",
            "ETA: 15 minutes   21.837213499368346%   7260/33246 TOTALS: [367, 2980, 35, 188]\n",
            "ETA: 16 minutes   21.89737111231426%   7280/33246 TOTALS: [367, 2990, 35, 188]\n",
            "ETA: 14 minutes   21.957528725260183%   7300/33246 TOTALS: [367, 2996, 35, 188]\n",
            "ETA: 16 minutes   22.0176863382061%   7320/33246 TOTALS: [368, 3006, 35, 188]\n",
            "ETA: 16 minutes   22.07784395115202%   7340/33246 TOTALS: [368, 3016, 35, 189]\n",
            "ETA: 16 minutes   22.138001564097937%   7360/33246 TOTALS: [371, 3024, 35, 189]\n",
            "ETA: 15 minutes   22.198159177043856%   7380/33246 TOTALS: [371, 3032, 36, 189]\n",
            "ETA: 16 minutes   22.258316789989774%   7400/33246 TOTALS: [371, 3045, 36, 190]\n",
            "ETA: 15 minutes   22.318474402935692%   7420/33246 TOTALS: [372, 3051, 36, 190]\n",
            "ETA: 14 minutes   22.37863201588161%   7440/33246 TOTALS: [372, 3055, 36, 191]\n",
            "ETA: 14 minutes   22.43878962882753%   7460/33246 TOTALS: [373, 3061, 36, 191]\n",
            "ETA: 16 minutes   22.498947241773447%   7480/33246 TOTALS: [373, 3071, 36, 194]\n",
            "ETA: 16 minutes   22.559104854719365%   7500/33246 TOTALS: [373, 3081, 37, 195]\n",
            "ETA: 15 minutes   22.619262467665283%   7520/33246 TOTALS: [374, 3089, 37, 195]\n",
            "ETA: 15 minutes   22.6794200806112%   7540/33246 TOTALS: [374, 3100, 37, 195]\n",
            "ETA: 14 minutes   22.73957769355712%   7560/33246 TOTALS: [374, 3108, 37, 195]\n",
            "ETA: 15 minutes   22.799735306503038%   7580/33246 TOTALS: [376, 3117, 37, 195]\n",
            "ETA: 16 minutes   22.859892919448956%   7600/33246 TOTALS: [377, 3130, 37, 195]\n",
            "ETA: 15 minutes   22.920050532394875%   7620/33246 TOTALS: [377, 3138, 37, 195]\n",
            "ETA: 15 minutes   22.980208145340793%   7640/33246 TOTALS: [377, 3148, 37, 195]\n",
            "ETA: 15 minutes   23.04036575828671%   7660/33246 TOTALS: [378, 3153, 37, 196]\n",
            "ETA: 15 minutes   23.10052337123263%   7680/33246 TOTALS: [378, 3161, 37, 196]\n",
            "ETA: 15 minutes   23.160680984178548%   7700/33246 TOTALS: [380, 3168, 37, 197]\n",
            "ETA: 15 minutes   23.220838597124466%   7720/33246 TOTALS: [381, 3174, 37, 198]\n",
            "ETA: 15 minutes   23.280996210070384%   7740/33246 TOTALS: [382, 3180, 37, 200]\n",
            "ETA: 14 minutes   23.341153823016302%   7760/33246 TOTALS: [382, 3185, 37, 200]\n",
            "ETA: 16 minutes   23.40131143596222%   7780/33246 TOTALS: [382, 3193, 38, 200]\n",
            "ETA: 16 minutes   23.46146904890814%   7800/33246 TOTALS: [386, 3202, 38, 200]\n",
            "ETA: 16 minutes   23.521626661854057%   7820/33246 TOTALS: [389, 3211, 38, 200]\n",
            "ETA: 15 minutes   23.58178427479998%   7840/33246 TOTALS: [390, 3219, 38, 200]\n",
            "ETA: 15 minutes   23.641941887745894%   7860/33246 TOTALS: [391, 3227, 38, 200]\n",
            "ETA: 15 minutes   23.702099500691812%   7880/33246 TOTALS: [391, 3238, 38, 200]\n",
            "ETA: 16 minutes   23.76225711363773%   7900/33246 TOTALS: [392, 3249, 38, 200]\n",
            "ETA: 15 minutes   23.82241472658365%   7920/33246 TOTALS: [392, 3259, 38, 200]\n",
            "ETA: 14 minutes   23.882572339529567%   7940/33246 TOTALS: [393, 3264, 38, 200]\n",
            "ETA: 15 minutes   23.942729952475485%   7960/33246 TOTALS: [394, 3275, 38, 200]\n",
            "ETA: 16 minutes   24.002887565421403%   7980/33246 TOTALS: [395, 3284, 38, 201]\n",
            "ETA: 14 minutes   24.06304517836732%   8000/33246 TOTALS: [397, 3288, 38, 201]\n",
            "ETA: 16 minutes   24.123202791313243%   8020/33246 TOTALS: [398, 3296, 38, 203]\n",
            "ETA: 15 minutes   24.183360404259158%   8040/33246 TOTALS: [399, 3302, 38, 204]\n",
            "ETA: 15 minutes   24.243518017205076%   8060/33246 TOTALS: [399, 3312, 38, 205]\n",
            "ETA: 14 minutes   24.303675630150995%   8080/33246 TOTALS: [401, 3317, 38, 205]\n",
            "ETA: 15 minutes   24.363833243096913%   8100/33246 TOTALS: [401, 3327, 38, 205]\n",
            "ETA: 15 minutes   24.42399085604283%   8120/33246 TOTALS: [401, 3335, 38, 205]\n",
            "ETA: 15 minutes   24.48414846898875%   8140/33246 TOTALS: [403, 3342, 38, 206]\n",
            "ETA: 15 minutes   24.544306081934668%   8160/33246 TOTALS: [405, 3349, 38, 206]\n",
            "ETA: 15 minutes   24.60446369488059%   8180/33246 TOTALS: [405, 3357, 38, 206]\n",
            "ETA: 15 minutes   24.664621307826508%   8200/33246 TOTALS: [406, 3365, 38, 206]\n",
            "ETA: 15 minutes   24.724778920772426%   8220/33246 TOTALS: [406, 3373, 38, 207]\n",
            "ETA: 15 minutes   24.78493653371834%   8240/33246 TOTALS: [406, 3382, 38, 207]\n",
            "ETA: 15 minutes   24.84509414666426%   8260/33246 TOTALS: [406, 3388, 38, 209]\n",
            "ETA: 15 minutes   24.905251759610177%   8280/33246 TOTALS: [407, 3399, 38, 209]\n",
            "ETA: 16 minutes   24.965409372556095%   8300/33246 TOTALS: [408, 3410, 38, 210]\n",
            "ETA: 16 minutes   25.025566985502017%   8320/33246 TOTALS: [411, 3416, 39, 210]\n",
            "ETA: 16 minutes   25.085724598447932%   8340/33246 TOTALS: [413, 3427, 39, 211]\n",
            "ETA: 15 minutes   25.14588221139385%   8360/33246 TOTALS: [414, 3435, 39, 211]\n",
            "ETA: 15 minutes   25.206039824339772%   8380/33246 TOTALS: [416, 3444, 39, 211]\n",
            "ETA: 14 minutes   25.266197437285687%   8400/33246 TOTALS: [417, 3448, 39, 211]\n",
            "ETA: 15 minutes   25.32635505023161%   8420/33246 TOTALS: [417, 3455, 39, 213]\n",
            "ETA: 14 minutes   25.386512663177523%   8440/33246 TOTALS: [417, 3462, 39, 213]\n",
            "ETA: 14 minutes   25.446670276123445%   8460/33246 TOTALS: [417, 3470, 39, 213]\n",
            "ETA: 14 minutes   25.50682788906936%   8480/33246 TOTALS: [417, 3477, 39, 214]\n",
            "ETA: 14 minutes   25.56698550201528%   8500/33246 TOTALS: [418, 3484, 40, 214]\n",
            "ETA: 14 minutes   25.6271431149612%   8520/33246 TOTALS: [418, 3493, 40, 214]\n",
            "ETA: 16 minutes   25.687300727907115%   8540/33246 TOTALS: [419, 3503, 40, 215]\n",
            "ETA: 15 minutes   25.747458340853036%   8560/33246 TOTALS: [420, 3513, 40, 216]\n",
            "ETA: 15 minutes   25.80761595379895%   8580/33246 TOTALS: [420, 3525, 40, 216]\n",
            "ETA: 14 minutes   25.867773566744873%   8600/33246 TOTALS: [420, 3533, 40, 216]\n",
            "ETA: 15 minutes   25.927931179690788%   8620/33246 TOTALS: [420, 3544, 40, 217]\n",
            "ETA: 14 minutes   25.98808879263671%   8640/33246 TOTALS: [421, 3552, 40, 217]\n",
            "ETA: 14 minutes   26.048246405582624%   8660/33246 TOTALS: [421, 3559, 40, 217]\n",
            "ETA: 14 minutes   26.108404018528546%   8680/33246 TOTALS: [422, 3569, 40, 217]\n",
            "ETA: 15 minutes   26.168561631474464%   8700/33246 TOTALS: [423, 3574, 40, 217]\n",
            "ETA: 16 minutes   26.22871924442038%   8720/33246 TOTALS: [423, 3587, 40, 217]\n",
            "ETA: 14 minutes   26.2888768573663%   8740/33246 TOTALS: [424, 3595, 40, 217]\n",
            "ETA: 14 minutes   26.349034470312215%   8760/33246 TOTALS: [424, 3601, 40, 217]\n",
            "ETA: 15 minutes   26.409192083258137%   8780/33246 TOTALS: [424, 3611, 40, 218]\n",
            "ETA: 14 minutes   26.469349696204052%   8800/33246 TOTALS: [424, 3617, 40, 218]\n",
            "ETA: 14 minutes   26.529507309149974%   8820/33246 TOTALS: [427, 3621, 40, 218]\n",
            "ETA: 15 minutes   26.589664922095892%   8840/33246 TOTALS: [427, 3631, 40, 220]\n",
            "ETA: 15 minutes   26.64982253504181%   8860/33246 TOTALS: [428, 3637, 40, 222]\n",
            "ETA: 15 minutes   26.70998014798773%   8880/33246 TOTALS: [430, 3648, 40, 222]\n",
            "ETA: 16 minutes   26.77013776093365%   8900/33246 TOTALS: [430, 3663, 40, 222]\n",
            "ETA: 14 minutes   26.830295373879565%   8920/33246 TOTALS: [430, 3672, 40, 223]\n",
            "ETA: 14 minutes   26.89045298682548%   8940/33246 TOTALS: [432, 3678, 40, 223]\n",
            "ETA: 14 minutes   26.9506105997714%   8960/33246 TOTALS: [432, 3686, 40, 223]\n",
            "ETA: 13 minutes   27.010768212717316%   8980/33246 TOTALS: [432, 3692, 40, 223]\n",
            "ETA: 14 minutes   27.070925825663238%   9000/33246 TOTALS: [433, 3697, 40, 223]\n",
            "ETA: 15 minutes   27.131083438609156%   9020/33246 TOTALS: [434, 3708, 40, 223]\n",
            "ETA: 14 minutes   27.191241051555075%   9040/33246 TOTALS: [435, 3713, 40, 223]\n",
            "ETA: 14 minutes   27.251398664500993%   9060/33246 TOTALS: [435, 3720, 40, 223]\n",
            "ETA: 15 minutes   27.311556277446915%   9080/33246 TOTALS: [437, 3728, 41, 225]\n",
            "ETA: 14 minutes   27.37171389039283%   9100/33246 TOTALS: [439, 3734, 41, 225]\n",
            "ETA: 15 minutes   27.431871503338744%   9120/33246 TOTALS: [439, 3746, 42, 226]\n",
            "ETA: 13 minutes   27.492029116284666%   9140/33246 TOTALS: [441, 3748, 42, 226]\n",
            "ETA: 14 minutes   27.55218672923058%   9160/33246 TOTALS: [442, 3759, 42, 226]\n",
            "ETA: 14 minutes   27.612344342176502%   9180/33246 TOTALS: [442, 3768, 42, 226]\n",
            "ETA: 14 minutes   27.67250195512242%   9200/33246 TOTALS: [443, 3774, 42, 226]\n",
            "ETA: 15 minutes   27.732659568068343%   9220/33246 TOTALS: [445, 3782, 42, 227]\n",
            "ETA: 14 minutes   27.792817181014257%   9240/33246 TOTALS: [446, 3794, 42, 227]\n",
            "ETA: 14 minutes   27.85297479396018%   9260/33246 TOTALS: [447, 3800, 42, 227]\n",
            "ETA: 15 minutes   27.913132406906094%   9280/33246 TOTALS: [448, 3810, 42, 228]\n",
            "ETA: 14 minutes   27.97329001985201%   9300/33246 TOTALS: [448, 3820, 42, 228]\n",
            "ETA: 14 minutes   28.03344763279793%   9320/33246 TOTALS: [448, 3827, 42, 229]\n",
            "ETA: 14 minutes   28.093605245743845%   9340/33246 TOTALS: [449, 3834, 42, 230]\n",
            "ETA: 14 minutes   28.153762858689767%   9360/33246 TOTALS: [451, 3841, 42, 231]\n",
            "ETA: 14 minutes   28.213920471635685%   9380/33246 TOTALS: [452, 3850, 42, 231]\n",
            "ETA: 14 minutes   28.274078084581607%   9400/33246 TOTALS: [452, 3856, 42, 231]\n",
            "ETA: 14 minutes   28.33423569752752%   9420/33246 TOTALS: [453, 3865, 42, 231]\n",
            "ETA: 13 minutes   28.394393310473443%   9440/33246 TOTALS: [453, 3872, 42, 231]\n",
            "ETA: 14 minutes   28.454550923419358%   9460/33246 TOTALS: [454, 3878, 42, 233]\n",
            "ETA: 13 minutes   28.51470853636528%   9480/33246 TOTALS: [454, 3886, 42, 233]\n",
            "ETA: 15 minutes   28.574866149311195%   9500/33246 TOTALS: [457, 3895, 42, 234]\n",
            "ETA: 14 minutes   28.635023762257113%   9520/33246 TOTALS: [458, 3902, 42, 236]\n",
            "ETA: 13 minutes   28.69518137520303%   9540/33246 TOTALS: [458, 3906, 43, 237]\n",
            "ETA: 15 minutes   28.75533898814895%   9560/33246 TOTALS: [459, 3919, 43, 237]\n",
            "ETA: 15 minutes   28.81549660109487%   9580/33246 TOTALS: [460, 3928, 43, 238]\n",
            "ETA: 13 minutes   28.875654214040786%   9600/33246 TOTALS: [461, 3932, 43, 238]\n",
            "ETA: 14 minutes   28.935811826986708%   9620/33246 TOTALS: [462, 3937, 44, 239]\n",
            "ETA: 13 minutes   28.995969439932622%   9640/33246 TOTALS: [465, 3941, 44, 239]\n",
            "ETA: 15 minutes   29.056127052878544%   9660/33246 TOTALS: [469, 3948, 44, 239]\n",
            "ETA: 14 minutes   29.11628466582446%   9680/33246 TOTALS: [470, 3955, 44, 240]\n",
            "ETA: 14 minutes   29.176442278770377%   9700/33246 TOTALS: [472, 3960, 44, 240]\n",
            "ETA: 14 minutes   29.236599891716295%   9720/33246 TOTALS: [474, 3967, 44, 240]\n",
            "ETA: 14 minutes   29.296757504662214%   9740/33246 TOTALS: [474, 3976, 44, 240]\n",
            "ETA: 15 minutes   29.356915117608136%   9760/33246 TOTALS: [477, 3984, 44, 240]\n",
            "ETA: 14 minutes   29.41707273055405%   9780/33246 TOTALS: [478, 3994, 44, 240]\n",
            "ETA: 15 minutes   29.477230343499972%   9800/33246 TOTALS: [479, 4007, 44, 240]\n",
            "ETA: 15 minutes   29.537387956445887%   9820/33246 TOTALS: [480, 4021, 44, 240]\n",
            "ETA: 13 minutes   29.59754556939181%   9840/33246 TOTALS: [480, 4027, 44, 240]\n",
            "ETA: 15 minutes   29.657703182337723%   9860/33246 TOTALS: [481, 4038, 44, 240]\n",
            "ETA: 15 minutes   29.71786079528364%   9880/33246 TOTALS: [483, 4050, 44, 240]\n",
            "ETA: 13 minutes   29.778018408229563%   9900/33246 TOTALS: [484, 4057, 44, 240]\n",
            "ETA: 15 minutes   29.838176021175478%   9920/33246 TOTALS: [485, 4063, 44, 242]\n",
            "ETA: 15 minutes   29.8983336341214%   9940/33246 TOTALS: [489, 4075, 44, 242]\n",
            "ETA: 13 minutes   29.958491247067315%   9960/33246 TOTALS: [489, 4084, 44, 242]\n",
            "ETA: 14 minutes   30.018648860013236%   9980/33246 TOTALS: [491, 4090, 44, 243]\n",
            "ETA: 14 minutes   30.07880647295915%   10000/33246 TOTALS: [491, 4098, 44, 243]\n",
            "ETA: 14 minutes   30.138964085905073%   10020/33246 TOTALS: [492, 4107, 44, 243]\n",
            "ETA: 13 minutes   30.199121698850988%   10040/33246 TOTALS: [492, 4115, 44, 243]\n",
            "ETA: 14 minutes   30.25927931179691%   10060/33246 TOTALS: [494, 4122, 44, 244]\n",
            "ETA: 14 minutes   30.319436924742828%   10080/33246 TOTALS: [494, 4128, 44, 244]\n",
            "ETA: 15 minutes   30.379594537688742%   10100/33246 TOTALS: [495, 4138, 44, 245]\n",
            "ETA: 14 minutes   30.439752150634664%   10120/33246 TOTALS: [496, 4145, 44, 246]\n",
            "ETA: 12 minutes   30.49990976358058%   10140/33246 TOTALS: [496, 4149, 44, 246]\n",
            "ETA: 14 minutes   30.5600673765265%   10160/33246 TOTALS: [497, 4156, 44, 248]\n",
            "ETA: 13 minutes   30.620224989472415%   10180/33246 TOTALS: [497, 4164, 44, 248]\n",
            "ETA: 14 minutes   30.680382602418337%   10200/33246 TOTALS: [499, 4172, 44, 248]\n",
            "ETA: 13 minutes   30.740540215364256%   10220/33246 TOTALS: [501, 4176, 44, 248]\n",
            "ETA: 14 minutes   30.800697828310174%   10240/33246 TOTALS: [501, 4187, 45, 249]\n",
            "ETA: 14 minutes   30.860855441256092%   10260/33246 TOTALS: [504, 4195, 45, 249]\n",
            "ETA: 13 minutes   30.921013054202007%   10280/33246 TOTALS: [505, 4200, 45, 251]\n",
            "ETA: 13 minutes   30.98117066714793%   10300/33246 TOTALS: [505, 4208, 46, 251]\n",
            "ETA: 13 minutes   31.041328280093843%   10320/33246 TOTALS: [506, 4216, 46, 251]\n",
            "ETA: 14 minutes   31.101485893039765%   10340/33246 TOTALS: [506, 4223, 46, 253]\n",
            "ETA: 14 minutes   31.16164350598568%   10360/33246 TOTALS: [506, 4233, 46, 254]\n",
            "ETA: 14 minutes   31.2218011189316%   10380/33246 TOTALS: [507, 4241, 46, 255]\n",
            "ETA: 15 minutes   31.28195873187752%   10400/33246 TOTALS: [508, 4252, 46, 255]\n",
            "ETA: 13 minutes   31.342116344823438%   10420/33246 TOTALS: [509, 4257, 46, 257]\n",
            "ETA: 14 minutes   31.402273957769356%   10440/33246 TOTALS: [511, 4269, 46, 257]\n",
            "ETA: 14 minutes   31.46243157071527%   10460/33246 TOTALS: [514, 4275, 46, 258]\n",
            "ETA: 14 minutes   31.522589183661193%   10480/33246 TOTALS: [515, 4285, 46, 258]\n",
            "ETA: 13 minutes   31.582746796607108%   10500/33246 TOTALS: [515, 4295, 46, 258]\n",
            "ETA: 14 minutes   31.64290440955303%   10520/33246 TOTALS: [516, 4305, 46, 258]\n",
            "ETA: 14 minutes   31.703062022498944%   10540/33246 TOTALS: [517, 4314, 47, 259]\n",
            "ETA: 13 minutes   31.763219635444866%   10560/33246 TOTALS: [518, 4324, 47, 259]\n",
            "ETA: 13 minutes   31.823377248390784%   10580/33246 TOTALS: [518, 4331, 47, 259]\n",
            "ETA: 14 minutes   31.883534861336706%   10600/33246 TOTALS: [519, 4341, 47, 259]\n",
            "ETA: 13 minutes   31.94369247428262%   10620/33246 TOTALS: [520, 4346, 47, 259]\n",
            "ETA: 14 minutes   32.00385008722854%   10640/33246 TOTALS: [521, 4354, 47, 260]\n",
            "ETA: 14 minutes   32.06400770017446%   10660/33246 TOTALS: [521, 4368, 47, 260]\n",
            "ETA: 14 minutes   32.12416531312037%   10680/33246 TOTALS: [522, 4376, 47, 261]\n",
            "ETA: 14 minutes   32.184322926066294%   10700/33246 TOTALS: [523, 4386, 47, 262]\n",
            "ETA: 13 minutes   32.24448053901221%   10720/33246 TOTALS: [523, 4394, 47, 263]\n",
            "ETA: 13 minutes   32.30463815195813%   10740/33246 TOTALS: [523, 4404, 47, 263]\n",
            "ETA: 14 minutes   32.364795764904045%   10760/33246 TOTALS: [523, 4415, 47, 263]\n",
            "ETA: 13 minutes   32.42495337784997%   10780/33246 TOTALS: [524, 4426, 47, 263]\n",
            "ETA: 13 minutes   32.48511099079588%   10800/33246 TOTALS: [524, 4432, 47, 264]\n",
            "ETA: 13 minutes   32.5452686037418%   10820/33246 TOTALS: [524, 4440, 48, 264]\n",
            "ETA: 14 minutes   32.605426216687725%   10840/33246 TOTALS: [524, 4448, 48, 268]\n",
            "ETA: 14 minutes   32.66558382963364%   10860/33246 TOTALS: [526, 4455, 48, 269]\n",
            "ETA: 14 minutes   32.72574144257956%   10880/33246 TOTALS: [526, 4464, 48, 270]\n",
            "ETA: 14 minutes   32.785899055525476%   10900/33246 TOTALS: [526, 4476, 48, 270]\n",
            "ETA: 14 minutes   32.8460566684714%   10920/33246 TOTALS: [528, 4485, 48, 271]\n",
            "ETA: 13 minutes   32.90621428141731%   10940/33246 TOTALS: [529, 4493, 48, 271]\n",
            "ETA: 14 minutes   32.966371894363235%   10960/33246 TOTALS: [530, 4505, 48, 271]\n",
            "ETA: 13 minutes   33.02652950730915%   10980/33246 TOTALS: [533, 4512, 48, 271]\n",
            "ETA: 13 minutes   33.08668712025507%   11000/33246 TOTALS: [534, 4520, 48, 272]\n",
            "ETA: 14 minutes   33.146844733200986%   11020/33246 TOTALS: [535, 4529, 48, 273]\n",
            "ETA: 13 minutes   33.2070023461469%   11040/33246 TOTALS: [536, 4536, 48, 273]\n",
            "ETA: 12 minutes   33.26715995909282%   11060/33246 TOTALS: [536, 4540, 48, 273]\n",
            "ETA: 14 minutes   33.32731757203874%   11080/33246 TOTALS: [537, 4553, 48, 273]\n",
            "ETA: 13 minutes   33.38747518498466%   11100/33246 TOTALS: [538, 4559, 48, 275]\n",
            "ETA: 13 minutes   33.447632797930574%   11120/33246 TOTALS: [540, 4564, 48, 276]\n",
            "ETA: 14 minutes   33.507790410876495%   11140/33246 TOTALS: [542, 4571, 48, 277]\n",
            "ETA: 13 minutes   33.56794802382241%   11160/33246 TOTALS: [543, 4580, 48, 277]\n",
            "ETA: 14 minutes   33.62810563676833%   11180/33246 TOTALS: [545, 4591, 48, 277]\n",
            "ETA: 13 minutes   33.688263249714254%   11200/33246 TOTALS: [546, 4600, 48, 277]\n",
            "ETA: 13 minutes   33.748420862660176%   11220/33246 TOTALS: [547, 4607, 48, 279]\n",
            "ETA: 12 minutes   33.80857847560609%   11240/33246 TOTALS: [547, 4613, 48, 279]\n",
            "ETA: 13 minutes   33.868736088552005%   11260/33246 TOTALS: [548, 4620, 48, 281]\n",
            "ETA: 14 minutes   33.92889370149793%   11280/33246 TOTALS: [550, 4632, 48, 281]\n",
            "ETA: 14 minutes   33.98905131444384%   11300/33246 TOTALS: [552, 4641, 48, 281]\n",
            "ETA: 13 minutes   34.04920892738976%   11320/33246 TOTALS: [557, 4647, 48, 281]\n",
            "ETA: 14 minutes   34.10936654033568%   11340/33246 TOTALS: [557, 4654, 48, 282]\n",
            "ETA: 12 minutes   34.1695241532816%   11360/33246 TOTALS: [557, 4660, 49, 282]\n",
            "ETA: 13 minutes   34.229681766227515%   11380/33246 TOTALS: [558, 4669, 49, 283]\n",
            "ETA: 13 minutes   34.289839379173436%   11400/33246 TOTALS: [559, 4677, 49, 285]\n",
            "ETA: 13 minutes   34.34999699211935%   11420/33246 TOTALS: [560, 4687, 49, 285]\n",
            "ETA: 13 minutes   34.410154605065266%   11440/33246 TOTALS: [561, 4691, 49, 287]\n",
            "ETA: 13 minutes   34.47031221801119%   11460/33246 TOTALS: [561, 4699, 49, 287]\n",
            "ETA: 13 minutes   34.5304698309571%   11480/33246 TOTALS: [561, 4708, 49, 287]\n",
            "ETA: 13 minutes   34.590627443903024%   11500/33246 TOTALS: [561, 4715, 50, 288]\n",
            "ETA: 13 minutes   34.650785056848946%   11520/33246 TOTALS: [561, 4726, 51, 289]\n",
            "ETA: 13 minutes   34.71094266979486%   11540/33246 TOTALS: [564, 4734, 51, 289]\n",
            "ETA: 13 minutes   34.77110028274078%   11560/33246 TOTALS: [564, 4743, 51, 289]\n",
            "ETA: 14 minutes   34.831257895686704%   11580/33246 TOTALS: [567, 4749, 51, 290]\n",
            "ETA: 13 minutes   34.89141550863262%   11600/33246 TOTALS: [567, 4758, 51, 290]\n",
            "ETA: 13 minutes   34.951573121578534%   11620/33246 TOTALS: [568, 4764, 51, 290]\n",
            "ETA: 12 minutes   35.011730734524455%   11640/33246 TOTALS: [568, 4770, 51, 291]\n",
            "ETA: 14 minutes   35.07188834747037%   11660/33246 TOTALS: [569, 4779, 51, 292]\n",
            "ETA: 13 minutes   35.13204596041629%   11680/33246 TOTALS: [570, 4788, 51, 293]\n",
            "ETA: 12 minutes   35.19220357336221%   11700/33246 TOTALS: [570, 4794, 51, 294]\n",
            "ETA: 12 minutes   35.25236118630813%   11720/33246 TOTALS: [570, 4802, 51, 294]\n",
            "ETA: 13 minutes   35.31251879925404%   11740/33246 TOTALS: [572, 4812, 51, 294]\n",
            "ETA: 13 minutes   35.372676412199965%   11760/33246 TOTALS: [573, 4822, 51, 294]\n",
            "ETA: 13 minutes   35.43283402514588%   11780/33246 TOTALS: [574, 4832, 51, 296]\n",
            "ETA: 12 minutes   35.4929916380918%   11800/33246 TOTALS: [576, 4839, 51, 296]\n",
            "ETA: 12 minutes   35.553149251037716%   11820/33246 TOTALS: [576, 4844, 51, 297]\n",
            "ETA: 13 minutes   35.61330686398364%   11840/33246 TOTALS: [578, 4854, 51, 297]\n",
            "ETA: 12 minutes   35.67346447692955%   11860/33246 TOTALS: [578, 4861, 51, 298]\n",
            "ETA: 14 minutes   35.733622089875475%   11880/33246 TOTALS: [578, 4871, 51, 298]\n",
            "ETA: 13 minutes   35.793779702821396%   11900/33246 TOTALS: [578, 4881, 52, 299]\n",
            "ETA: 13 minutes   35.85393731576731%   11920/33246 TOTALS: [581, 4889, 52, 299]\n",
            "ETA: 13 minutes   35.91409492871323%   11940/33246 TOTALS: [581, 4898, 52, 300]\n",
            "ETA: 13 minutes   35.97425254165915%   11960/33246 TOTALS: [581, 4909, 52, 300]\n",
            "ETA: 13 minutes   36.03441015460507%   11980/33246 TOTALS: [581, 4916, 53, 301]\n",
            "ETA: 13 minutes   36.094567767550984%   12000/33246 TOTALS: [581, 4923, 53, 302]\n",
            "ETA: 13 minutes   36.1547253804969%   12020/33246 TOTALS: [581, 4933, 53, 302]\n",
            "ETA: 13 minutes   36.21488299344282%   12040/33246 TOTALS: [583, 4940, 53, 303]\n",
            "ETA: 13 minutes   36.275040606388735%   12060/33246 TOTALS: [584, 4948, 53, 304]\n",
            "ETA: 12 minutes   36.33519821933466%   12080/33246 TOTALS: [584, 4958, 53, 304]\n",
            "ETA: 12 minutes   36.39535583228057%   12100/33246 TOTALS: [584, 4965, 53, 305]\n",
            "ETA: 14 minutes   36.455513445226494%   12120/33246 TOTALS: [584, 4980, 53, 306]\n",
            "ETA: 15 minutes   36.51567105817241%   12140/33246 TOTALS: [585, 4990, 53, 307]\n",
            "ETA: 13 minutes   36.57582867111833%   12160/33246 TOTALS: [585, 5000, 53, 307]\n",
            "ETA: 12 minutes   36.635986284064245%   12180/33246 TOTALS: [586, 5007, 53, 307]\n",
            "ETA: 12 minutes   36.69614389701017%   12200/33246 TOTALS: [587, 5015, 53, 309]\n",
            "ETA: 13 minutes   36.75630150995609%   12220/33246 TOTALS: [589, 5025, 53, 309]\n",
            "ETA: 12 minutes   36.816459122902%   12240/33246 TOTALS: [589, 5032, 53, 309]\n",
            "ETA: 12 minutes   36.876616735847925%   12260/33246 TOTALS: [590, 5038, 53, 309]\n",
            "ETA: 13 minutes   36.93677434879384%   12280/33246 TOTALS: [590, 5045, 53, 311]\n",
            "ETA: 13 minutes   36.99693196173976%   12300/33246 TOTALS: [591, 5053, 53, 312]\n",
            "ETA: 12 minutes   37.057089574685676%   12320/33246 TOTALS: [591, 5062, 53, 312]\n",
            "ETA: 12 minutes   37.1172471876316%   12340/33246 TOTALS: [591, 5072, 53, 312]\n",
            "ETA: 13 minutes   37.17740480057751%   12360/33246 TOTALS: [592, 5081, 53, 313]\n",
            "ETA: 12 minutes   37.237562413523435%   12380/33246 TOTALS: [593, 5085, 53, 313]\n",
            "ETA: 12 minutes   37.29772002646935%   12400/33246 TOTALS: [593, 5091, 53, 314]\n",
            "ETA: 13 minutes   37.357877639415264%   12420/33246 TOTALS: [594, 5100, 53, 314]\n",
            "ETA: 13 minutes   37.418035252361186%   12440/33246 TOTALS: [595, 5107, 53, 314]\n",
            "ETA: 12 minutes   37.4781928653071%   12460/33246 TOTALS: [596, 5111, 54, 314]\n",
            "ETA: 11 minutes   37.53835047825302%   12480/33246 TOTALS: [596, 5115, 54, 314]\n",
            "ETA: 12 minutes   37.59850809119894%   12500/33246 TOTALS: [597, 5123, 55, 314]\n",
            "ETA: 12 minutes   37.65866570414486%   12520/33246 TOTALS: [598, 5129, 55, 314]\n",
            "ETA: 13 minutes   37.71882331709078%   12540/33246 TOTALS: [598, 5140, 55, 315]\n",
            "ETA: 13 minutes   37.778980930036695%   12560/33246 TOTALS: [599, 5149, 55, 315]\n",
            "ETA: 13 minutes   37.83913854298262%   12580/33246 TOTALS: [602, 5159, 55, 315]\n",
            "ETA: 13 minutes   37.89929615592853%   12600/33246 TOTALS: [604, 5169, 55, 315]\n",
            "ETA: 13 minutes   37.959453768874454%   12620/33246 TOTALS: [604, 5179, 55, 316]\n",
            "ETA: 13 minutes   38.01961138182037%   12640/33246 TOTALS: [607, 5187, 55, 316]\n",
            "ETA: 14 minutes   38.07976899476629%   12660/33246 TOTALS: [608, 5198, 55, 317]\n",
            "ETA: 12 minutes   38.139926607712205%   12680/33246 TOTALS: [608, 5210, 55, 317]\n",
            "ETA: 13 minutes   38.20008422065813%   12700/33246 TOTALS: [609, 5219, 55, 318]\n",
            "ETA: 12 minutes   38.26024183360404%   12720/33246 TOTALS: [609, 5227, 55, 319]\n",
            "ETA: 12 minutes   38.32039944654996%   12740/33246 TOTALS: [609, 5234, 55, 321]\n",
            "ETA: 12 minutes   38.38055705949588%   12760/33246 TOTALS: [609, 5240, 55, 322]\n",
            "ETA: 13 minutes   38.44071467244179%   12780/33246 TOTALS: [609, 5253, 55, 324]\n",
            "ETA: 12 minutes   38.500872285387715%   12800/33246 TOTALS: [610, 5260, 56, 325]\n",
            "ETA: 12 minutes   38.56102989833363%   12820/33246 TOTALS: [610, 5268, 56, 326]\n",
            "ETA: 12 minutes   38.62118751127955%   12840/33246 TOTALS: [614, 5277, 56, 326]\n",
            "ETA: 12 minutes   38.681345124225466%   12860/33246 TOTALS: [614, 5289, 56, 326]\n",
            "ETA: 12 minutes   38.74150273717139%   12880/33246 TOTALS: [616, 5298, 56, 326]\n",
            "ETA: 12 minutes   38.80166035011731%   12900/33246 TOTALS: [616, 5305, 56, 326]\n",
            "ETA: 12 minutes   38.86181796306323%   12920/33246 TOTALS: [617, 5313, 56, 326]\n",
            "ETA: 12 minutes   38.921975576009146%   12940/33246 TOTALS: [619, 5318, 56, 326]\n",
            "ETA: 13 minutes   38.98213318895507%   12960/33246 TOTALS: [619, 5326, 56, 327]\n",
            "ETA: 13 minutes   39.04229080190098%   12980/33246 TOTALS: [619, 5334, 57, 327]\n",
            "ETA: 12 minutes   39.1024484148469%   13000/33246 TOTALS: [620, 5339, 57, 329]\n",
            "ETA: 12 minutes   39.16260602779282%   13020/33246 TOTALS: [620, 5349, 58, 329]\n",
            "ETA: 11 minutes   39.222763640738734%   13040/33246 TOTALS: [622, 5354, 58, 329]\n",
            "ETA: 12 minutes   39.282921253684655%   13060/33246 TOTALS: [624, 5361, 58, 329]\n",
            "ETA: 12 minutes   39.34307886663057%   13080/33246 TOTALS: [624, 5369, 58, 331]\n",
            "ETA: 12 minutes   39.40323647957649%   13100/33246 TOTALS: [625, 5375, 58, 331]\n",
            "ETA: 12 minutes   39.46339409252241%   13120/33246 TOTALS: [626, 5384, 58, 331]\n",
            "ETA: 13 minutes   39.52355170546833%   13140/33246 TOTALS: [628, 5392, 58, 333]\n",
            "ETA: 12 minutes   39.58370931841424%   13160/33246 TOTALS: [629, 5400, 58, 336]\n",
            "ETA: 13 minutes   39.64386693136016%   13180/33246 TOTALS: [632, 5409, 58, 336]\n",
            "ETA: 13 minutes   39.70402454430608%   13200/33246 TOTALS: [634, 5420, 58, 336]\n",
            "ETA: 12 minutes   39.764182157252%   13220/33246 TOTALS: [635, 5428, 58, 336]\n",
            "ETA: 12 minutes   39.824339770197916%   13240/33246 TOTALS: [635, 5437, 58, 339]\n",
            "ETA: 12 minutes   39.88449738314384%   13260/33246 TOTALS: [639, 5442, 58, 339]\n",
            "ETA: 12 minutes   39.94465499608976%   13280/33246 TOTALS: [639, 5448, 58, 340]\n",
            "ETA: 13 minutes   40.004812609035675%   13300/33246 TOTALS: [643, 5455, 58, 340]\n",
            "ETA: 12 minutes   40.064970221981596%   13320/33246 TOTALS: [643, 5462, 58, 341]\n",
            "ETA: 12 minutes   40.12512783492751%   13340/33246 TOTALS: [643, 5469, 58, 343]\n",
            "ETA: 11 minutes   40.18528544787343%   13360/33246 TOTALS: [644, 5478, 58, 343]\n",
            "ETA: 11 minutes   40.24544306081935%   13380/33246 TOTALS: [644, 5485, 58, 343]\n",
            "ETA: 12 minutes   40.30560067376526%   13400/33246 TOTALS: [644, 5496, 58, 343]\n",
            "ETA: 12 minutes   40.365758286711184%   13420/33246 TOTALS: [644, 5505, 58, 344]\n",
            "ETA: 12 minutes   40.4259158996571%   13440/33246 TOTALS: [645, 5513, 58, 345]\n",
            "ETA: 13 minutes   40.48607351260302%   13460/33246 TOTALS: [645, 5523, 58, 345]\n",
            "ETA: 12 minutes   40.546231125548935%   13480/33246 TOTALS: [645, 5532, 58, 345]\n",
            "ETA: 12 minutes   40.60638873849486%   13500/33246 TOTALS: [646, 5541, 58, 345]\n",
            "ETA: 12 minutes   40.66654635144077%   13520/33246 TOTALS: [646, 5551, 58, 346]\n",
            "ETA: 12 minutes   40.726703964386694%   13540/33246 TOTALS: [647, 5560, 58, 347]\n",
            "ETA: 12 minutes   40.78686157733261%   13560/33246 TOTALS: [648, 5569, 58, 347]\n",
            "ETA: 12 minutes   40.84701919027853%   13580/33246 TOTALS: [648, 5581, 58, 347]\n",
            "ETA: 12 minutes   40.90717680322445%   13600/33246 TOTALS: [649, 5588, 59, 348]\n",
            "ETA: 13 minutes   40.96733441617037%   13620/33246 TOTALS: [651, 5596, 59, 350]\n",
            "ETA: 12 minutes   41.02749202911629%   13640/33246 TOTALS: [651, 5607, 59, 351]\n",
            "ETA: 12 minutes   41.0876496420622%   13660/33246 TOTALS: [652, 5616, 59, 351]\n",
            "ETA: 12 minutes   41.147807255008125%   13680/33246 TOTALS: [652, 5626, 59, 351]\n",
            "ETA: 11 minutes   41.20796486795404%   13700/33246 TOTALS: [652, 5635, 59, 351]\n",
            "ETA: 11 minutes   41.26812248089996%   13720/33246 TOTALS: [654, 5640, 59, 352]\n",
            "ETA: 11 minutes   41.328280093845876%   13740/33246 TOTALS: [655, 5647, 59, 353]\n",
            "ETA: 12 minutes   41.38843770679179%   13760/33246 TOTALS: [656, 5653, 60, 354]\n",
            "ETA: 12 minutes   41.44859531973771%   13780/33246 TOTALS: [656, 5661, 60, 356]\n",
            "ETA: 11 minutes   41.50875293268363%   13800/33246 TOTALS: [657, 5668, 60, 356]\n",
            "ETA: 11 minutes   41.56891054562955%   13820/33246 TOTALS: [657, 5677, 61, 356]\n",
            "ETA: 11 minutes   41.629068158575464%   13840/33246 TOTALS: [657, 5688, 61, 356]\n",
            "ETA: 11 minutes   41.689225771521386%   13860/33246 TOTALS: [658, 5697, 61, 357]\n",
            "ETA: 12 minutes   41.7493833844673%   13880/33246 TOTALS: [660, 5705, 61, 357]\n",
            "ETA: 11 minutes   41.80954099741322%   13900/33246 TOTALS: [660, 5713, 61, 358]\n",
            "ETA: 11 minutes   41.86969861035914%   13920/33246 TOTALS: [661, 5717, 62, 358]\n",
            "ETA: 12 minutes   41.92985622330506%   13940/33246 TOTALS: [661, 5726, 63, 359]\n",
            "ETA: 12 minutes   41.99001383625098%   13960/33246 TOTALS: [662, 5736, 63, 360]\n",
            "ETA: 12 minutes   42.050171449196895%   13980/33246 TOTALS: [663, 5746, 63, 361]\n",
            "ETA: 11 minutes   42.11032906214282%   14000/33246 TOTALS: [664, 5753, 63, 362]\n",
            "ETA: 13 minutes   42.17048667508873%   14020/33246 TOTALS: [666, 5763, 63, 364]\n",
            "ETA: 12 minutes   42.230644288034654%   14040/33246 TOTALS: [667, 5774, 63, 365]\n",
            "ETA: 11 minutes   42.29080190098057%   14060/33246 TOTALS: [668, 5782, 63, 365]\n",
            "ETA: 12 minutes   42.35095951392649%   14080/33246 TOTALS: [669, 5795, 63, 365]\n",
            "ETA: 12 minutes   42.411117126872405%   14100/33246 TOTALS: [672, 5804, 63, 365]\n",
            "ETA: 12 minutes   42.47127473981833%   14120/33246 TOTALS: [672, 5819, 63, 365]\n",
            "ETA: 11 minutes   42.53143235276424%   14140/33246 TOTALS: [672, 5829, 63, 367]\n",
            "ETA: 12 minutes   42.591589965710156%   14160/33246 TOTALS: [674, 5837, 63, 368]\n",
            "ETA: 12 minutes   42.65174757865608%   14180/33246 TOTALS: [674, 5848, 63, 370]\n",
            "ETA: 12 minutes   42.71190519160199%   14200/33246 TOTALS: [675, 5857, 63, 371]\n",
            "ETA: 11 minutes   42.772062804547915%   14220/33246 TOTALS: [676, 5865, 63, 371]\n",
            "ETA: 12 minutes   42.83222041749383%   14240/33246 TOTALS: [677, 5875, 63, 372]\n",
            "ETA: 12 minutes   42.89237803043975%   14260/33246 TOTALS: [677, 5887, 63, 372]\n",
            "ETA: 12 minutes   42.95253564338567%   14280/33246 TOTALS: [679, 5896, 63, 372]\n",
            "ETA: 11 minutes   43.01269325633159%   14300/33246 TOTALS: [679, 5901, 63, 373]\n",
            "ETA: 11 minutes   43.07285086927751%   14320/33246 TOTALS: [679, 5911, 63, 374]\n",
            "ETA: 11 minutes   43.133008482223424%   14340/33246 TOTALS: [680, 5919, 63, 374]\n",
            "ETA: 11 minutes   43.193166095169346%   14360/33246 TOTALS: [680, 5929, 63, 375]\n",
            "ETA: 11 minutes   43.25332370811526%   14380/33246 TOTALS: [680, 5939, 63, 376]\n",
            "ETA: 12 minutes   43.31348132106118%   14400/33246 TOTALS: [680, 5948, 63, 378]\n",
            "ETA: 12 minutes   43.3736389340071%   14420/33246 TOTALS: [681, 5958, 64, 378]\n",
            "ETA: 11 minutes   43.43379654695302%   14440/33246 TOTALS: [681, 5965, 64, 378]\n",
            "ETA: 11 minutes   43.493954159898934%   14460/33246 TOTALS: [683, 5974, 64, 378]\n",
            "ETA: 11 minutes   43.554111772844855%   14480/33246 TOTALS: [683, 5983, 64, 378]\n",
            "ETA: 11 minutes   43.61426938579077%   14500/33246 TOTALS: [683, 5991, 64, 378]\n",
            "ETA: 11 minutes   43.67442699873669%   14520/33246 TOTALS: [685, 5996, 64, 378]\n",
            "ETA: 11 minutes   43.73458461168261%   14540/33246 TOTALS: [687, 5999, 64, 379]\n",
            "ETA: 11 minutes   43.79474222462852%   14560/33246 TOTALS: [689, 6010, 64, 379]\n",
            "ETA: 11 minutes   43.85489983757444%   14580/33246 TOTALS: [689, 6021, 65, 379]\n",
            "ETA: 11 minutes   43.915057450520365%   14600/33246 TOTALS: [691, 6029, 65, 379]\n",
            "ETA: 12 minutes   43.97521506346628%   14620/33246 TOTALS: [693, 6036, 65, 379]\n",
            "ETA: 10 minutes   44.0353726764122%   14640/33246 TOTALS: [693, 6044, 66, 379]\n",
            "ETA: 10 minutes   44.09553028935812%   14660/33246 TOTALS: [694, 6051, 66, 380]\n",
            "ETA: 11 minutes   44.15568790230404%   14680/33246 TOTALS: [695, 6057, 66, 380]\n",
            "ETA: 11 minutes   44.21584551524996%   14700/33246 TOTALS: [695, 6063, 66, 381]\n",
            "ETA: 11 minutes   44.276003128195875%   14720/33246 TOTALS: [695, 6069, 66, 382]\n",
            "ETA: 11 minutes   44.33616074114179%   14740/33246 TOTALS: [696, 6076, 66, 382]\n",
            "ETA: 12 minutes   44.39631835408771%   14760/33246 TOTALS: [697, 6087, 66, 383]\n",
            "ETA: 11 minutes   44.456475967033626%   14780/33246 TOTALS: [697, 6097, 66, 384]\n",
            "ETA: 11 minutes   44.51663357997955%   14800/33246 TOTALS: [698, 6106, 66, 384]\n",
            "ETA: 10 minutes   44.57679119292546%   14820/33246 TOTALS: [698, 6114, 66, 384]\n",
            "ETA: 11 minutes   44.636948805871384%   14840/33246 TOTALS: [699, 6123, 67, 386]\n",
            "ETA: 11 minutes   44.6971064188173%   14860/33246 TOTALS: [700, 6129, 67, 386]\n",
            "ETA: 11 minutes   44.75726403176322%   14880/33246 TOTALS: [701, 6141, 67, 386]\n",
            "ETA: 11 minutes   44.817421644709135%   14900/33246 TOTALS: [702, 6151, 67, 386]\n",
            "ETA: 12 minutes   44.87757925765506%   14920/33246 TOTALS: [704, 6161, 68, 386]\n",
            "ETA: 12 minutes   44.93773687060097%   14940/33246 TOTALS: [704, 6171, 68, 387]\n",
            "ETA: 11 minutes   44.997894483546894%   14960/33246 TOTALS: [705, 6179, 68, 387]\n",
            "ETA: 11 minutes   45.058052096492816%   14980/33246 TOTALS: [705, 6188, 68, 389]\n",
            "ETA: 11 minutes   45.11820970943873%   15000/33246 TOTALS: [706, 6195, 68, 390]\n",
            "ETA: 11 minutes   45.17836732238465%   15020/33246 TOTALS: [709, 6205, 68, 391]\n",
            "ETA: 11 minutes   45.23852493533057%   15040/33246 TOTALS: [711, 6211, 69, 393]\n",
            "ETA: 11 minutes   45.29868254827649%   15060/33246 TOTALS: [713, 6219, 69, 393]\n",
            "ETA: 11 minutes   45.3588401612224%   15080/33246 TOTALS: [717, 6224, 69, 395]\n",
            "ETA: 11 minutes   45.418997774168325%   15100/33246 TOTALS: [718, 6231, 69, 395]\n",
            "ETA: 11 minutes   45.47915538711424%   15120/33246 TOTALS: [719, 6238, 69, 396]\n",
            "ETA: 10 minutes   45.539313000060154%   15140/33246 TOTALS: [719, 6244, 69, 397]\n",
            "ETA: 10 minutes   45.599470613006076%   15160/33246 TOTALS: [720, 6250, 69, 397]\n",
            "ETA: 11 minutes   45.65962822595199%   15180/33246 TOTALS: [721, 6262, 69, 397]\n",
            "ETA: 11 minutes   45.71978583889791%   15200/33246 TOTALS: [721, 6272, 69, 398]\n",
            "ETA: 12 minutes   45.77994345184383%   15220/33246 TOTALS: [724, 6278, 69, 398]\n",
            "ETA: 11 minutes   45.84010106478975%   15240/33246 TOTALS: [724, 6286, 69, 398]\n",
            "ETA: 11 minutes   45.900258677735664%   15260/33246 TOTALS: [724, 6295, 69, 398]\n",
            "ETA: 10 minutes   45.960416290681586%   15280/33246 TOTALS: [724, 6302, 69, 398]\n",
            "ETA: 10 minutes   46.02057390362751%   15300/33246 TOTALS: [724, 6310, 70, 398]\n",
            "ETA: 11 minutes   46.08073151657342%   15320/33246 TOTALS: [725, 6322, 70, 398]\n",
            "ETA: 10 minutes   46.140889129519344%   15340/33246 TOTALS: [725, 6332, 70, 398]\n",
            "ETA: 10 minutes   46.20104674246526%   15360/33246 TOTALS: [726, 6339, 70, 398]\n",
            "ETA: 11 minutes   46.26120435541118%   15380/33246 TOTALS: [727, 6347, 70, 399]\n",
            "ETA: 11 minutes   46.321361968357095%   15400/33246 TOTALS: [728, 6357, 70, 400]\n",
            "ETA: 11 minutes   46.38151958130302%   15420/33246 TOTALS: [729, 6364, 70, 400]\n",
            "ETA: 10 minutes   46.44167719424893%   15440/33246 TOTALS: [730, 6370, 70, 401]\n",
            "ETA: 12 minutes   46.501834807194854%   15460/33246 TOTALS: [731, 6379, 70, 403]\n",
            "ETA: 11 minutes   46.56199242014077%   15480/33246 TOTALS: [734, 6388, 70, 403]\n",
            "ETA: 10 minutes   46.62215003308668%   15500/33246 TOTALS: [734, 6398, 70, 403]\n",
            "ETA: 10 minutes   46.682307646032605%   15520/33246 TOTALS: [735, 6407, 70, 403]\n",
            "ETA: 11 minutes   46.74246525897852%   15540/33246 TOTALS: [736, 6417, 70, 403]\n",
            "ETA: 11 minutes   46.80262287192444%   15560/33246 TOTALS: [737, 6424, 70, 403]\n",
            "ETA: 11 minutes   46.862780484870356%   15580/33246 TOTALS: [738, 6432, 70, 405]\n",
            "ETA: 10 minutes   46.92293809781628%   15600/33246 TOTALS: [738, 6441, 70, 406]\n",
            "ETA: 10 minutes   46.98309571076219%   15620/33246 TOTALS: [739, 6445, 70, 406]\n",
            "ETA: 10 minutes   47.043253323708115%   15640/33246 TOTALS: [741, 6450, 71, 406]\n",
            "ETA: 10 minutes   47.103410936654036%   15660/33246 TOTALS: [743, 6456, 71, 408]\n",
            "ETA: 11 minutes   47.16356854959996%   15680/33246 TOTALS: [746, 6465, 71, 408]\n",
            "ETA: 10 minutes   47.22372616254587%   15700/33246 TOTALS: [747, 6474, 71, 408]\n",
            "ETA: 10 minutes   47.28388377549179%   15720/33246 TOTALS: [749, 6482, 71, 408]\n",
            "ETA: 10 minutes   47.34404138843771%   15740/33246 TOTALS: [751, 6487, 72, 409]\n",
            "ETA: 10 minutes   47.404199001383624%   15760/33246 TOTALS: [752, 6496, 72, 410]\n",
            "ETA: 10 minutes   47.464356614329546%   15780/33246 TOTALS: [753, 6503, 72, 410]\n",
            "ETA: 10 minutes   47.52451422727546%   15800/33246 TOTALS: [754, 6512, 72, 410]\n",
            "ETA: 10 minutes   47.58467184022138%   15820/33246 TOTALS: [756, 6519, 72, 412]\n",
            "ETA: 11 minutes   47.6448294531673%   15840/33246 TOTALS: [757, 6530, 72, 412]\n",
            "ETA: 10 minutes   47.70498706611322%   15860/33246 TOTALS: [758, 6539, 72, 413]\n",
            "ETA: 10 minutes   47.765144679059134%   15880/33246 TOTALS: [759, 6544, 72, 413]\n",
            "ETA: 10 minutes   47.82530229200505%   15900/33246 TOTALS: [760, 6549, 72, 413]\n",
            "ETA: 11 minutes   47.88545990495097%   15920/33246 TOTALS: [762, 6557, 72, 413]\n",
            "ETA: 10 minutes   47.945617517896885%   15940/33246 TOTALS: [765, 6561, 72, 413]\n",
            "ETA: 10 minutes   48.00577513084281%   15960/33246 TOTALS: [766, 6568, 72, 413]\n",
            "ETA: 9 minutes   48.06593274378873%   15980/33246 TOTALS: [766, 6573, 72, 413]\n",
            "ETA: 10 minutes   48.12609035673464%   16000/33246 TOTALS: [767, 6580, 73, 413]\n",
            "ETA: 10 minutes   48.186247969680565%   16020/33246 TOTALS: [768, 6586, 73, 413]\n",
            "ETA: 10 minutes   48.24640558262649%   16040/33246 TOTALS: [769, 6592, 74, 414]\n",
            "ETA: 10 minutes   48.3065631955724%   16060/33246 TOTALS: [770, 6601, 74, 414]\n",
            "ETA: 10 minutes   48.366720808518316%   16080/33246 TOTALS: [770, 6609, 74, 414]\n",
            "ETA: 10 minutes   48.42687842146424%   16100/33246 TOTALS: [770, 6618, 74, 414]\n",
            "ETA: 10 minutes   48.48703603441015%   16120/33246 TOTALS: [771, 6629, 74, 414]\n",
            "ETA: 10 minutes   48.547193647356075%   16140/33246 TOTALS: [771, 6642, 74, 414]\n",
            "ETA: 10 minutes   48.60735126030199%   16160/33246 TOTALS: [771, 6649, 74, 415]\n",
            "ETA: 10 minutes   48.66750887324791%   16180/33246 TOTALS: [772, 6658, 74, 416]\n",
            "ETA: 10 minutes   48.727666486193826%   16200/33246 TOTALS: [773, 6663, 74, 417]\n",
            "ETA: 10 minutes   48.78782409913975%   16220/33246 TOTALS: [776, 6668, 74, 417]\n",
            "ETA: 10 minutes   48.84798171208566%   16240/33246 TOTALS: [778, 6676, 74, 417]\n",
            "ETA: 11 minutes   48.908139325031584%   16260/33246 TOTALS: [779, 6688, 74, 417]\n",
            "ETA: 10 minutes   48.9682969379775%   16280/33246 TOTALS: [781, 6694, 74, 417]\n",
            "ETA: 10 minutes   49.02845455092341%   16300/33246 TOTALS: [781, 6703, 74, 417]\n",
            "ETA: 10 minutes   49.088612163869335%   16320/33246 TOTALS: [782, 6708, 74, 418]\n",
            "ETA: 9 minutes   49.14876977681526%   16340/33246 TOTALS: [782, 6713, 74, 418]\n",
            "ETA: 10 minutes   49.20892738976118%   16360/33246 TOTALS: [782, 6724, 74, 419]\n",
            "ETA: 10 minutes   49.269085002707094%   16380/33246 TOTALS: [782, 6734, 75, 419]\n",
            "ETA: 11 minutes   49.329242615653015%   16400/33246 TOTALS: [783, 6744, 75, 420]\n",
            "ETA: 9 minutes   49.38940022859893%   16420/33246 TOTALS: [783, 6748, 75, 422]\n",
            "ETA: 10 minutes   49.44955784154485%   16440/33246 TOTALS: [783, 6756, 76, 424]\n",
            "ETA: 9 minutes   49.50971545449077%   16460/33246 TOTALS: [785, 6763, 76, 424]\n",
            "ETA: 10 minutes   49.56987306743668%   16480/33246 TOTALS: [788, 6772, 76, 424]\n",
            "ETA: 11 minutes   49.6300306803826%   16500/33246 TOTALS: [788, 6784, 76, 428]\n",
            "ETA: 10 minutes   49.69018829332852%   16520/33246 TOTALS: [790, 6790, 76, 429]\n",
            "ETA: 11 minutes   49.75034590627444%   16540/33246 TOTALS: [791, 6804, 77, 429]\n",
            "ETA: 10 minutes   49.810503519220354%   16560/33246 TOTALS: [791, 6811, 77, 430]\n",
            "ETA: 10 minutes   49.870661132166276%   16580/33246 TOTALS: [794, 6817, 78, 430]\n",
            "ETA: 10 minutes   49.93081874511219%   16600/33246 TOTALS: [796, 6824, 79, 430]\n",
            "ETA: 10 minutes   49.99097635805811%   16620/33246 TOTALS: [798, 6833, 79, 430]\n",
            "ETA: 10 minutes   50.051133971004035%   16640/33246 TOTALS: [799, 6841, 79, 430]\n",
            "ETA: 9 minutes   50.11129158394995%   16660/33246 TOTALS: [800, 6849, 79, 430]\n",
            "ETA: 9 minutes   50.171449196895864%   16680/33246 TOTALS: [801, 6854, 79, 430]\n",
            "ETA: 11 minutes   50.231606809841786%   16700/33246 TOTALS: [802, 6866, 80, 431]\n",
            "ETA: 9 minutes   50.2917644227877%   16720/33246 TOTALS: [803, 6874, 80, 431]\n",
            "ETA: 9 minutes   50.35192203573362%   16740/33246 TOTALS: [803, 6881, 80, 432]\n",
            "ETA: 10 minutes   50.412079648679544%   16760/33246 TOTALS: [803, 6895, 81, 432]\n",
            "ETA: 10 minutes   50.472237261625466%   16780/33246 TOTALS: [803, 6903, 81, 433]\n",
            "ETA: 9 minutes   50.532394874571374%   16800/33246 TOTALS: [803, 6909, 81, 433]\n",
            "ETA: 9 minutes   50.592552487517295%   16820/33246 TOTALS: [804, 6915, 81, 433]\n",
            "ETA: 10 minutes   50.65271010046322%   16840/33246 TOTALS: [804, 6924, 81, 434]\n",
            "ETA: 10 minutes   50.712867713409125%   16860/33246 TOTALS: [806, 6929, 81, 436]\n",
            "ETA: 11 minutes   50.77302532635505%   16880/33246 TOTALS: [808, 6940, 81, 437]\n",
            "ETA: 10 minutes   50.83318293930097%   16900/33246 TOTALS: [808, 6949, 82, 437]\n",
            "ETA: 10 minutes   50.89334055224689%   16920/33246 TOTALS: [812, 6956, 82, 439]\n",
            "ETA: 10 minutes   50.9534981651928%   16940/33246 TOTALS: [813, 6962, 82, 440]\n",
            "ETA: 9 minutes   51.01365577813872%   16960/33246 TOTALS: [813, 6968, 83, 441]\n",
            "ETA: 10 minutes   51.07381339108464%   16980/33246 TOTALS: [815, 6978, 83, 442]\n",
            "ETA: 10 minutes   51.13397100403056%   17000/33246 TOTALS: [816, 6986, 83, 442]\n",
            "ETA: 10 minutes   51.19412861697648%   17020/33246 TOTALS: [819, 6993, 83, 443]\n",
            "ETA: 10 minutes   51.2542862299224%   17040/33246 TOTALS: [820, 7004, 83, 443]\n",
            "ETA: 9 minutes   51.314443842868315%   17060/33246 TOTALS: [821, 7008, 83, 444]\n",
            "ETA: 9 minutes   51.37460145581423%   17080/33246 TOTALS: [823, 7013, 84, 445]\n",
            "ETA: 10 minutes   51.43475906876015%   17100/33246 TOTALS: [824, 7022, 85, 446]\n",
            "ETA: 10 minutes   51.49491668170607%   17120/33246 TOTALS: [824, 7031, 85, 448]\n",
            "ETA: 10 minutes   51.555074294651995%   17140/33246 TOTALS: [825, 7042, 85, 448]\n",
            "ETA: 9 minutes   51.6152319075979%   17160/33246 TOTALS: [826, 7050, 85, 448]\n",
            "ETA: 10 minutes   51.675389520543824%   17180/33246 TOTALS: [827, 7060, 85, 448]\n",
            "ETA: 10 minutes   51.735547133489746%   17200/33246 TOTALS: [827, 7069, 85, 448]\n",
            "ETA: 10 minutes   51.79570474643567%   17220/33246 TOTALS: [828, 7080, 85, 448]\n",
            "ETA: 9 minutes   51.855862359381575%   17240/33246 TOTALS: [828, 7088, 85, 448]\n",
            "ETA: 9 minutes   51.9160199723275%   17260/33246 TOTALS: [829, 7095, 85, 448]\n",
            "ETA: 9 minutes   51.97617758527342%   17280/33246 TOTALS: [830, 7101, 85, 448]\n",
            "ETA: 10 minutes   52.036335198219334%   17300/33246 TOTALS: [830, 7111, 85, 450]\n",
            "ETA: 9 minutes   52.09649281116525%   17320/33246 TOTALS: [830, 7121, 85, 450]\n",
            "ETA: 9 minutes   52.15665042411117%   17340/33246 TOTALS: [831, 7128, 85, 450]\n",
            "ETA: 10 minutes   52.21680803705709%   17360/33246 TOTALS: [832, 7139, 85, 452]\n",
            "ETA: 9 minutes   52.27696565000301%   17380/33246 TOTALS: [832, 7149, 85, 452]\n",
            "ETA: 9 minutes   52.33712326294893%   17400/33246 TOTALS: [833, 7157, 85, 453]\n",
            "ETA: 10 minutes   52.39728087589485%   17420/33246 TOTALS: [835, 7166, 86, 454]\n",
            "ETA: 10 minutes   52.45743848884076%   17440/33246 TOTALS: [836, 7177, 86, 454]\n",
            "ETA: 10 minutes   52.51759610178668%   17460/33246 TOTALS: [837, 7186, 87, 454]\n",
            "ETA: 9 minutes   52.5777537147326%   17480/33246 TOTALS: [837, 7193, 87, 454]\n",
            "ETA: 9 minutes   52.63791132767852%   17500/33246 TOTALS: [838, 7202, 87, 455]\n",
            "ETA: 10 minutes   52.69806894062443%   17520/33246 TOTALS: [838, 7215, 87, 455]\n",
            "ETA: 9 minutes   52.75822655357035%   17540/33246 TOTALS: [840, 7219, 87, 455]\n",
            "ETA: 10 minutes   52.818384166516275%   17560/33246 TOTALS: [842, 7227, 87, 455]\n",
            "ETA: 9 minutes   52.878541779462196%   17580/33246 TOTALS: [842, 7237, 88, 455]\n",
            "ETA: 9 minutes   52.938699392408104%   17600/33246 TOTALS: [844, 7243, 88, 455]\n",
            "ETA: 9 minutes   52.998857005354026%   17620/33246 TOTALS: [844, 7254, 88, 455]\n",
            "ETA: 9 minutes   53.05901461829995%   17640/33246 TOTALS: [844, 7263, 88, 456]\n",
            "ETA: 10 minutes   53.11917223124586%   17660/33246 TOTALS: [846, 7276, 89, 456]\n",
            "ETA: 9 minutes   53.179329844191784%   17680/33246 TOTALS: [847, 7284, 89, 458]\n",
            "ETA: 9 minutes   53.2394874571377%   17700/33246 TOTALS: [850, 7291, 89, 458]\n",
            "ETA: 9 minutes   53.29964507008362%   17720/33246 TOTALS: [851, 7301, 89, 459]\n",
            "ETA: 9 minutes   53.359802683029535%   17740/33246 TOTALS: [851, 7308, 89, 459]\n",
            "ETA: 9 minutes   53.41996029597546%   17760/33246 TOTALS: [853, 7315, 89, 459]\n",
            "ETA: 9 minutes   53.48011790892138%   17780/33246 TOTALS: [853, 7321, 89, 460]\n",
            "ETA: 9 minutes   53.5402755218673%   17800/33246 TOTALS: [855, 7329, 89, 460]\n",
            "ETA: 9 minutes   53.60043313481321%   17820/33246 TOTALS: [855, 7340, 89, 460]\n",
            "ETA: 9 minutes   53.66059074775913%   17840/33246 TOTALS: [855, 7349, 89, 461]\n",
            "ETA: 9 minutes   53.72074836070505%   17860/33246 TOTALS: [855, 7358, 89, 461]\n",
            "ETA: 9 minutes   53.78090597365096%   17880/33246 TOTALS: [856, 7365, 89, 461]\n",
            "ETA: 10 minutes   53.84106358659688%   17900/33246 TOTALS: [856, 7376, 89, 462]\n",
            "ETA: 9 minutes   53.9012211995428%   17920/33246 TOTALS: [856, 7386, 89, 464]\n",
            "ETA: 9 minutes   53.961378812488725%   17940/33246 TOTALS: [858, 7393, 89, 464]\n",
            "ETA: 9 minutes   54.02153642543463%   17960/33246 TOTALS: [858, 7402, 89, 464]\n",
            "ETA: 8 minutes   54.081694038380554%   17980/33246 TOTALS: [858, 7405, 89, 465]\n",
            "ETA: 8 minutes   54.141851651326476%   18000/33246 TOTALS: [858, 7409, 89, 466]\n",
            "ETA: 8 minutes   54.20200926427239%   18020/33246 TOTALS: [860, 7415, 90, 466]\n",
            "ETA: 9 minutes   54.26216687721831%   18040/33246 TOTALS: [862, 7423, 90, 466]\n",
            "ETA: 9 minutes   54.322324490164235%   18060/33246 TOTALS: [862, 7429, 90, 467]\n",
            "ETA: 9 minutes   54.38248210311015%   18080/33246 TOTALS: [863, 7437, 90, 467]\n",
            "ETA: 8 minutes   54.442639716056064%   18100/33246 TOTALS: [864, 7443, 90, 467]\n",
            "ETA: 9 minutes   54.502797329001986%   18120/33246 TOTALS: [866, 7451, 90, 468]\n",
            "ETA: 9 minutes   54.56295494194791%   18140/33246 TOTALS: [868, 7460, 90, 468]\n",
            "ETA: 9 minutes   54.62311255489383%   18160/33246 TOTALS: [868, 7470, 90, 468]\n",
            "ETA: 9 minutes   54.68327016783974%   18180/33246 TOTALS: [868, 7480, 90, 468]\n",
            "ETA: 9 minutes   54.74342778078566%   18200/33246 TOTALS: [869, 7490, 90, 470]\n",
            "ETA: 10 minutes   54.80358539373158%   18220/33246 TOTALS: [870, 7499, 90, 471]\n",
            "ETA: 9 minutes   54.86374300667749%   18240/33246 TOTALS: [871, 7509, 91, 471]\n",
            "ETA: 9 minutes   54.92390061962341%   18260/33246 TOTALS: [873, 7514, 91, 471]\n",
            "ETA: 9 minutes   54.98405823256933%   18280/33246 TOTALS: [874, 7523, 91, 471]\n",
            "ETA: 9 minutes   55.044215845515254%   18300/33246 TOTALS: [874, 7529, 91, 473]\n",
            "ETA: 9 minutes   55.10437345846116%   18320/33246 TOTALS: [877, 7537, 91, 473]\n",
            "ETA: 9 minutes   55.16453107140708%   18340/33246 TOTALS: [878, 7545, 91, 473]\n",
            "ETA: 8 minutes   55.224688684353005%   18360/33246 TOTALS: [879, 7549, 92, 473]\n",
            "ETA: 9 minutes   55.28484629729893%   18380/33246 TOTALS: [880, 7559, 92, 473]\n",
            "ETA: 8 minutes   55.34500391024484%   18400/33246 TOTALS: [880, 7568, 92, 473]\n",
            "ETA: 8 minutes   55.40516152319076%   18420/33246 TOTALS: [880, 7576, 92, 473]\n",
            "ETA: 8 minutes   55.465319136136685%   18440/33246 TOTALS: [881, 7582, 92, 473]\n",
            "ETA: 9 minutes   55.52547674908259%   18460/33246 TOTALS: [883, 7591, 92, 474]\n",
            "ETA: 9 minutes   55.585634362028514%   18480/33246 TOTALS: [884, 7599, 92, 476]\n",
            "ETA: 8 minutes   55.645791974974436%   18500/33246 TOTALS: [885, 7603, 92, 476]\n",
            "ETA: 9 minutes   55.70594958792036%   18520/33246 TOTALS: [885, 7612, 92, 477]\n",
            "ETA: 8 minutes   55.766107200866266%   18540/33246 TOTALS: [885, 7615, 92, 478]\n",
            "ETA: 8 minutes   55.82626481381219%   18560/33246 TOTALS: [885, 7623, 92, 478]\n",
            "ETA: 9 minutes   55.88642242675811%   18580/33246 TOTALS: [887, 7630, 92, 479]\n",
            "ETA: 9 minutes   55.94658003970402%   18600/33246 TOTALS: [887, 7636, 92, 481]\n",
            "ETA: 8 minutes   56.00673765264994%   18620/33246 TOTALS: [887, 7644, 92, 482]\n",
            "ETA: 8 minutes   56.06689526559586%   18640/33246 TOTALS: [888, 7649, 92, 482]\n",
            "ETA: 8 minutes   56.12705287854178%   18660/33246 TOTALS: [891, 7654, 92, 482]\n",
            "ETA: 8 minutes   56.18721049148769%   18680/33246 TOTALS: [891, 7661, 92, 482]\n",
            "ETA: 9 minutes   56.24736810443361%   18700/33246 TOTALS: [892, 7673, 92, 482]\n",
            "ETA: 8 minutes   56.307525717379534%   18720/33246 TOTALS: [892, 7678, 92, 482]\n",
            "ETA: 8 minutes   56.367683330325455%   18740/33246 TOTALS: [893, 7684, 93, 482]\n",
            "ETA: 9 minutes   56.42784094327137%   18760/33246 TOTALS: [894, 7694, 93, 483]\n",
            "ETA: 8 minutes   56.48799855621729%   18780/33246 TOTALS: [895, 7701, 93, 484]\n",
            "ETA: 9 minutes   56.548156169163214%   18800/33246 TOTALS: [895, 7711, 94, 484]\n",
            "ETA: 8 minutes   56.60831378210912%   18820/33246 TOTALS: [895, 7718, 94, 484]\n",
            "ETA: 9 minutes   56.66847139505504%   18840/33246 TOTALS: [897, 7729, 94, 484]\n",
            "ETA: 9 minutes   56.728629008000965%   18860/33246 TOTALS: [899, 7735, 95, 484]\n",
            "ETA: 9 minutes   56.78878662094689%   18880/33246 TOTALS: [899, 7744, 95, 486]\n",
            "ETA: 9 minutes   56.848944233892794%   18900/33246 TOTALS: [900, 7754, 95, 486]\n",
            "ETA: 8 minutes   56.909101846838716%   18920/33246 TOTALS: [900, 7762, 95, 486]\n",
            "ETA: 8 minutes   56.96925945978464%   18940/33246 TOTALS: [900, 7768, 95, 486]\n",
            "ETA: 9 minutes   57.02941707273056%   18960/33246 TOTALS: [901, 7775, 95, 487]\n",
            "ETA: 8 minutes   57.08957468567647%   18980/33246 TOTALS: [902, 7779, 95, 488]\n",
            "ETA: 8 minutes   57.14973229862239%   19000/33246 TOTALS: [904, 7787, 95, 488]\n",
            "ETA: 8 minutes   57.20988991156831%   19020/33246 TOTALS: [905, 7795, 95, 488]\n",
            "ETA: 8 minutes   57.270047524514226%   19040/33246 TOTALS: [906, 7803, 95, 488]\n",
            "ETA: 8 minutes   57.33020513746014%   19060/33246 TOTALS: [906, 7809, 95, 488]\n",
            "ETA: 8 minutes   57.39036275040606%   19080/33246 TOTALS: [907, 7817, 95, 488]\n",
            "ETA: 8 minutes   57.450520363351984%   19100/33246 TOTALS: [909, 7826, 95, 488]\n",
            "ETA: 8 minutes   57.5106779762979%   19120/33246 TOTALS: [909, 7837, 95, 489]\n",
            "ETA: 8 minutes   57.57083558924382%   19140/33246 TOTALS: [910, 7842, 95, 489]\n",
            "ETA: 9 minutes   57.63099320218974%   19160/33246 TOTALS: [910, 7851, 95, 490]\n",
            "ETA: 8 minutes   57.69115081513565%   19180/33246 TOTALS: [911, 7861, 95, 490]\n",
            "ETA: 8 minutes   57.75130842808157%   19200/33246 TOTALS: [912, 7868, 96, 491]\n",
            "ETA: 8 minutes   57.811466041027494%   19220/33246 TOTALS: [912, 7876, 96, 491]\n",
            "ETA: 8 minutes   57.871623653973415%   19240/33246 TOTALS: [914, 7884, 96, 491]\n",
            "ETA: 8 minutes   57.93178126691932%   19260/33246 TOTALS: [914, 7893, 96, 492]\n",
            "ETA: 9 minutes   57.991938879865245%   19280/33246 TOTALS: [914, 7902, 97, 493]\n",
            "ETA: 8 minutes   58.05209649281117%   19300/33246 TOTALS: [915, 7909, 97, 493]\n",
            "ETA: 8 minutes   58.11225410575709%   19320/33246 TOTALS: [917, 7917, 97, 494]\n",
            "ETA: 8 minutes   58.172411718702996%   19340/33246 TOTALS: [917, 7923, 97, 495]\n",
            "ETA: 8 minutes   58.23256933164892%   19360/33246 TOTALS: [917, 7934, 97, 495]\n",
            "ETA: 8 minutes   58.29272694459484%   19380/33246 TOTALS: [918, 7944, 97, 495]\n",
            "ETA: 8 minutes   58.352884557540754%   19400/33246 TOTALS: [919, 7955, 97, 495]\n",
            "ETA: 8 minutes   58.413042170486676%   19420/33246 TOTALS: [920, 7962, 97, 495]\n",
            "ETA: 7 minutes   58.47319978343259%   19440/33246 TOTALS: [920, 7966, 97, 495]\n",
            "ETA: 8 minutes   58.53335739637851%   19460/33246 TOTALS: [920, 7976, 97, 496]\n",
            "ETA: 8 minutes   58.59351500932443%   19480/33246 TOTALS: [921, 7984, 97, 496]\n",
            "ETA: 8 minutes   58.65367262227035%   19500/33246 TOTALS: [921, 7994, 97, 496]\n",
            "ETA: 8 minutes   58.71383023521627%   19520/33246 TOTALS: [922, 8004, 98, 496]\n",
            "ETA: 8 minutes   58.77398784816219%   19540/33246 TOTALS: [924, 8011, 98, 498]\n",
            "ETA: 8 minutes   58.8341454611081%   19560/33246 TOTALS: [924, 8023, 98, 498]\n",
            "ETA: 8 minutes   58.89430307405402%   19580/33246 TOTALS: [924, 8028, 98, 499]\n",
            "ETA: 8 minutes   58.954460686999944%   19600/33246 TOTALS: [924, 8036, 99, 499]\n",
            "ETA: 8 minutes   59.01461829994585%   19620/33246 TOTALS: [925, 8042, 99, 500]\n",
            "ETA: 8 minutes   59.07477591289177%   19640/33246 TOTALS: [925, 8052, 99, 500]\n",
            "ETA: 8 minutes   59.134933525837695%   19660/33246 TOTALS: [926, 8059, 99, 500]\n",
            "ETA: 8 minutes   59.19509113878362%   19680/33246 TOTALS: [927, 8066, 99, 500]\n",
            "ETA: 8 minutes   59.255248751729525%   19700/33246 TOTALS: [927, 8076, 100, 500]\n",
            "ETA: 9 minutes   59.31540636467545%   19720/33246 TOTALS: [928, 8089, 100, 500]\n",
            "ETA: 8 minutes   59.37556397762137%   19740/33246 TOTALS: [931, 8098, 100, 500]\n",
            "ETA: 7 minutes   59.43572159056728%   19760/33246 TOTALS: [931, 8105, 100, 501]\n",
            "ETA: 8 minutes   59.495879203513205%   19780/33246 TOTALS: [933, 8113, 100, 502]\n",
            "ETA: 8 minutes   59.55603681645913%   19800/33246 TOTALS: [934, 8118, 100, 502]\n",
            "ETA: 7 minutes   59.61619442940504%   19820/33246 TOTALS: [935, 8123, 100, 502]\n",
            "ETA: 8 minutes   59.676352042350956%   19840/33246 TOTALS: [936, 8133, 100, 503]\n",
            "ETA: 8 minutes   59.73650965529688%   19860/33246 TOTALS: [936, 8147, 100, 503]\n",
            "ETA: 8 minutes   59.7966672682428%   19880/33246 TOTALS: [938, 8154, 100, 503]\n",
            "ETA: 8 minutes   59.85682488118872%   19900/33246 TOTALS: [940, 8159, 101, 503]\n",
            "ETA: 7 minutes   59.91698249413463%   19920/33246 TOTALS: [942, 8167, 101, 503]\n",
            "ETA: 7 minutes   59.97714010708055%   19940/33246 TOTALS: [942, 8171, 101, 504]\n",
            "ETA: 8 minutes   60.03729772002647%   19960/33246 TOTALS: [942, 8180, 101, 504]\n",
            "ETA: 8 minutes   60.09745533297238%   19980/33246 TOTALS: [942, 8192, 101, 504]\n",
            "ETA: 8 minutes   60.1576129459183%   20000/33246 TOTALS: [942, 8203, 101, 506]\n",
            "ETA: 7 minutes   60.217770558864224%   20020/33246 TOTALS: [942, 8213, 101, 506]\n",
            "ETA: 8 minutes   60.277928171810146%   20040/33246 TOTALS: [944, 8220, 101, 507]\n",
            "ETA: 8 minutes   60.33808578475606%   20060/33246 TOTALS: [945, 8227, 101, 508]\n",
            "ETA: 8 minutes   60.398243397701975%   20080/33246 TOTALS: [946, 8236, 101, 508]\n",
            "ETA: 8 minutes   60.4584010106479%   20100/33246 TOTALS: [949, 8244, 101, 509]\n",
            "ETA: 8 minutes   60.51855862359382%   20120/33246 TOTALS: [952, 8250, 102, 510]\n",
            "ETA: 7 minutes   60.578716236539734%   20140/33246 TOTALS: [952, 8256, 102, 510]\n",
            "ETA: 7 minutes   60.638873849485655%   20160/33246 TOTALS: [952, 8262, 102, 512]\n",
            "ETA: 8 minutes   60.69903146243158%   20180/33246 TOTALS: [953, 8272, 102, 512]\n",
            "ETA: 8 minutes   60.759189075377485%   20200/33246 TOTALS: [953, 8282, 102, 513]\n",
            "ETA: 8 minutes   60.81934668832341%   20220/33246 TOTALS: [953, 8292, 102, 513]\n",
            "ETA: 7 minutes   60.87950430126933%   20240/33246 TOTALS: [955, 8298, 102, 514]\n",
            "ETA: 7 minutes   60.93966191421525%   20260/33246 TOTALS: [957, 8305, 102, 515]\n",
            "ETA: 8 minutes   60.99981952716116%   20280/33246 TOTALS: [957, 8316, 102, 515]\n",
            "ETA: 8 minutes   61.05997714010708%   20300/33246 TOTALS: [958, 8324, 102, 515]\n",
            "ETA: 8 minutes   61.120134753053%   20320/33246 TOTALS: [959, 8336, 102, 515]\n",
            "ETA: 7 minutes   61.18029236599891%   20340/33246 TOTALS: [959, 8346, 102, 515]\n",
            "ETA: 7 minutes   61.24044997894483%   20360/33246 TOTALS: [960, 8352, 102, 516]\n",
            "ETA: 8 minutes   61.30060759189075%   20380/33246 TOTALS: [961, 8362, 102, 516]\n",
            "ETA: 8 minutes   61.360765204836675%   20400/33246 TOTALS: [961, 8374, 102, 516]\n",
            "ETA: 8 minutes   61.42092281778259%   20420/33246 TOTALS: [961, 8385, 102, 517]\n",
            "ETA: 8 minutes   61.48108043072851%   20440/33246 TOTALS: [962, 8393, 102, 518]\n",
            "ETA: 7 minutes   61.541238043674426%   20460/33246 TOTALS: [962, 8398, 103, 518]\n",
            "ETA: 7 minutes   61.60139565662035%   20480/33246 TOTALS: [964, 8405, 103, 518]\n",
            "ETA: 7 minutes   61.66155326956626%   20500/33246 TOTALS: [964, 8414, 104, 518]\n",
            "ETA: 7 minutes   61.721710882512184%   20520/33246 TOTALS: [966, 8421, 104, 518]\n",
            "ETA: 7 minutes   61.781868495458106%   20540/33246 TOTALS: [967, 8429, 105, 518]\n",
            "ETA: 7 minutes   61.84202610840401%   20560/33246 TOTALS: [967, 8435, 105, 519]\n",
            "ETA: 7 minutes   61.902183721349935%   20580/33246 TOTALS: [967, 8442, 105, 522]\n",
            "ETA: 7 minutes   61.96234133429586%   20600/33246 TOTALS: [967, 8449, 105, 523]\n",
            "ETA: 7 minutes   62.02249894724178%   20620/33246 TOTALS: [969, 8456, 105, 523]\n",
            "ETA: 8 minutes   62.08265656018769%   20640/33246 TOTALS: [969, 8466, 106, 523]\n",
            "ETA: 7 minutes   62.14281417313361%   20660/33246 TOTALS: [969, 8477, 107, 523]\n",
            "ETA: 8 minutes   62.20297178607953%   20680/33246 TOTALS: [969, 8490, 107, 524]\n",
            "ETA: 8 minutes   62.26312939902545%   20700/33246 TOTALS: [969, 8499, 109, 525]\n",
            "ETA: 8 minutes   62.32328701197136%   20720/33246 TOTALS: [970, 8505, 109, 525]\n",
            "ETA: 8 minutes   62.38344462491728%   20740/33246 TOTALS: [972, 8514, 109, 525]\n",
            "ETA: 7 minutes   62.4436022378632%   20760/33246 TOTALS: [973, 8521, 109, 525]\n",
            "ETA: 7 minutes   62.50375985080912%   20780/33246 TOTALS: [974, 8529, 109, 525]\n",
            "ETA: 8 minutes   62.56391746375504%   20800/33246 TOTALS: [974, 8542, 109, 525]\n",
            "ETA: 7 minutes   62.62407507670096%   20820/33246 TOTALS: [974, 8550, 110, 526]\n",
            "ETA: 7 minutes   62.684232689646876%   20840/33246 TOTALS: [975, 8553, 110, 528]\n",
            "ETA: 8 minutes   62.74439030259279%   20860/33246 TOTALS: [978, 8565, 110, 528]\n",
            "ETA: 7 minutes   62.80454791553871%   20880/33246 TOTALS: [979, 8575, 110, 528]\n",
            "ETA: 7 minutes   62.864705528484635%   20900/33246 TOTALS: [982, 8581, 110, 528]\n",
            "ETA: 7 minutes   62.92486314143054%   20920/33246 TOTALS: [983, 8588, 110, 528]\n",
            "ETA: 7 minutes   62.985020754376464%   20940/33246 TOTALS: [983, 8599, 110, 528]\n",
            "ETA: 6 minutes   63.045178367322386%   20960/33246 TOTALS: [983, 8605, 110, 528]\n",
            "ETA: 7 minutes   63.10533598026831%   20980/33246 TOTALS: [983, 8614, 110, 528]\n",
            "ETA: 7 minutes   63.165493593214215%   21000/33246 TOTALS: [983, 8623, 110, 528]\n",
            "ETA: 7 minutes   63.22565120616014%   21020/33246 TOTALS: [984, 8633, 110, 528]\n",
            "ETA: 7 minutes   63.28580881910606%   21040/33246 TOTALS: [984, 8640, 110, 531]\n",
            "ETA: 7 minutes   63.34596643205198%   21060/33246 TOTALS: [985, 8649, 110, 532]\n",
            "ETA: 7 minutes   63.40612404499789%   21080/33246 TOTALS: [986, 8656, 111, 532]\n",
            "ETA: 7 minutes   63.46628165794381%   21100/33246 TOTALS: [987, 8664, 111, 532]\n",
            "ETA: 7 minutes   63.52643927088973%   21120/33246 TOTALS: [988, 8670, 111, 533]\n",
            "ETA: 7 minutes   63.58659688383565%   21140/33246 TOTALS: [989, 8677, 111, 533]\n",
            "ETA: 7 minutes   63.64675449678157%   21160/33246 TOTALS: [989, 8686, 111, 533]\n",
            "ETA: 7 minutes   63.70691210972749%   21180/33246 TOTALS: [990, 8692, 111, 533]\n",
            "ETA: 7 minutes   63.76706972267341%   21200/33246 TOTALS: [991, 8702, 111, 533]\n",
            "ETA: 7 minutes   63.82722733561932%   21220/33246 TOTALS: [993, 8710, 111, 533]\n",
            "ETA: 7 minutes   63.88738494856524%   21240/33246 TOTALS: [994, 8723, 111, 533]\n",
            "ETA: 7 minutes   63.94754256151116%   21260/33246 TOTALS: [994, 8734, 111, 535]\n",
            "ETA: 7 minutes   64.00770017445709%   21280/33246 TOTALS: [994, 8744, 111, 536]\n",
            "ETA: 7 minutes   64.067857787403%   21300/33246 TOTALS: [995, 8752, 111, 536]\n",
            "ETA: 6 minutes   64.12801540034891%   21320/33246 TOTALS: [995, 8756, 111, 537]\n",
            "ETA: 7 minutes   64.18817301329483%   21340/33246 TOTALS: [996, 8763, 111, 538]\n",
            "ETA: 7 minutes   64.24833062624074%   21360/33246 TOTALS: [997, 8769, 111, 538]\n",
            "ETA: 7 minutes   64.30848823918667%   21380/33246 TOTALS: [997, 8779, 111, 538]\n",
            "ETA: 7 minutes   64.36864585213259%   21400/33246 TOTALS: [997, 8785, 111, 538]\n",
            "ETA: 6 minutes   64.42880346507852%   21420/33246 TOTALS: [997, 8791, 111, 538]\n",
            "ETA: 7 minutes   64.48896107802442%   21440/33246 TOTALS: [998, 8798, 111, 539]\n",
            "ETA: 7 minutes   64.54911869097035%   21460/33246 TOTALS: [999, 8804, 111, 539]\n",
            "ETA: 7 minutes   64.60927630391626%   21480/33246 TOTALS: [1000, 8813, 111, 539]\n",
            "ETA: 7 minutes   64.66943391686218%   21500/33246 TOTALS: [1001, 8824, 111, 539]\n",
            "ETA: 7 minutes   64.72959152980809%   21520/33246 TOTALS: [1002, 8832, 111, 539]\n",
            "ETA: 6 minutes   64.78974914275402%   21540/33246 TOTALS: [1004, 8839, 111, 539]\n",
            "ETA: 6 minutes   64.84990675569993%   21560/33246 TOTALS: [1004, 8846, 111, 539]\n",
            "ETA: 7 minutes   64.91006436864585%   21580/33246 TOTALS: [1004, 8857, 111, 540]\n",
            "ETA: 7 minutes   64.97022198159176%   21600/33246 TOTALS: [1004, 8869, 111, 540]\n",
            "ETA: 6 minutes   65.03037959453769%   21620/33246 TOTALS: [1004, 8877, 111, 540]\n",
            "ETA: 7 minutes   65.0905372074836%   21640/33246 TOTALS: [1005, 8888, 111, 540]\n",
            "ETA: 6 minutes   65.15069482042952%   21660/33246 TOTALS: [1005, 8897, 111, 540]\n",
            "ETA: 7 minutes   65.21085243337545%   21680/33246 TOTALS: [1006, 8907, 111, 541]\n",
            "ETA: 7 minutes   65.27101004632136%   21700/33246 TOTALS: [1006, 8917, 112, 542]\n",
            "ETA: 7 minutes   65.33116765926728%   21720/33246 TOTALS: [1006, 8925, 113, 542]\n",
            "ETA: 7 minutes   65.3913252722132%   21740/33246 TOTALS: [1008, 8932, 115, 544]\n",
            "ETA: 6 minutes   65.45148288515912%   21760/33246 TOTALS: [1009, 8938, 115, 544]\n",
            "ETA: 7 minutes   65.51164049810504%   21780/33246 TOTALS: [1010, 8945, 116, 544]\n",
            "ETA: 7 minutes   65.57179811105095%   21800/33246 TOTALS: [1010, 8954, 116, 545]\n",
            "ETA: 7 minutes   65.63195572399687%   21820/33246 TOTALS: [1010, 8963, 116, 545]\n",
            "ETA: 7 minutes   65.6921133369428%   21840/33246 TOTALS: [1010, 8969, 116, 545]\n",
            "ETA: 8 minutes   65.75227094988871%   21860/33246 TOTALS: [1011, 8975, 116, 547]\n",
            "ETA: 6 minutes   65.81242856283463%   21880/33246 TOTALS: [1011, 8982, 116, 547]\n",
            "ETA: 7 minutes   65.87258617578054%   21900/33246 TOTALS: [1013, 8991, 116, 549]\n",
            "ETA: 6 minutes   65.93274378872647%   21920/33246 TOTALS: [1014, 8998, 116, 549]\n",
            "ETA: 7 minutes   65.99290140167238%   21940/33246 TOTALS: [1014, 9008, 116, 550]\n",
            "ETA: 6 minutes   66.0530590146183%   21960/33246 TOTALS: [1014, 9017, 116, 550]\n",
            "ETA: 6 minutes   66.11321662756421%   21980/33246 TOTALS: [1014, 9025, 117, 551]\n",
            "ETA: 7 minutes   66.17337424051014%   22000/33246 TOTALS: [1015, 9038, 117, 551]\n",
            "ETA: 6 minutes   66.23353185345606%   22020/33246 TOTALS: [1016, 9046, 117, 551]\n",
            "ETA: 6 minutes   66.29368946640197%   22040/33246 TOTALS: [1016, 9053, 118, 551]\n",
            "ETA: 7 minutes   66.3538470793479%   22060/33246 TOTALS: [1017, 9061, 118, 551]\n",
            "ETA: 6 minutes   66.4140046922938%   22080/33246 TOTALS: [1017, 9072, 118, 551]\n",
            "ETA: 6 minutes   66.47416230523973%   22100/33246 TOTALS: [1017, 9082, 118, 551]\n",
            "ETA: 6 minutes   66.53431991818564%   22120/33246 TOTALS: [1018, 9091, 118, 551]\n",
            "ETA: 7 minutes   66.59447753113157%   22140/33246 TOTALS: [1018, 9101, 119, 551]\n",
            "ETA: 7 minutes   66.65463514407747%   22160/33246 TOTALS: [1018, 9109, 120, 551]\n",
            "ETA: 6 minutes   66.7147927570234%   22180/33246 TOTALS: [1019, 9116, 120, 552]\n",
            "ETA: 7 minutes   66.77495036996932%   22200/33246 TOTALS: [1021, 9127, 120, 552]\n",
            "ETA: 6 minutes   66.83510798291525%   22220/33246 TOTALS: [1022, 9134, 120, 552]\n",
            "ETA: 6 minutes   66.89526559586115%   22240/33246 TOTALS: [1022, 9139, 120, 553]\n",
            "ETA: 6 minutes   66.95542320880708%   22260/33246 TOTALS: [1023, 9148, 120, 553]\n",
            "ETA: 6 minutes   67.01558082175299%   22280/33246 TOTALS: [1024, 9151, 121, 553]\n",
            "ETA: 7 minutes   67.0757384346989%   22300/33246 TOTALS: [1024, 9163, 121, 554]\n",
            "ETA: 6 minutes   67.13589604764482%   22320/33246 TOTALS: [1024, 9169, 121, 554]\n",
            "ETA: 6 minutes   67.19605366059075%   22340/33246 TOTALS: [1025, 9178, 121, 554]\n",
            "ETA: 6 minutes   67.25621127353666%   22360/33246 TOTALS: [1025, 9187, 121, 554]\n",
            "ETA: 6 minutes   67.31636888648258%   22380/33246 TOTALS: [1025, 9193, 121, 554]\n",
            "ETA: 6 minutes   67.37652649942851%   22400/33246 TOTALS: [1025, 9206, 121, 554]\n",
            "ETA: 7 minutes   67.43668411237442%   22420/33246 TOTALS: [1027, 9216, 121, 554]\n",
            "ETA: 6 minutes   67.49684172532035%   22440/33246 TOTALS: [1028, 9225, 122, 554]\n",
            "ETA: 6 minutes   67.55699933826625%   22460/33246 TOTALS: [1029, 9229, 122, 555]\n",
            "ETA: 6 minutes   67.61715695121218%   22480/33246 TOTALS: [1029, 9238, 122, 556]\n",
            "ETA: 6 minutes   67.6773145641581%   22500/33246 TOTALS: [1031, 9242, 122, 557]\n",
            "ETA: 6 minutes   67.73747217710401%   22520/33246 TOTALS: [1034, 9247, 122, 557]\n",
            "ETA: 6 minutes   67.79762979004992%   22540/33246 TOTALS: [1035, 9255, 122, 557]\n",
            "ETA: 6 minutes   67.85778740299585%   22560/33246 TOTALS: [1036, 9259, 122, 557]\n",
            "ETA: 6 minutes   67.91794501594177%   22580/33246 TOTALS: [1037, 9267, 122, 557]\n",
            "ETA: 6 minutes   67.97810262888768%   22600/33246 TOTALS: [1039, 9275, 122, 557]\n",
            "ETA: 6 minutes   68.0382602418336%   22620/33246 TOTALS: [1040, 9283, 122, 558]\n",
            "ETA: 6 minutes   68.09841785477953%   22640/33246 TOTALS: [1040, 9291, 123, 558]\n",
            "ETA: 6 minutes   68.15857546772544%   22660/33246 TOTALS: [1040, 9298, 123, 558]\n",
            "ETA: 6 minutes   68.21873308067136%   22680/33246 TOTALS: [1042, 9306, 123, 558]\n",
            "ETA: 6 minutes   68.27889069361729%   22700/33246 TOTALS: [1043, 9317, 123, 560]\n",
            "ETA: 6 minutes   68.3390483065632%   22720/33246 TOTALS: [1043, 9325, 123, 561]\n",
            "ETA: 6 minutes   68.39920591950911%   22740/33246 TOTALS: [1043, 9334, 123, 561]\n",
            "ETA: 6 minutes   68.45936353245503%   22760/33246 TOTALS: [1044, 9339, 123, 562]\n",
            "ETA: 6 minutes   68.51952114540096%   22780/33246 TOTALS: [1044, 9345, 123, 562]\n",
            "ETA: 6 minutes   68.57967875834687%   22800/33246 TOTALS: [1044, 9355, 123, 562]\n",
            "ETA: 6 minutes   68.63983637129279%   22820/33246 TOTALS: [1045, 9363, 123, 563]\n",
            "ETA: 6 minutes   68.6999939842387%   22840/33246 TOTALS: [1047, 9372, 123, 563]\n",
            "ETA: 6 minutes   68.76015159718463%   22860/33246 TOTALS: [1049, 9376, 124, 563]\n",
            "ETA: 6 minutes   68.82030921013053%   22880/33246 TOTALS: [1049, 9382, 124, 563]\n",
            "ETA: 5 minutes   68.88046682307646%   22900/33246 TOTALS: [1051, 9388, 124, 563]\n",
            "ETA: 7 minutes   68.94062443602238%   22920/33246 TOTALS: [1051, 9399, 124, 564]\n",
            "ETA: 6 minutes   69.0007820489683%   22940/33246 TOTALS: [1053, 9405, 124, 564]\n",
            "ETA: 6 minutes   69.0609396619142%   22960/33246 TOTALS: [1053, 9412, 124, 565]\n",
            "ETA: 6 minutes   69.12109727486013%   22980/33246 TOTALS: [1053, 9418, 124, 566]\n",
            "ETA: 6 minutes   69.18125488780605%   23000/33246 TOTALS: [1054, 9428, 124, 566]\n",
            "ETA: 6 minutes   69.24141250075198%   23020/33246 TOTALS: [1054, 9436, 124, 566]\n",
            "ETA: 6 minutes   69.30157011369789%   23040/33246 TOTALS: [1054, 9445, 124, 566]\n",
            "ETA: 6 minutes   69.3617277266438%   23060/33246 TOTALS: [1055, 9453, 124, 568]\n",
            "ETA: 6 minutes   69.42188533958972%   23080/33246 TOTALS: [1056, 9461, 124, 568]\n",
            "ETA: 7 minutes   69.48204295253564%   23100/33246 TOTALS: [1058, 9473, 124, 569]\n",
            "ETA: 6 minutes   69.54220056548156%   23120/33246 TOTALS: [1059, 9480, 124, 571]\n",
            "ETA: 6 minutes   69.60235817842748%   23140/33246 TOTALS: [1060, 9487, 124, 572]\n",
            "ETA: 6 minutes   69.66251579137341%   23160/33246 TOTALS: [1060, 9494, 124, 572]\n",
            "ETA: 6 minutes   69.72267340431931%   23180/33246 TOTALS: [1061, 9499, 124, 572]\n",
            "ETA: 6 minutes   69.78283101726524%   23200/33246 TOTALS: [1061, 9510, 124, 572]\n",
            "ETA: 6 minutes   69.84298863021115%   23220/33246 TOTALS: [1061, 9523, 124, 572]\n",
            "ETA: 6 minutes   69.90314624315707%   23240/33246 TOTALS: [1061, 9533, 124, 574]\n",
            "ETA: 6 minutes   69.96330385610298%   23260/33246 TOTALS: [1061, 9542, 124, 574]\n",
            "ETA: 6 minutes   70.02346146904891%   23280/33246 TOTALS: [1061, 9553, 124, 574]\n",
            "ETA: 6 minutes   70.08361908199483%   23300/33246 TOTALS: [1062, 9562, 124, 574]\n",
            "ETA: 5 minutes   70.14377669494074%   23320/33246 TOTALS: [1062, 9567, 124, 574]\n",
            "ETA: 6 minutes   70.20393430788666%   23340/33246 TOTALS: [1064, 9576, 124, 574]\n",
            "ETA: 6 minutes   70.26409192083258%   23360/33246 TOTALS: [1065, 9584, 124, 574]\n",
            "ETA: 5 minutes   70.3242495337785%   23380/33246 TOTALS: [1065, 9589, 124, 574]\n",
            "ETA: 5 minutes   70.38440714672441%   23400/33246 TOTALS: [1066, 9593, 124, 574]\n",
            "ETA: 6 minutes   70.44456475967034%   23420/33246 TOTALS: [1066, 9601, 124, 575]\n",
            "ETA: 5 minutes   70.50472237261626%   23440/33246 TOTALS: [1066, 9608, 124, 575]\n",
            "ETA: 5 minutes   70.56487998556217%   23460/33246 TOTALS: [1066, 9615, 124, 575]\n",
            "ETA: 6 minutes   70.62503759850809%   23480/33246 TOTALS: [1069, 9621, 124, 576]\n",
            "ETA: 6 minutes   70.68519521145402%   23500/33246 TOTALS: [1070, 9630, 124, 576]\n",
            "ETA: 6 minutes   70.74535282439993%   23520/33246 TOTALS: [1071, 9639, 124, 576]\n",
            "ETA: 6 minutes   70.80551043734584%   23540/33246 TOTALS: [1071, 9647, 126, 577]\n",
            "ETA: 5 minutes   70.86566805029176%   23560/33246 TOTALS: [1071, 9652, 126, 577]\n",
            "ETA: 6 minutes   70.92582566323769%   23580/33246 TOTALS: [1071, 9660, 126, 577]\n",
            "ETA: 5 minutes   70.9859832761836%   23600/33246 TOTALS: [1072, 9668, 126, 578]\n",
            "ETA: 5 minutes   71.04614088912952%   23620/33246 TOTALS: [1072, 9676, 126, 579]\n",
            "ETA: 6 minutes   71.10629850207543%   23640/33246 TOTALS: [1072, 9684, 126, 579]\n",
            "ETA: 5 minutes   71.16645611502136%   23660/33246 TOTALS: [1072, 9694, 126, 580]\n",
            "ETA: 5 minutes   71.22661372796728%   23680/33246 TOTALS: [1073, 9703, 126, 580]\n",
            "ETA: 6 minutes   71.28677134091319%   23700/33246 TOTALS: [1074, 9715, 126, 580]\n",
            "ETA: 5 minutes   71.3469289538591%   23720/33246 TOTALS: [1074, 9719, 126, 581]\n",
            "ETA: 5 minutes   71.40708656680503%   23740/33246 TOTALS: [1074, 9726, 126, 581]\n",
            "ETA: 5 minutes   71.46724417975095%   23760/33246 TOTALS: [1075, 9733, 126, 581]\n",
            "ETA: 5 minutes   71.52740179269686%   23780/33246 TOTALS: [1077, 9739, 126, 581]\n",
            "ETA: 6 minutes   71.58755940564279%   23800/33246 TOTALS: [1078, 9747, 127, 581]\n",
            "ETA: 5 minutes   71.6477170185887%   23820/33246 TOTALS: [1078, 9755, 128, 581]\n",
            "ETA: 5 minutes   71.70787463153462%   23840/33246 TOTALS: [1081, 9760, 128, 581]\n",
            "ETA: 5 minutes   71.76803224448054%   23860/33246 TOTALS: [1083, 9767, 128, 582]\n",
            "ETA: 5 minutes   71.82818985742647%   23880/33246 TOTALS: [1085, 9774, 128, 582]\n",
            "ETA: 5 minutes   71.88834747037237%   23900/33246 TOTALS: [1086, 9782, 128, 582]\n",
            "ETA: 5 minutes   71.9485050833183%   23920/33246 TOTALS: [1088, 9788, 128, 582]\n",
            "ETA: 5 minutes   72.00866269626421%   23940/33246 TOTALS: [1090, 9795, 129, 582]\n",
            "ETA: 5 minutes   72.06882030921014%   23960/33246 TOTALS: [1091, 9804, 129, 582]\n",
            "ETA: 5 minutes   72.12897792215604%   23980/33246 TOTALS: [1091, 9814, 129, 582]\n",
            "ETA: 5 minutes   72.18913553510197%   24000/33246 TOTALS: [1094, 9817, 129, 582]\n",
            "ETA: 5 minutes   72.24929314804788%   24020/33246 TOTALS: [1098, 9824, 129, 582]\n",
            "ETA: 5 minutes   72.3094507609938%   24040/33246 TOTALS: [1099, 9832, 129, 582]\n",
            "ETA: 5 minutes   72.36960837393973%   24060/33246 TOTALS: [1100, 9839, 129, 583]\n",
            "ETA: 5 minutes   72.42976598688564%   24080/33246 TOTALS: [1101, 9847, 129, 584]\n",
            "ETA: 5 minutes   72.48992359983156%   24100/33246 TOTALS: [1102, 9855, 129, 585]\n",
            "ETA: 5 minutes   72.55008121277747%   24120/33246 TOTALS: [1102, 9862, 129, 585]\n",
            "ETA: 5 minutes   72.6102388257234%   24140/33246 TOTALS: [1102, 9869, 129, 585]\n",
            "ETA: 5 minutes   72.67039643866931%   24160/33246 TOTALS: [1103, 9877, 129, 585]\n",
            "ETA: 5 minutes   72.73055405161524%   24180/33246 TOTALS: [1105, 9879, 129, 585]\n",
            "ETA: 5 minutes   72.79071166456114%   24200/33246 TOTALS: [1105, 9886, 129, 586]\n",
            "ETA: 5 minutes   72.85086927750707%   24220/33246 TOTALS: [1105, 9895, 129, 587]\n",
            "ETA: 5 minutes   72.91102689045299%   24240/33246 TOTALS: [1106, 9902, 129, 590]\n",
            "ETA: 5 minutes   72.9711845033989%   24260/33246 TOTALS: [1108, 9907, 129, 590]\n",
            "ETA: 5 minutes   73.03134211634482%   24280/33246 TOTALS: [1108, 9914, 129, 590]\n",
            "ETA: 5 minutes   73.09149972929075%   24300/33246 TOTALS: [1109, 9922, 129, 591]\n",
            "ETA: 5 minutes   73.15165734223666%   24320/33246 TOTALS: [1110, 9929, 129, 593]\n",
            "ETA: 5 minutes   73.21181495518258%   24340/33246 TOTALS: [1110, 9935, 129, 594]\n",
            "ETA: 5 minutes   73.27197256812849%   24360/33246 TOTALS: [1111, 9941, 129, 595]\n",
            "ETA: 4 minutes   73.33213018107442%   24380/33246 TOTALS: [1111, 9945, 129, 597]\n",
            "ETA: 5 minutes   73.39228779402033%   24400/33246 TOTALS: [1112, 9947, 129, 598]\n",
            "ETA: 5 minutes   73.45244540696625%   24420/33246 TOTALS: [1112, 9959, 129, 599]\n",
            "ETA: 5 minutes   73.51260301991218%   24440/33246 TOTALS: [1112, 9966, 130, 600]\n",
            "ETA: 5 minutes   73.57276063285809%   24460/33246 TOTALS: [1114, 9976, 130, 600]\n",
            "ETA: 5 minutes   73.632918245804%   24480/33246 TOTALS: [1115, 9983, 130, 602]\n",
            "ETA: 5 minutes   73.69307585874992%   24500/33246 TOTALS: [1119, 9990, 130, 602]\n",
            "ETA: 5 minutes   73.75323347169585%   24520/33246 TOTALS: [1119, 10000, 130, 602]\n",
            "ETA: 5 minutes   73.81339108464176%   24540/33246 TOTALS: [1119, 10011, 130, 603]\n",
            "ETA: 5 minutes   73.87354869758768%   24560/33246 TOTALS: [1121, 10021, 130, 603]\n",
            "ETA: 5 minutes   73.9337063105336%   24580/33246 TOTALS: [1122, 10030, 130, 603]\n",
            "ETA: 4 minutes   73.99386392347952%   24600/33246 TOTALS: [1122, 10032, 130, 604]\n",
            "ETA: 5 minutes   74.05402153642542%   24620/33246 TOTALS: [1124, 10038, 130, 604]\n",
            "ETA: 5 minutes   74.11417914937135%   24640/33246 TOTALS: [1125, 10047, 130, 605]\n",
            "ETA: 5 minutes   74.17433676231727%   24660/33246 TOTALS: [1126, 10053, 130, 605]\n",
            "ETA: 5 minutes   74.2344943752632%   24680/33246 TOTALS: [1126, 10061, 130, 606]\n",
            "ETA: 5 minutes   74.2946519882091%   24700/33246 TOTALS: [1126, 10070, 130, 606]\n",
            "ETA: 5 minutes   74.35480960115503%   24720/33246 TOTALS: [1127, 10079, 130, 606]\n",
            "ETA: 5 minutes   74.41496721410094%   24740/33246 TOTALS: [1127, 10088, 130, 607]\n",
            "ETA: 5 minutes   74.47512482704687%   24760/33246 TOTALS: [1128, 10097, 130, 608]\n",
            "ETA: 5 minutes   74.53528243999278%   24780/33246 TOTALS: [1130, 10103, 131, 608]\n",
            "ETA: 4 minutes   74.5954400529387%   24800/33246 TOTALS: [1131, 10108, 131, 608]\n",
            "ETA: 5 minutes   74.65559766588463%   24820/33246 TOTALS: [1134, 10117, 131, 608]\n",
            "ETA: 5 minutes   74.71575527883053%   24840/33246 TOTALS: [1134, 10126, 131, 609]\n",
            "ETA: 4 minutes   74.77591289177646%   24860/33246 TOTALS: [1134, 10131, 131, 609]\n",
            "ETA: 5 minutes   74.83607050472237%   24880/33246 TOTALS: [1134, 10138, 131, 610]\n",
            "ETA: 5 minutes   74.8962281176683%   24900/33246 TOTALS: [1135, 10145, 131, 613]\n",
            "ETA: 5 minutes   74.9563857306142%   24920/33246 TOTALS: [1135, 10154, 131, 615]\n",
            "ETA: 5 minutes   75.01654334356013%   24940/33246 TOTALS: [1135, 10168, 131, 615]\n",
            "ETA: 5 minutes   75.07670095650604%   24960/33246 TOTALS: [1135, 10179, 131, 615]\n",
            "ETA: 5 minutes   75.13685856945196%   24980/33246 TOTALS: [1136, 10187, 131, 615]\n",
            "ETA: 4 minutes   75.19701618239787%   25000/33246 TOTALS: [1136, 10194, 131, 615]\n",
            "ETA: 5 minutes   75.2571737953438%   25020/33246 TOTALS: [1137, 10204, 131, 616]\n",
            "ETA: 5 minutes   75.31733140828972%   25040/33246 TOTALS: [1138, 10214, 131, 616]\n",
            "ETA: 5 minutes   75.37748902123563%   25060/33246 TOTALS: [1139, 10222, 131, 617]\n",
            "ETA: 4 minutes   75.43764663418156%   25080/33246 TOTALS: [1139, 10229, 131, 617]\n",
            "ETA: 5 minutes   75.49780424712748%   25100/33246 TOTALS: [1141, 10237, 131, 618]\n",
            "ETA: 5 minutes   75.55796186007339%   25120/33246 TOTALS: [1141, 10246, 132, 619]\n",
            "ETA: 5 minutes   75.6181194730193%   25140/33246 TOTALS: [1142, 10255, 132, 619]\n",
            "ETA: 4 minutes   75.67827708596523%   25160/33246 TOTALS: [1142, 10260, 132, 619]\n",
            "ETA: 4 minutes   75.73843469891115%   25180/33246 TOTALS: [1143, 10266, 132, 619]\n",
            "ETA: 4 minutes   75.79859231185706%   25200/33246 TOTALS: [1144, 10272, 132, 621]\n",
            "ETA: 4 minutes   75.85874992480298%   25220/33246 TOTALS: [1146, 10276, 132, 622]\n",
            "ETA: 4 minutes   75.91890753774891%   25240/33246 TOTALS: [1147, 10283, 132, 622]\n",
            "ETA: 5 minutes   75.97906515069482%   25260/33246 TOTALS: [1148, 10292, 132, 622]\n",
            "ETA: 5 minutes   76.03922276364074%   25280/33246 TOTALS: [1149, 10299, 132, 622]\n",
            "ETA: 5 minutes   76.09938037658665%   25300/33246 TOTALS: [1149, 10310, 132, 622]\n",
            "ETA: 4 minutes   76.15953798953258%   25320/33246 TOTALS: [1149, 10318, 133, 622]\n",
            "ETA: 4 minutes   76.2196956024785%   25340/33246 TOTALS: [1151, 10327, 133, 622]\n",
            "ETA: 4 minutes   76.27985321542441%   25360/33246 TOTALS: [1151, 10337, 133, 622]\n",
            "ETA: 5 minutes   76.34001082837032%   25380/33246 TOTALS: [1152, 10347, 135, 622]\n",
            "ETA: 4 minutes   76.40016844131625%   25400/33246 TOTALS: [1152, 10355, 135, 622]\n",
            "ETA: 4 minutes   76.46032605426217%   25420/33246 TOTALS: [1153, 10360, 135, 622]\n",
            "ETA: 4 minutes   76.52048366720808%   25440/33246 TOTALS: [1155, 10366, 135, 623]\n",
            "ETA: 4 minutes   76.580641280154%   25460/33246 TOTALS: [1155, 10372, 135, 623]\n",
            "ETA: 5 minutes   76.64079889309993%   25480/33246 TOTALS: [1155, 10382, 135, 624]\n",
            "ETA: 4 minutes   76.70095650604584%   25500/33246 TOTALS: [1156, 10391, 135, 625]\n",
            "ETA: 4 minutes   76.76111411899176%   25520/33246 TOTALS: [1158, 10398, 135, 626]\n",
            "ETA: 4 minutes   76.82127173193768%   25540/33246 TOTALS: [1159, 10407, 135, 627]\n",
            "ETA: 5 minutes   76.88142934488359%   25560/33246 TOTALS: [1160, 10417, 135, 627]\n",
            "ETA: 4 minutes   76.94158695782951%   25580/33246 TOTALS: [1160, 10425, 136, 627]\n",
            "ETA: 4 minutes   77.00174457077543%   25600/33246 TOTALS: [1160, 10432, 137, 627]\n",
            "ETA: 4 minutes   77.06190218372136%   25620/33246 TOTALS: [1161, 10439, 137, 627]\n",
            "ETA: 4 minutes   77.12205979666726%   25640/33246 TOTALS: [1161, 10449, 137, 627]\n",
            "ETA: 4 minutes   77.18221740961319%   25660/33246 TOTALS: [1164, 10454, 137, 628]\n",
            "ETA: 4 minutes   77.2423750225591%   25680/33246 TOTALS: [1167, 10458, 137, 628]\n",
            "ETA: 4 minutes   77.30253263550503%   25700/33246 TOTALS: [1168, 10467, 137, 631]\n",
            "ETA: 4 minutes   77.36269024845093%   25720/33246 TOTALS: [1168, 10474, 137, 631]\n",
            "ETA: 4 minutes   77.42284786139686%   25740/33246 TOTALS: [1169, 10484, 137, 631]\n",
            "ETA: 4 minutes   77.48300547434278%   25760/33246 TOTALS: [1169, 10490, 137, 631]\n",
            "ETA: 4 minutes   77.54316308728869%   25780/33246 TOTALS: [1169, 10497, 137, 632]\n",
            "ETA: 4 minutes   77.60332070023462%   25800/33246 TOTALS: [1170, 10502, 137, 632]\n",
            "ETA: 4 minutes   77.66347831318053%   25820/33246 TOTALS: [1173, 10510, 137, 632]\n",
            "ETA: 4 minutes   77.72363592612646%   25840/33246 TOTALS: [1173, 10518, 137, 633]\n",
            "ETA: 4 minutes   77.78379353907236%   25860/33246 TOTALS: [1173, 10527, 137, 634]\n",
            "ETA: 4 minutes   77.84395115201829%   25880/33246 TOTALS: [1173, 10540, 137, 634]\n",
            "ETA: 4 minutes   77.9041087649642%   25900/33246 TOTALS: [1175, 10551, 137, 634]\n",
            "ETA: 4 minutes   77.96426637791014%   25920/33246 TOTALS: [1176, 10562, 137, 634]\n",
            "ETA: 4 minutes   78.02442399085604%   25940/33246 TOTALS: [1176, 10567, 137, 636]\n",
            "ETA: 4 minutes   78.08458160380196%   25960/33246 TOTALS: [1176, 10573, 137, 637]\n",
            "ETA: 4 minutes   78.14473921674788%   25980/33246 TOTALS: [1176, 10583, 137, 637]\n",
            "ETA: 4 minutes   78.2048968296938%   26000/33246 TOTALS: [1178, 10590, 138, 637]\n",
            "ETA: 4 minutes   78.26505444263971%   26020/33246 TOTALS: [1178, 10597, 138, 639]\n",
            "ETA: 4 minutes   78.32521205558564%   26040/33246 TOTALS: [1178, 10606, 138, 639]\n",
            "ETA: 4 minutes   78.38536966853155%   26060/33246 TOTALS: [1180, 10616, 138, 639]\n",
            "ETA: 4 minutes   78.44552728147747%   26080/33246 TOTALS: [1181, 10627, 138, 639]\n",
            "ETA: 4 minutes   78.50568489442338%   26100/33246 TOTALS: [1181, 10636, 139, 639]\n",
            "ETA: 4 minutes   78.56584250736931%   26120/33246 TOTALS: [1181, 10644, 139, 639]\n",
            "ETA: 4 minutes   78.62600012031523%   26140/33246 TOTALS: [1184, 10651, 139, 640]\n",
            "ETA: 4 minutes   78.68615773326114%   26160/33246 TOTALS: [1184, 10659, 139, 641]\n",
            "ETA: 4 minutes   78.74631534620707%   26180/33246 TOTALS: [1186, 10666, 140, 641]\n",
            "ETA: 4 minutes   78.80647295915298%   26200/33246 TOTALS: [1188, 10673, 140, 643]\n",
            "ETA: 4 minutes   78.8666305720989%   26220/33246 TOTALS: [1190, 10682, 140, 643]\n",
            "ETA: 4 minutes   78.92678818504481%   26240/33246 TOTALS: [1190, 10687, 140, 644]\n",
            "ETA: 4 minutes   78.98694579799074%   26260/33246 TOTALS: [1192, 10695, 140, 645]\n",
            "ETA: 4 minutes   79.04710341093666%   26280/33246 TOTALS: [1192, 10700, 140, 645]\n",
            "ETA: 4 minutes   79.10726102388257%   26300/33246 TOTALS: [1193, 10711, 140, 645]\n",
            "ETA: 4 minutes   79.16741863682849%   26320/33246 TOTALS: [1194, 10718, 140, 645]\n",
            "ETA: 4 minutes   79.22757624977442%   26340/33246 TOTALS: [1195, 10723, 140, 645]\n",
            "ETA: 3 minutes   79.28773386272032%   26360/33246 TOTALS: [1197, 10726, 141, 645]\n",
            "ETA: 4 minutes   79.34789147566624%   26380/33246 TOTALS: [1197, 10740, 141, 645]\n",
            "ETA: 4 minutes   79.40804908861216%   26400/33246 TOTALS: [1197, 10748, 141, 646]\n",
            "ETA: 4 minutes   79.46820670155809%   26420/33246 TOTALS: [1198, 10761, 141, 646]\n",
            "ETA: 4 minutes   79.528364314504%   26440/33246 TOTALS: [1200, 10767, 141, 648]\n",
            "ETA: 4 minutes   79.58852192744992%   26460/33246 TOTALS: [1201, 10775, 141, 648]\n",
            "ETA: 4 minutes   79.64867954039583%   26480/33246 TOTALS: [1201, 10781, 141, 648]\n",
            "ETA: 4 minutes   79.70883715334176%   26500/33246 TOTALS: [1202, 10791, 141, 648]\n",
            "ETA: 4 minutes   79.76899476628768%   26520/33246 TOTALS: [1205, 10798, 141, 648]\n",
            "ETA: 4 minutes   79.82915237923359%   26540/33246 TOTALS: [1205, 10807, 141, 649]\n",
            "ETA: 4 minutes   79.88930999217952%   26560/33246 TOTALS: [1208, 10815, 141, 649]\n",
            "ETA: 4 minutes   79.94946760512542%   26580/33246 TOTALS: [1211, 10822, 141, 651]\n",
            "ETA: 3 minutes   80.00962521807135%   26600/33246 TOTALS: [1211, 10826, 142, 651]\n",
            "ETA: 4 minutes   80.06978283101726%   26620/33246 TOTALS: [1214, 10833, 142, 651]\n",
            "ETA: 4 minutes   80.12994044396319%   26640/33246 TOTALS: [1215, 10840, 142, 654]\n",
            "ETA: 4 minutes   80.1900980569091%   26660/33246 TOTALS: [1215, 10850, 142, 655]\n",
            "ETA: 4 minutes   80.25025566985502%   26680/33246 TOTALS: [1217, 10861, 142, 655]\n",
            "ETA: 4 minutes   80.31041328280094%   26700/33246 TOTALS: [1218, 10865, 143, 657]\n",
            "ETA: 3 minutes   80.37057089574687%   26720/33246 TOTALS: [1219, 10871, 144, 657]\n",
            "ETA: 3 minutes   80.43072850869277%   26740/33246 TOTALS: [1221, 10877, 144, 657]\n",
            "ETA: 4 minutes   80.4908861216387%   26760/33246 TOTALS: [1223, 10884, 145, 657]\n",
            "ETA: 4 minutes   80.55104373458461%   26780/33246 TOTALS: [1224, 10895, 145, 657]\n",
            "ETA: 4 minutes   80.61120134753052%   26800/33246 TOTALS: [1227, 10901, 145, 657]\n",
            "ETA: 3 minutes   80.67135896047645%   26820/33246 TOTALS: [1228, 10909, 145, 658]\n",
            "ETA: 3 minutes   80.73151657342237%   26840/33246 TOTALS: [1228, 10915, 145, 659]\n",
            "ETA: 4 minutes   80.79167418636828%   26860/33246 TOTALS: [1229, 10925, 146, 660]\n",
            "ETA: 4 minutes   80.8518317993142%   26880/33246 TOTALS: [1230, 10938, 146, 661]\n",
            "ETA: 3 minutes   80.91198941226013%   26900/33246 TOTALS: [1231, 10945, 147, 662]\n",
            "ETA: 3 minutes   80.97214702520604%   26920/33246 TOTALS: [1233, 10953, 147, 662]\n",
            "ETA: 3 minutes   81.03230463815196%   26940/33246 TOTALS: [1233, 10959, 147, 662]\n",
            "ETA: 3 minutes   81.09246225109787%   26960/33246 TOTALS: [1234, 10967, 147, 663]\n",
            "ETA: 3 minutes   81.1526198640438%   26980/33246 TOTALS: [1236, 10977, 147, 663]\n",
            "ETA: 3 minutes   81.21277747698971%   27000/33246 TOTALS: [1237, 10985, 147, 663]\n",
            "ETA: 3 minutes   81.27293508993563%   27020/33246 TOTALS: [1238, 10995, 147, 664]\n",
            "ETA: 3 minutes   81.33309270288154%   27040/33246 TOTALS: [1238, 11001, 147, 665]\n",
            "ETA: 3 minutes   81.39325031582747%   27060/33246 TOTALS: [1238, 11011, 147, 666]\n",
            "ETA: 3 minutes   81.45340792877339%   27080/33246 TOTALS: [1241, 11019, 147, 666]\n",
            "ETA: 3 minutes   81.5135655417193%   27100/33246 TOTALS: [1241, 11028, 147, 667]\n",
            "ETA: 4 minutes   81.57372315466522%   27120/33246 TOTALS: [1242, 11038, 147, 667]\n",
            "ETA: 4 minutes   81.63388076761115%   27140/33246 TOTALS: [1242, 11049, 147, 667]\n",
            "ETA: 3 minutes   81.69403838055706%   27160/33246 TOTALS: [1242, 11056, 147, 667]\n",
            "ETA: 3 minutes   81.75419599350298%   27180/33246 TOTALS: [1243, 11066, 147, 667]\n",
            "ETA: 3 minutes   81.8143536064489%   27200/33246 TOTALS: [1244, 11075, 147, 667]\n",
            "ETA: 3 minutes   81.87451121939482%   27220/33246 TOTALS: [1244, 11081, 147, 668]\n",
            "ETA: 3 minutes   81.93466883234073%   27240/33246 TOTALS: [1245, 11085, 149, 668]\n",
            "ETA: 3 minutes   81.99482644528665%   27260/33246 TOTALS: [1245, 11092, 149, 669]\n",
            "ETA: 3 minutes   82.05498405823258%   27280/33246 TOTALS: [1246, 11099, 149, 669]\n",
            "ETA: 3 minutes   82.11514167117849%   27300/33246 TOTALS: [1246, 11108, 149, 669]\n",
            "ETA: 3 minutes   82.1752992841244%   27320/33246 TOTALS: [1247, 11114, 149, 669]\n",
            "ETA: 3 minutes   82.23545689707032%   27340/33246 TOTALS: [1249, 11124, 149, 670]\n",
            "ETA: 3 minutes   82.29561451001625%   27360/33246 TOTALS: [1250, 11131, 149, 670]\n",
            "ETA: 3 minutes   82.35577212296215%   27380/33246 TOTALS: [1252, 11139, 149, 670]\n",
            "ETA: 3 minutes   82.41592973590808%   27400/33246 TOTALS: [1253, 11146, 149, 671]\n",
            "ETA: 3 minutes   82.476087348854%   27420/33246 TOTALS: [1253, 11153, 149, 671]\n",
            "ETA: 3 minutes   82.53624496179992%   27440/33246 TOTALS: [1253, 11162, 149, 671]\n",
            "ETA: 3 minutes   82.59640257474584%   27460/33246 TOTALS: [1255, 11169, 149, 671]\n",
            "ETA: 3 minutes   82.65656018769175%   27480/33246 TOTALS: [1256, 11180, 149, 671]\n",
            "ETA: 3 minutes   82.71671780063767%   27500/33246 TOTALS: [1259, 11189, 149, 671]\n",
            "ETA: 3 minutes   82.77687541358358%   27520/33246 TOTALS: [1259, 11202, 149, 672]\n",
            "ETA: 3 minutes   82.83703302652951%   27540/33246 TOTALS: [1259, 11212, 149, 672]\n",
            "ETA: 3 minutes   82.89719063947543%   27560/33246 TOTALS: [1261, 11219, 149, 673]\n",
            "ETA: 3 minutes   82.95734825242135%   27580/33246 TOTALS: [1261, 11227, 149, 673]\n",
            "ETA: 3 minutes   83.01750586536726%   27600/33246 TOTALS: [1262, 11232, 149, 673]\n",
            "ETA: 3 minutes   83.07766347831318%   27620/33246 TOTALS: [1262, 11237, 149, 674]\n",
            "ETA: 3 minutes   83.1378210912591%   27640/33246 TOTALS: [1263, 11247, 149, 675]\n",
            "ETA: 3 minutes   83.19797870420503%   27660/33246 TOTALS: [1265, 11254, 149, 675]\n",
            "ETA: 3 minutes   83.25813631715093%   27680/33246 TOTALS: [1267, 11262, 149, 675]\n",
            "ETA: 3 minutes   83.31829393009686%   27700/33246 TOTALS: [1268, 11269, 149, 676]\n",
            "ETA: 3 minutes   83.37845154304277%   27720/33246 TOTALS: [1268, 11273, 150, 676]\n",
            "ETA: 3 minutes   83.43860915598869%   27740/33246 TOTALS: [1268, 11282, 150, 676]\n",
            "ETA: 3 minutes   83.4987667689346%   27760/33246 TOTALS: [1268, 11293, 150, 677]\n",
            "ETA: 3 minutes   83.55892438188053%   27780/33246 TOTALS: [1269, 11301, 150, 678]\n",
            "ETA: 3 minutes   83.61908199482644%   27800/33246 TOTALS: [1272, 11309, 150, 678]\n",
            "ETA: 3 minutes   83.67923960777236%   27820/33246 TOTALS: [1273, 11315, 150, 679]\n",
            "ETA: 3 minutes   83.73939722071827%   27840/33246 TOTALS: [1274, 11323, 150, 679]\n",
            "ETA: 3 minutes   83.7995548336642%   27860/33246 TOTALS: [1274, 11332, 150, 679]\n",
            "ETA: 3 minutes   83.85971244661012%   27880/33246 TOTALS: [1274, 11343, 150, 679]\n",
            "ETA: 3 minutes   83.91987005955603%   27900/33246 TOTALS: [1274, 11353, 150, 680]\n",
            "ETA: 3 minutes   83.98002767250196%   27920/33246 TOTALS: [1274, 11364, 150, 682]\n",
            "ETA: 3 minutes   84.04018528544788%   27940/33246 TOTALS: [1274, 11372, 150, 682]\n",
            "ETA: 3 minutes   84.10034289839379%   27960/33246 TOTALS: [1275, 11378, 151, 682]\n",
            "ETA: 3 minutes   84.1605005113397%   27980/33246 TOTALS: [1276, 11388, 151, 682]\n",
            "ETA: 3 minutes   84.22065812428563%   28000/33246 TOTALS: [1277, 11398, 151, 682]\n",
            "ETA: 3 minutes   84.28081573723155%   28020/33246 TOTALS: [1277, 11406, 151, 682]\n",
            "ETA: 3 minutes   84.34097335017746%   28040/33246 TOTALS: [1278, 11417, 151, 683]\n",
            "ETA: 3 minutes   84.40113096312338%   28060/33246 TOTALS: [1279, 11425, 152, 683]\n",
            "ETA: 3 minutes   84.46128857606931%   28080/33246 TOTALS: [1280, 11431, 152, 683]\n",
            "ETA: 3 minutes   84.52144618901521%   28100/33246 TOTALS: [1280, 11443, 152, 683]\n",
            "ETA: 3 minutes   84.58160380196114%   28120/33246 TOTALS: [1281, 11450, 153, 684]\n",
            "ETA: 3 minutes   84.64176141490705%   28140/33246 TOTALS: [1282, 11457, 153, 684]\n",
            "ETA: 3 minutes   84.70191902785298%   28160/33246 TOTALS: [1282, 11467, 153, 684]\n",
            "ETA: 3 minutes   84.7620766407989%   28180/33246 TOTALS: [1283, 11474, 153, 684]\n",
            "ETA: 3 minutes   84.82223425374481%   28200/33246 TOTALS: [1283, 11483, 154, 685]\n",
            "ETA: 2 minutes   84.88239186669074%   28220/33246 TOTALS: [1284, 11488, 154, 685]\n",
            "ETA: 3 minutes   84.94254947963665%   28240/33246 TOTALS: [1285, 11498, 154, 685]\n",
            "ETA: 2 minutes   85.00270709258257%   28260/33246 TOTALS: [1286, 11503, 154, 686]\n",
            "ETA: 3 minutes   85.06286470552848%   28280/33246 TOTALS: [1286, 11513, 154, 687]\n",
            "ETA: 2 minutes   85.12302231847441%   28300/33246 TOTALS: [1287, 11518, 154, 688]\n",
            "ETA: 3 minutes   85.18317993142031%   28320/33246 TOTALS: [1287, 11527, 154, 688]\n",
            "ETA: 3 minutes   85.24333754436624%   28340/33246 TOTALS: [1290, 11537, 154, 689]\n",
            "ETA: 3 minutes   85.30349515731216%   28360/33246 TOTALS: [1292, 11545, 154, 690]\n",
            "ETA: 3 minutes   85.36365277025808%   28380/33246 TOTALS: [1293, 11554, 154, 692]\n",
            "ETA: 3 minutes   85.42381038320399%   28400/33246 TOTALS: [1293, 11565, 154, 692]\n",
            "ETA: 3 minutes   85.48396799614991%   28420/33246 TOTALS: [1294, 11576, 154, 692]\n",
            "ETA: 3 minutes   85.54412560909583%   28440/33246 TOTALS: [1295, 11584, 155, 692]\n",
            "ETA: 3 minutes   85.60428322204176%   28460/33246 TOTALS: [1296, 11592, 156, 693]\n",
            "ETA: 2 minutes   85.66444083498766%   28480/33246 TOTALS: [1296, 11598, 156, 694]\n",
            "ETA: 3 minutes   85.72459844793359%   28500/33246 TOTALS: [1297, 11611, 156, 694]\n",
            "ETA: 2 minutes   85.7847560608795%   28520/33246 TOTALS: [1297, 11622, 156, 694]\n",
            "ETA: 2 minutes   85.84491367382542%   28540/33246 TOTALS: [1297, 11628, 156, 695]\n",
            "ETA: 3 minutes   85.90507128677135%   28560/33246 TOTALS: [1297, 11637, 156, 696]\n",
            "ETA: 2 minutes   85.96522889971726%   28580/33246 TOTALS: [1298, 11646, 156, 697]\n",
            "ETA: 2 minutes   86.02538651266318%   28600/33246 TOTALS: [1299, 11653, 156, 700]\n",
            "ETA: 2 minutes   86.08554412560909%   28620/33246 TOTALS: [1300, 11663, 156, 701]\n",
            "ETA: 2 minutes   86.14570173855502%   28640/33246 TOTALS: [1301, 11671, 156, 701]\n",
            "ETA: 2 minutes   86.20585935150093%   28660/33246 TOTALS: [1301, 11682, 156, 703]\n",
            "ETA: 2 minutes   86.26601696444685%   28680/33246 TOTALS: [1303, 11691, 156, 704]\n",
            "ETA: 2 minutes   86.32617457739276%   28700/33246 TOTALS: [1303, 11698, 156, 706]\n",
            "ETA: 2 minutes   86.38633219033869%   28720/33246 TOTALS: [1305, 11704, 156, 706]\n",
            "ETA: 2 minutes   86.4464898032846%   28740/33246 TOTALS: [1306, 11712, 156, 706]\n",
            "ETA: 2 minutes   86.50664741623052%   28760/33246 TOTALS: [1306, 11720, 156, 706]\n",
            "ETA: 2 minutes   86.56680502917644%   28780/33246 TOTALS: [1307, 11729, 156, 706]\n",
            "ETA: 2 minutes   86.62696264212236%   28800/33246 TOTALS: [1309, 11734, 156, 707]\n",
            "ETA: 2 minutes   86.68712025506828%   28820/33246 TOTALS: [1311, 11743, 156, 708]\n",
            "ETA: 2 minutes   86.7472778680142%   28840/33246 TOTALS: [1312, 11751, 156, 708]\n",
            "ETA: 2 minutes   86.80743548096011%   28860/33246 TOTALS: [1312, 11761, 156, 708]\n",
            "ETA: 2 minutes   86.86759309390604%   28880/33246 TOTALS: [1312, 11768, 156, 708]\n",
            "ETA: 2 minutes   86.92775070685195%   28900/33246 TOTALS: [1312, 11775, 156, 709]\n",
            "ETA: 2 minutes   86.98790831979787%   28920/33246 TOTALS: [1312, 11785, 156, 710]\n",
            "ETA: 2 minutes   87.0480659327438%   28940/33246 TOTALS: [1312, 11791, 156, 710]\n",
            "ETA: 2 minutes   87.10822354568971%   28960/33246 TOTALS: [1314, 11804, 156, 711]\n",
            "ETA: 2 minutes   87.16838115863563%   28980/33246 TOTALS: [1315, 11813, 156, 712]\n",
            "ETA: 2 minutes   87.22853877158154%   29000/33246 TOTALS: [1318, 11817, 157, 713]\n",
            "ETA: 2 minutes   87.28869638452747%   29020/33246 TOTALS: [1319, 11823, 157, 713]\n",
            "ETA: 2 minutes   87.34885399747338%   29040/33246 TOTALS: [1320, 11830, 157, 714]\n",
            "ETA: 2 minutes   87.4090116104193%   29060/33246 TOTALS: [1320, 11837, 157, 714]\n",
            "ETA: 2 minutes   87.46916922336521%   29080/33246 TOTALS: [1320, 11841, 157, 715]\n",
            "ETA: 2 minutes   87.52932683631114%   29100/33246 TOTALS: [1323, 11851, 157, 716]\n",
            "ETA: 2 minutes   87.58948444925704%   29120/33246 TOTALS: [1326, 11862, 157, 716]\n",
            "ETA: 2 minutes   87.64964206220297%   29140/33246 TOTALS: [1326, 11871, 157, 717]\n",
            "ETA: 2 minutes   87.70979967514889%   29160/33246 TOTALS: [1327, 11878, 157, 721]\n",
            "ETA: 2 minutes   87.76995728809482%   29180/33246 TOTALS: [1329, 11885, 157, 721]\n",
            "ETA: 2 minutes   87.83011490104073%   29200/33246 TOTALS: [1330, 11889, 157, 721]\n",
            "ETA: 2 minutes   87.89027251398664%   29220/33246 TOTALS: [1330, 11899, 157, 721]\n",
            "ETA: 2 minutes   87.95043012693256%   29240/33246 TOTALS: [1333, 11906, 157, 721]\n",
            "ETA: 2 minutes   88.01058773987847%   29260/33246 TOTALS: [1335, 11916, 157, 721]\n",
            "ETA: 2 minutes   88.0707453528244%   29280/33246 TOTALS: [1336, 11923, 158, 722]\n",
            "ETA: 2 minutes   88.13090296577032%   29300/33246 TOTALS: [1337, 11932, 158, 722]\n",
            "ETA: 2 minutes   88.19106057871625%   29320/33246 TOTALS: [1338, 11940, 158, 723]\n",
            "ETA: 2 minutes   88.25121819166215%   29340/33246 TOTALS: [1338, 11948, 159, 724]\n",
            "ETA: 2 minutes   88.31137580460808%   29360/33246 TOTALS: [1338, 11958, 159, 724]\n",
            "ETA: 2 minutes   88.37153341755399%   29380/33246 TOTALS: [1338, 11966, 159, 724]\n",
            "ETA: 2 minutes   88.43169103049992%   29400/33246 TOTALS: [1338, 11974, 159, 724]\n",
            "ETA: 2 minutes   88.49184864344582%   29420/33246 TOTALS: [1338, 11985, 160, 724]\n",
            "ETA: 2 minutes   88.55200625639175%   29440/33246 TOTALS: [1338, 11994, 160, 724]\n",
            "ETA: 2 minutes   88.61216386933766%   29460/33246 TOTALS: [1338, 12003, 160, 725]\n",
            "ETA: 2 minutes   88.67232148228358%   29480/33246 TOTALS: [1339, 12011, 160, 725]\n",
            "ETA: 2 minutes   88.7324790952295%   29500/33246 TOTALS: [1341, 12017, 160, 726]\n",
            "ETA: 2 minutes   88.79263670817542%   29520/33246 TOTALS: [1341, 12027, 160, 726]\n",
            "ETA: 2 minutes   88.85279432112134%   29540/33246 TOTALS: [1343, 12033, 161, 727]\n",
            "ETA: 2 minutes   88.91295193406725%   29560/33246 TOTALS: [1344, 12042, 161, 727]\n",
            "ETA: 2 minutes   88.97310954701318%   29580/33246 TOTALS: [1346, 12045, 161, 728]\n",
            "ETA: 2 minutes   89.0332671599591%   29600/33246 TOTALS: [1348, 12052, 161, 729]\n",
            "ETA: 2 minutes   89.09342477290501%   29620/33246 TOTALS: [1349, 12058, 162, 729]\n",
            "ETA: 2 minutes   89.15358238585092%   29640/33246 TOTALS: [1349, 12062, 162, 730]\n",
            "ETA: 2 minutes   89.21373999879685%   29660/33246 TOTALS: [1352, 12070, 162, 730]\n",
            "ETA: 2 minutes   89.27389761174277%   29680/33246 TOTALS: [1353, 12079, 162, 731]\n",
            "ETA: 2 minutes   89.33405522468868%   29700/33246 TOTALS: [1354, 12089, 162, 731]\n",
            "ETA: 2 minutes   89.3942128376346%   29720/33246 TOTALS: [1356, 12098, 162, 731]\n",
            "ETA: 2 minutes   89.45437045058053%   29740/33246 TOTALS: [1356, 12108, 162, 732]\n",
            "ETA: 2 minutes   89.51452806352644%   29760/33246 TOTALS: [1358, 12118, 162, 732]\n",
            "ETA: 2 minutes   89.57468567647236%   29780/33246 TOTALS: [1358, 12125, 162, 733]\n",
            "ETA: 2 minutes   89.63484328941827%   29800/33246 TOTALS: [1358, 12133, 162, 735]\n",
            "ETA: 1 minutes   89.6950009023642%   29820/33246 TOTALS: [1358, 12139, 162, 735]\n",
            "ETA: 2 minutes   89.75515851531011%   29840/33246 TOTALS: [1359, 12148, 164, 735]\n",
            "ETA: 2 minutes   89.81531612825603%   29860/33246 TOTALS: [1362, 12156, 164, 735]\n",
            "ETA: 2 minutes   89.87547374120194%   29880/33246 TOTALS: [1362, 12167, 164, 735]\n",
            "ETA: 2 minutes   89.93563135414787%   29900/33246 TOTALS: [1364, 12175, 164, 735]\n",
            "ETA: 2 minutes   89.99578896709379%   29920/33246 TOTALS: [1364, 12184, 164, 735]\n",
            "ETA: 1 minutes   90.0559465800397%   29940/33246 TOTALS: [1364, 12188, 164, 735]\n",
            "ETA: 2 minutes   90.11610419298563%   29960/33246 TOTALS: [1364, 12198, 164, 737]\n",
            "ETA: 1 minutes   90.17626180593155%   29980/33246 TOTALS: [1364, 12208, 164, 737]\n",
            "ETA: 1 minutes   90.23641941887746%   30000/33246 TOTALS: [1365, 12212, 165, 737]\n",
            "ETA: 2 minutes   90.29657703182338%   30020/33246 TOTALS: [1368, 12222, 165, 737]\n",
            "ETA: 2 minutes   90.3567346447693%   30040/33246 TOTALS: [1370, 12232, 165, 738]\n",
            "ETA: 2 minutes   90.4168922577152%   30060/33246 TOTALS: [1371, 12243, 165, 738]\n",
            "ETA: 1 minutes   90.47704987066113%   30080/33246 TOTALS: [1371, 12249, 165, 739]\n",
            "ETA: 2 minutes   90.53720748360705%   30100/33246 TOTALS: [1371, 12257, 165, 741]\n",
            "ETA: 1 minutes   90.59736509655298%   30120/33246 TOTALS: [1372, 12266, 165, 742]\n",
            "ETA: 2 minutes   90.65752270949888%   30140/33246 TOTALS: [1373, 12276, 165, 743]\n",
            "ETA: 1 minutes   90.7176803224448%   30160/33246 TOTALS: [1374, 12283, 165, 744]\n",
            "ETA: 1 minutes   90.77783793539072%   30180/33246 TOTALS: [1375, 12289, 165, 744]\n",
            "ETA: 2 minutes   90.83799554833665%   30200/33246 TOTALS: [1376, 12298, 166, 747]\n",
            "ETA: 1 minutes   90.89815316128255%   30220/33246 TOTALS: [1377, 12306, 166, 748]\n",
            "ETA: 1 minutes   90.95831077422848%   30240/33246 TOTALS: [1378, 12313, 166, 748]\n",
            "ETA: 1 minutes   91.0184683871744%   30260/33246 TOTALS: [1378, 12320, 166, 748]\n",
            "ETA: 1 minutes   91.07862600012031%   30280/33246 TOTALS: [1378, 12327, 166, 749]\n",
            "ETA: 1 minutes   91.13878361306624%   30300/33246 TOTALS: [1381, 12336, 166, 749]\n",
            "ETA: 1 minutes   91.19894122601215%   30320/33246 TOTALS: [1381, 12343, 166, 751]\n",
            "ETA: 1 minutes   91.25909883895808%   30340/33246 TOTALS: [1381, 12352, 167, 751]\n",
            "ETA: 1 minutes   91.31925645190398%   30360/33246 TOTALS: [1383, 12354, 167, 751]\n",
            "ETA: 1 minutes   91.37941406484991%   30380/33246 TOTALS: [1384, 12360, 167, 752]\n",
            "ETA: 1 minutes   91.43957167779583%   30400/33246 TOTALS: [1384, 12369, 167, 752]\n",
            "ETA: 1 minutes   91.49972929074174%   30420/33246 TOTALS: [1385, 12375, 167, 753]\n",
            "ETA: 1 minutes   91.55988690368766%   30440/33246 TOTALS: [1386, 12383, 167, 753]\n",
            "ETA: 1 minutes   91.62004451663358%   30460/33246 TOTALS: [1388, 12388, 167, 754]\n",
            "ETA: 1 minutes   91.6802021295795%   30480/33246 TOTALS: [1390, 12396, 167, 754]\n",
            "ETA: 1 minutes   91.74035974252541%   30500/33246 TOTALS: [1390, 12403, 167, 755]\n",
            "ETA: 1 minutes   91.80051735547133%   30520/33246 TOTALS: [1391, 12411, 168, 755]\n",
            "ETA: 1 minutes   91.86067496841726%   30540/33246 TOTALS: [1393, 12417, 168, 755]\n",
            "ETA: 1 minutes   91.92083258136317%   30560/33246 TOTALS: [1393, 12424, 168, 755]\n",
            "ETA: 1 minutes   91.98099019430909%   30580/33246 TOTALS: [1397, 12430, 168, 755]\n",
            "ETA: 1 minutes   92.04114780725502%   30600/33246 TOTALS: [1397, 12439, 169, 756]\n",
            "ETA: 1 minutes   92.10130542020093%   30620/33246 TOTALS: [1397, 12445, 169, 757]\n",
            "ETA: 1 minutes   92.16146303314684%   30640/33246 TOTALS: [1399, 12455, 169, 758]\n",
            "ETA: 1 minutes   92.22162064609276%   30660/33246 TOTALS: [1399, 12466, 169, 758]\n",
            "ETA: 1 minutes   92.28177825903869%   30680/33246 TOTALS: [1400, 12478, 169, 759]\n",
            "ETA: 1 minutes   92.3419358719846%   30700/33246 TOTALS: [1401, 12486, 169, 759]\n",
            "ETA: 1 minutes   92.40209348493052%   30720/33246 TOTALS: [1403, 12495, 169, 759]\n",
            "ETA: 1 minutes   92.46225109787643%   30740/33246 TOTALS: [1405, 12505, 169, 760]\n",
            "ETA: 1 minutes   92.52240871082236%   30760/33246 TOTALS: [1406, 12516, 169, 761]\n",
            "ETA: 1 minutes   92.58256632376828%   30780/33246 TOTALS: [1406, 12522, 169, 761]\n",
            "ETA: 1 minutes   92.64272393671419%   30800/33246 TOTALS: [1406, 12531, 169, 761]\n",
            "ETA: 1 minutes   92.7028815496601%   30820/33246 TOTALS: [1407, 12536, 169, 761]\n",
            "ETA: 1 minutes   92.76303916260603%   30840/33246 TOTALS: [1410, 12540, 169, 761]\n",
            "ETA: 1 minutes   92.82319677555193%   30860/33246 TOTALS: [1410, 12550, 169, 762]\n",
            "ETA: 1 minutes   92.88335438849786%   30880/33246 TOTALS: [1411, 12564, 169, 762]\n",
            "ETA: 1 minutes   92.94351200144378%   30900/33246 TOTALS: [1413, 12571, 169, 762]\n",
            "ETA: 1 minutes   93.00366961438971%   30920/33246 TOTALS: [1415, 12575, 169, 763]\n",
            "ETA: 1 minutes   93.06382722733562%   30940/33246 TOTALS: [1415, 12580, 169, 765]\n",
            "ETA: 1 minutes   93.12398484028154%   30960/33246 TOTALS: [1415, 12590, 169, 765]\n",
            "ETA: 1 minutes   93.18414245322745%   30980/33246 TOTALS: [1416, 12596, 170, 766]\n",
            "ETA: 1 minutes   93.24430006617337%   31000/33246 TOTALS: [1417, 12603, 170, 768]\n",
            "ETA: 1 minutes   93.3044576791193%   31020/33246 TOTALS: [1417, 12615, 170, 768]\n",
            "ETA: 1 minutes   93.36461529206521%   31040/33246 TOTALS: [1419, 12621, 170, 769]\n",
            "ETA: 1 minutes   93.42477290501114%   31060/33246 TOTALS: [1421, 12633, 170, 770]\n",
            "ETA: 1 minutes   93.48493051795704%   31080/33246 TOTALS: [1424, 12638, 170, 770]\n",
            "ETA: 1 minutes   93.54508813090297%   31100/33246 TOTALS: [1424, 12648, 170, 770]\n",
            "ETA: 1 minutes   93.60524574384888%   31120/33246 TOTALS: [1426, 12656, 170, 771]\n",
            "ETA: 1 minutes   93.66540335679481%   31140/33246 TOTALS: [1427, 12667, 170, 771]\n",
            "ETA: 1 minutes   93.72556096974071%   31160/33246 TOTALS: [1428, 12675, 170, 772]\n",
            "ETA: 1 minutes   93.78571858268664%   31180/33246 TOTALS: [1430, 12679, 170, 773]\n",
            "ETA: 1 minutes   93.84587619563256%   31200/33246 TOTALS: [1430, 12687, 170, 773]\n",
            "ETA: 1 minutes   93.90603380857847%   31220/33246 TOTALS: [1431, 12696, 170, 774]\n",
            "ETA: 1 minutes   93.96619142152439%   31240/33246 TOTALS: [1431, 12705, 170, 775]\n",
            "ETA: 1 minutes   94.02634903447031%   31260/33246 TOTALS: [1431, 12713, 170, 775]\n",
            "ETA: 1 minutes   94.08650664741623%   31280/33246 TOTALS: [1431, 12720, 170, 776]\n",
            "ETA: 1 minutes   94.14666426036214%   31300/33246 TOTALS: [1436, 12724, 170, 776]\n",
            "ETA: 1 minutes   94.20682187330807%   31320/33246 TOTALS: [1437, 12731, 170, 776]\n",
            "ETA: 1 minutes   94.26697948625399%   31340/33246 TOTALS: [1440, 12740, 170, 776]\n",
            "ETA: 1 minutes   94.32713709919992%   31360/33246 TOTALS: [1441, 12750, 171, 777]\n",
            "ETA: 1 minutes   94.38729471214582%   31380/33246 TOTALS: [1442, 12759, 171, 777]\n",
            "ETA: 1 minutes   94.44745232509175%   31400/33246 TOTALS: [1442, 12766, 171, 777]\n",
            "ETA: 1 minutes   94.50760993803766%   31420/33246 TOTALS: [1443, 12776, 171, 777]\n",
            "ETA: 1 minutes   94.56776755098358%   31440/33246 TOTALS: [1444, 12788, 171, 777]\n",
            "ETA: 1 minutes   94.62792516392949%   31460/33246 TOTALS: [1444, 12793, 171, 777]\n",
            "ETA: 1 minutes   94.68808277687542%   31480/33246 TOTALS: [1444, 12802, 172, 777]\n",
            "ETA: 1 minutes   94.74824038982133%   31500/33246 TOTALS: [1445, 12813, 172, 778]\n",
            "ETA: 0 minutes   94.80839800276725%   31520/33246 TOTALS: [1445, 12816, 173, 778]\n",
            "ETA: 1 minutes   94.86855561571316%   31540/33246 TOTALS: [1445, 12825, 174, 778]\n",
            "ETA: 1 minutes   94.92871322865909%   31560/33246 TOTALS: [1446, 12831, 175, 778]\n",
            "ETA: 1 minutes   94.988870841605%   31580/33246 TOTALS: [1447, 12837, 175, 778]\n",
            "ETA: 1 minutes   95.04902845455092%   31600/33246 TOTALS: [1447, 12849, 175, 778]\n",
            "ETA: 1 minutes   95.10918606749684%   31620/33246 TOTALS: [1448, 12860, 175, 778]\n",
            "ETA: 1 minutes   95.16934368044276%   31640/33246 TOTALS: [1448, 12870, 176, 778]\n",
            "ETA: 1 minutes   95.22950129338868%   31660/33246 TOTALS: [1449, 12881, 177, 779]\n",
            "ETA: 1 minutes   95.2896589063346%   31680/33246 TOTALS: [1449, 12894, 177, 779]\n",
            "ETA: 1 minutes   95.34981651928052%   31700/33246 TOTALS: [1449, 12905, 177, 779]\n",
            "ETA: 0 minutes   95.40997413222644%   31720/33246 TOTALS: [1451, 12909, 177, 780]\n",
            "ETA: 0 minutes   95.47013174517235%   31740/33246 TOTALS: [1451, 12919, 177, 780]\n",
            "ETA: 0 minutes   95.53028935811827%   31760/33246 TOTALS: [1451, 12927, 177, 780]\n",
            "ETA: 0 minutes   95.5904469710642%   31780/33246 TOTALS: [1452, 12932, 177, 780]\n",
            "ETA: 0 minutes   95.6506045840101%   31800/33246 TOTALS: [1452, 12946, 177, 780]\n",
            "ETA: 0 minutes   95.71076219695603%   31820/33246 TOTALS: [1453, 12954, 177, 780]\n",
            "ETA: 0 minutes   95.77091980990194%   31840/33246 TOTALS: [1453, 12963, 177, 780]\n",
            "ETA: 0 minutes   95.83107742284787%   31860/33246 TOTALS: [1453, 12972, 177, 780]\n",
            "ETA: 0 minutes   95.89123503579377%   31880/33246 TOTALS: [1454, 12980, 177, 780]\n",
            "ETA: 0 minutes   95.9513926487397%   31900/33246 TOTALS: [1454, 12990, 177, 782]\n",
            "ETA: 0 minutes   96.01155026168561%   31920/33246 TOTALS: [1456, 12995, 179, 783]\n",
            "ETA: 0 minutes   96.07170787463154%   31940/33246 TOTALS: [1456, 13005, 179, 784]\n",
            "ETA: 0 minutes   96.13186548757746%   31960/33246 TOTALS: [1457, 13013, 179, 784]\n",
            "ETA: 0 minutes   96.19202310052337%   31980/33246 TOTALS: [1460, 13023, 179, 784]\n",
            "ETA: 0 minutes   96.25218071346929%   32000/33246 TOTALS: [1461, 13030, 179, 784]\n",
            "ETA: 0 minutes   96.3123383264152%   32020/33246 TOTALS: [1461, 13041, 179, 785]\n",
            "ETA: 0 minutes   96.37249593936113%   32040/33246 TOTALS: [1461, 13049, 179, 786]\n",
            "ETA: 0 minutes   96.43265355230704%   32060/33246 TOTALS: [1461, 13055, 179, 786]\n",
            "ETA: 0 minutes   96.49281116525297%   32080/33246 TOTALS: [1463, 13059, 179, 786]\n",
            "ETA: 0 minutes   96.55296877819887%   32100/33246 TOTALS: [1464, 13068, 179, 787]\n",
            "ETA: 0 minutes   96.6131263911448%   32120/33246 TOTALS: [1465, 13076, 179, 787]\n",
            "ETA: 0 minutes   96.67328400409072%   32140/33246 TOTALS: [1466, 13083, 179, 787]\n",
            "ETA: 0 minutes   96.73344161703663%   32160/33246 TOTALS: [1468, 13095, 179, 787]\n",
            "ETA: 0 minutes   96.79359922998255%   32180/33246 TOTALS: [1470, 13102, 179, 788]\n",
            "ETA: 0 minutes   96.85375684292848%   32200/33246 TOTALS: [1470, 13112, 179, 788]\n",
            "ETA: 0 minutes   96.91391445587439%   32220/33246 TOTALS: [1471, 13121, 179, 789]\n",
            "ETA: 0 minutes   96.9740720688203%   32240/33246 TOTALS: [1473, 13135, 179, 789]\n",
            "ETA: 0 minutes   97.03422968176622%   32260/33246 TOTALS: [1474, 13143, 179, 790]\n",
            "ETA: 0 minutes   97.09438729471215%   32280/33246 TOTALS: [1475, 13147, 179, 791]\n",
            "ETA: 0 minutes   97.15454490765806%   32300/33246 TOTALS: [1476, 13157, 179, 791]\n",
            "ETA: 0 minutes   97.21470252060398%   32320/33246 TOTALS: [1479, 13164, 179, 791]\n",
            "ETA: 0 minutes   97.27486013354991%   32340/33246 TOTALS: [1479, 13174, 179, 792]\n",
            "ETA: 0 minutes   97.33501774649582%   32360/33246 TOTALS: [1480, 13181, 179, 793]\n",
            "ETA: 0 minutes   97.39517535944174%   32380/33246 TOTALS: [1481, 13189, 180, 793]\n",
            "ETA: 0 minutes   97.45533297238765%   32400/33246 TOTALS: [1482, 13197, 180, 794]\n",
            "ETA: 0 minutes   97.51549058533358%   32420/33246 TOTALS: [1484, 13204, 180, 794]\n",
            "ETA: 0 minutes   97.5756481982795%   32440/33246 TOTALS: [1484, 13212, 180, 794]\n",
            "ETA: 0 minutes   97.63580581122541%   32460/33246 TOTALS: [1484, 13224, 181, 795]\n",
            "ETA: 0 minutes   97.69596342417132%   32480/33246 TOTALS: [1484, 13228, 181, 796]\n",
            "ETA: 0 minutes   97.75612103711725%   32500/33246 TOTALS: [1484, 13235, 181, 798]\n",
            "ETA: 0 minutes   97.81627865006317%   32520/33246 TOTALS: [1484, 13246, 181, 800]\n",
            "ETA: 0 minutes   97.87643626300908%   32540/33246 TOTALS: [1486, 13255, 181, 800]\n",
            "ETA: 0 minutes   97.936593875955%   32560/33246 TOTALS: [1487, 13263, 182, 800]\n",
            "ETA: 0 minutes   97.99675148890093%   32580/33246 TOTALS: [1488, 13271, 183, 800]\n",
            "ETA: 0 minutes   98.05690910184683%   32600/33246 TOTALS: [1489, 13279, 183, 801]\n",
            "ETA: 0 minutes   98.11706671479276%   32620/33246 TOTALS: [1489, 13287, 183, 801]\n",
            "ETA: 0 minutes   98.17722432773867%   32640/33246 TOTALS: [1490, 13297, 183, 801]\n",
            "ETA: 0 minutes   98.2373819406846%   32660/33246 TOTALS: [1492, 13302, 183, 801]\n",
            "ETA: 0 minutes   98.29753955363051%   32680/33246 TOTALS: [1493, 13310, 183, 801]\n",
            "ETA: 0 minutes   98.35769716657643%   32700/33246 TOTALS: [1493, 13320, 183, 801]\n",
            "ETA: 0 minutes   98.41785477952236%   32720/33246 TOTALS: [1494, 13333, 183, 802]\n",
            "ETA: 0 minutes   98.47801239246826%   32740/33246 TOTALS: [1497, 13340, 183, 802]\n",
            "ETA: 0 minutes   98.53817000541419%   32760/33246 TOTALS: [1499, 13347, 183, 802]\n",
            "ETA: 0 minutes   98.5983276183601%   32780/33246 TOTALS: [1499, 13358, 183, 803]\n",
            "ETA: 0 minutes   98.65848523130603%   32800/33246 TOTALS: [1501, 13367, 183, 803]\n",
            "ETA: 0 minutes   98.71864284425193%   32820/33246 TOTALS: [1501, 13375, 183, 803]\n",
            "ETA: 0 minutes   98.77880045719786%   32840/33246 TOTALS: [1502, 13382, 183, 803]\n",
            "ETA: 0 minutes   98.83895807014378%   32860/33246 TOTALS: [1502, 13388, 184, 803]\n",
            "ETA: 0 minutes   98.8991156830897%   32880/33246 TOTALS: [1504, 13393, 184, 804]\n",
            "ETA: 0 minutes   98.9592732960356%   32900/33246 TOTALS: [1505, 13404, 184, 805]\n",
            "ETA: 0 minutes   99.01943090898153%   32920/33246 TOTALS: [1505, 13416, 184, 805]\n",
            "ETA: 0 minutes   99.07958852192745%   32940/33246 TOTALS: [1506, 13422, 184, 807]\n",
            "ETA: 0 minutes   99.13974613487336%   32960/33246 TOTALS: [1507, 13429, 185, 810]\n",
            "ETA: 0 minutes   99.19990374781929%   32980/33246 TOTALS: [1510, 13439, 186, 812]\n",
            "ETA: 0 minutes   99.2600613607652%   33000/33246 TOTALS: [1511, 13449, 186, 813]\n",
            "ETA: 0 minutes   99.32021897371112%   33020/33246 TOTALS: [1514, 13451, 186, 815]\n",
            "ETA: 0 minutes   99.38037658665704%   33040/33246 TOTALS: [1516, 13458, 186, 816]\n",
            "ETA: 0 minutes   99.44053419960296%   33060/33246 TOTALS: [1517, 13465, 186, 817]\n",
            "ETA: 0 minutes   99.50069181254888%   33080/33246 TOTALS: [1520, 13471, 186, 818]\n",
            "ETA: 0 minutes   99.56084942549481%   33100/33246 TOTALS: [1520, 13478, 186, 819]\n",
            "ETA: 0 minutes   99.62100703844071%   33120/33246 TOTALS: [1520, 13487, 186, 820]\n",
            "ETA: 0 minutes   99.68116465138664%   33140/33246 TOTALS: [1520, 13495, 186, 822]\n",
            "ETA: 0 minutes   99.74132226433255%   33160/33246 TOTALS: [1520, 13505, 186, 822]\n",
            "ETA: 0 minutes   99.80147987727847%   33180/33246 TOTALS: [1520, 13510, 186, 822]\n",
            "ETA: 0 minutes   99.86163749022438%   33200/33246 TOTALS: [1522, 13521, 186, 824]\n",
            "ETA: 0 minutes   99.92179510317031%   33220/33246 TOTALS: [1523, 13526, 186, 825]\n",
            "ETA: 0 minutes   99.98195271611623%   33240/33246 TOTALS: [1525, 13537, 187, 825]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7f3b42e3d98b>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaved_image\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/PATCH_LOCALS/game\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "#1. Load Images From file\n",
        "from torchvision.io import read_image\n",
        "from torchvision.utils import draw_keypoints\n",
        "import torchvision.transforms.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import csv\n",
        "\n",
        "def show(imgs):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
        "    for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    plt.show()\n",
        "\n",
        "def classify(new):\n",
        "  global totals\n",
        "  front = False\n",
        "  body = False\n",
        "\n",
        "  #Find front\n",
        "  if any(element > 12 for element in new[:3]):#If face features have high confidence\n",
        "    front = True\n",
        "  elif new[5]<6 and new[6]<6:# If no shoulders then don't use this\n",
        "    return \"bad\"\n",
        "\n",
        "  #Find legs and shoulders\n",
        "  if any(element > 6 for element in new[-6:]) and any(element > 8 for element in new[:6]):\n",
        "    body = True\n",
        "  #Classify each\n",
        "  if front:\n",
        "    if body:\n",
        "      classification = \"FULL-BODY-FRONT-VIEW\"\n",
        "      totals[0]+=1\n",
        "    else:\n",
        "      classification = \"HEAD-AND-SHOULDER-FRONT-VIEW\"\n",
        "      totals[1]+=1\n",
        "  else:\n",
        "    if body:\n",
        "      classification = \"FULL-BODY-BACK-VIEW\"\n",
        "      totals[2]+=1\n",
        "    else:\n",
        "      classification = \"HEAD-AND-SHOULDER-BACK-VIEW\"\n",
        "      totals[3]+=1\n",
        "\n",
        "  return classification\n",
        "\n",
        "\n",
        "\n",
        "totals = [0,0,0,0]\n",
        "batch_size = 20\n",
        "now=time.time()\n",
        "#USE BATCH SIZE OF 50\n",
        "\n",
        "#IRISHMAN 3300,4400\n",
        "imgs=os.listdir(\"/content/PATCH_LOCALS/game\")\n",
        "print(len(imgs))\n",
        "\n",
        "for saved_image in range(0,len(imgs),batch_size):\n",
        "\n",
        "  elapsed = time.time()-now\n",
        "  now = time.time()\n",
        "  #SAVE HERE:\n",
        "  percent = ((saved_image/len(imgs))*100)\n",
        "  print(\"ETA: \"+str(int((elapsed/60)*((len(imgs)-saved_image)/batch_size)))+\" minutes   \"+str(percent)+\"%   \"+str(saved_image)+\"/\"+str(len(imgs))+\" TOTALS: \"+str(totals))\n",
        "\n",
        "  images=[]\n",
        "  for im in range(saved_image,saved_image+batch_size):\n",
        "    image = read_image(os.path.join(\"/content/PATCH_LOCALS/game\",imgs[im])).to(device)\n",
        "    images.append(image)\n",
        "\n",
        "  #2. Detect key points\n",
        "  person_float = torch.stack([transforms(img).to(device) for img in images])  # Stack images and move to device\n",
        "  #person_float = transforms(image)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(person_float)\n",
        "\n",
        "  counter=0\n",
        "  for output in outputs:\n",
        "    kpts = output['keypoints'][:1]\n",
        "    kpts_scores = output[\"keypoints_scores\"][:1]\n",
        "    scores = output['scores'][:1]\n",
        "\n",
        "    detect_threshold = 0.991\n",
        "    idx = torch.where(scores > detect_threshold)\n",
        "    keypoints = kpts[idx]\n",
        "    keypoint_scores = kpts_scores[idx]\n",
        "\n",
        "\n",
        "    if len(keypoints)>0:\n",
        "      new = keypoint_scores.cpu().numpy()[0]\n",
        "\n",
        "      positions = keypoints.cpu().numpy()[0].tolist()\n",
        "\n",
        "\n",
        "\n",
        "      #3. Put image into a file based upon key points\n",
        "      #IF IMAGE CONTAINS HIGH CONFIDENCE ON THE HIPS,KNEES or ANKLES THEN FULL BODY\n",
        "      #IF IMAGE CONTAINS FACE INFORMATION THEN FRONT VIEW\n",
        "      classification=classify(new)\n",
        "      if classification!=\"bad\":\n",
        "        #Change the CSV depending on whether it's game or move\n",
        "        filename = \"game/\"+str(classification)+\"/\"+imgs[saved_image+counter]\n",
        "        new_row = [filename,classification]+positions\n",
        "        #Add this score to a CSV, with filename, scores.\n",
        "        with open('/content/drive/MyDrive/PATCHES/GAME_POSE.csv','a') as fd:\n",
        "          # Create a CSV writer object\n",
        "          writer = csv.writer(fd)\n",
        "          # Write the list as a row\n",
        "          writer.writerow(new_row)\n",
        "        PIL_image = images[counter].detach().cpu()\n",
        "        PIL_image = F.to_pil_image(PIL_image)\n",
        "        PIL_image.save(\"/content/drive/MyDrive/PATCHES/classified/\"+filename)\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        for i in range(len(new)):\n",
        "          print(str(coco_keypoints[i])+\" \"+str(new[i]))\n",
        "        print(classification)\n",
        "        #USED TO DRAW THE PLOT AND SHOW CLASSIFICATION\n",
        "        res = draw_keypoints(images[counter], keypoints, colors=\"blue\", radius=3)\n",
        "        show(res)\n",
        "        \"\"\"\n",
        "    counter+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxRCMqAPKZst"
      },
      "source": [
        "### 1.3 Training Data Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4sardVse4yM"
      },
      "outputs": [],
      "source": [
        "#! rm -rf /content/PATCH_LOCALS/game\n",
        "\n",
        "#! cp -r /content/drive/MyDrive/PATCHES/game /content/PATCH_LOCALS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WwEzeNXN1e6I",
        "outputId": "156f86d4-9c04-4a9c-a50e-138c9f7b0ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At Image: 1500\n",
            "At Image: 1600\n",
            "At Image: 1700\n",
            "At Image: 1800\n",
            "At Image: 1900\n",
            "At Image: 2000\n",
            "At Image: 2100\n",
            "At Image: 2200\n",
            "At Image: 2300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-2-1e0f90157938>\", line 68, in <cell line: 49>\n",
            "    with open(\"/content/drive/MyDrive/PATCHES/PAIRS.csv\",\"a\") as file:\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 431, in _joinrealpath\n",
            "    st = os.lstat(newpath)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1e0f90157938>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/PATCHES/PAIRS.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Create a CSV writer object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "# Find pairs of similar images using similarity scores or feature positions maybe!\n",
        "# Find high confidence scores for features!\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "#FIND GOOD PAIRS OF IMAGES, FEATURES IN SIMILAR LOCATIONS, find similarity scores of these\n",
        "#Open CSV files and find high cosine similarity scores. Pick a threshold and rank all connections!\n",
        "#Find similar images in movie data to test\n",
        "\n",
        "def show(imgs):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
        "    for i, img in enumerate(imgs):\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    plt.show()\n",
        "\n",
        "def convert(row):\n",
        "  new_row=[]\n",
        "  for item in row:\n",
        "    new = ast.literal_eval(item)\n",
        "    new_row.append(new[0])\n",
        "    new_row.append(new[1])\n",
        "  return new_row\n",
        "\n",
        "#1. Load Movie CSV\n",
        "movie_data=[]\n",
        "with open('/content/drive/MyDrive/PATCHES/MOVIE_POSE.csv',\"r\") as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    for row in csv_reader:\n",
        "        new_row = row[:2]+convert(row[2:])\n",
        "        movie_data.append(new_row)\n",
        "\n",
        "\n",
        "#2. Load Game CSV\n",
        "game_data=[]\n",
        "with open('/content/drive/MyDrive/PATCHES/GAME_POSE.csv',\"r\") as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    for row in csv_reader:\n",
        "        new_row = row[:2]+convert(row[2:])\n",
        "        game_data.append(new_row)\n",
        "\n",
        "game_data_array = np.array(game_data)\n",
        "\n",
        "\n",
        "#3. Find Most Similar Pais, remove them and add to a new array!\n",
        "for i,image in enumerate(movie_data):\n",
        "  if i>2400:\n",
        "    similarities = []\n",
        "    sims = cosine_similarity([image[2:]], game_data_array[:, 2:])\n",
        "    max_index = np.argmax(sims)\n",
        "\n",
        "\n",
        "    #Add names to pairs\n",
        "    movie_name = movie_data[i][0]\n",
        "    game_name = game_data[max_index][0]\n",
        "\n",
        "\n",
        "\n",
        "    #DRAW PAIRS\n",
        "    #mov=Image.open(\"/content/PATCH_LOCALS/movie/\"+movie_name.split(\"/\")[-1])\n",
        "    #gam=Image.open(\"/content/PATCH_LOCALS/game/\"+game_name.split(\"/\")[-1])\n",
        "\n",
        "    pair=[\"/content/PATCH_LOCALS/movie/\"+movie_name.split(\"/\")[-1],\"/content/PATCH_LOCALS/game/\"+game_name.split(\"/\")[-1]]\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/PATCHES/PAIRS.csv\",\"a\") as file:\n",
        "        # Create a CSV writer object\n",
        "        writer = csv.writer(file)\n",
        "        # Write the list as a row\n",
        "        writer.writerow(pair)\n",
        "\n",
        "    if i%100==0:\n",
        "      print(\"At Image: \"+str(i))\n",
        "  \"\"\"\n",
        "  show(mov)\n",
        "  show(gam)\n",
        "  \"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bL2jVbdKQah"
      },
      "source": [
        "## 2. Real-World Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0ZNJ551KgGc"
      },
      "source": [
        "### 2.1 Image Model Deployment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj8U3cwy4S5H",
        "outputId": "5ed08051-b47b-43f2-e544-cc2e63469714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from scikit-video) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY3_ts5PKtAA",
        "outputId": "5389c0f5-00e6-44c7-8dec-65cd9081fbf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We're using => cuda\n",
            "Thu May  2 05:15:39 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              23W / 300W |      2MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#FIND A WAY TO DO THIS AND THEN WE CAN EASILY APPLY IT TO THE NEXT QUESTION!\n",
        "\n",
        "#IMAGE to IMAGE (CYCLEGAN)\n",
        "#BETWEEN GAME AND MOVIE DOMAINS\n",
        "import torch\n",
        "import skvideo.io\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"We're using =>\", device)\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IETPUMokNbmJ"
      },
      "source": [
        "#### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQD9n4452KPY",
        "outputId": "393325c0-f864-4833-afd4-c87539c98449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15654\n",
            "33246\n"
          ]
        }
      ],
      "source": [
        "#GET MOVIE FOOTAGE AND GAME FOOTAGE LOADED HERE AS IMAGES\n",
        "#https://github.com/ylongresearch/COMP4107-ACV/blob/main/CAT2DOG_solution.ipynb\n",
        "#https://pytorch.org/vision/stable/auto_examples/others/plot_visualization_utils.html#keypoint-output\n",
        "\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Copy data to COLAB DISK to speed up ALOT\n",
        "#! cp -r /content/drive/MyDrive/PATCHES/movie /content/PATCH_LOCALS\n",
        "#! rm -rf /content/PATCH_LOCALS/game\n",
        "#! cp -r /content/drive/MyDrive/PATCHES/game /content/PATCH_LOCALS\n",
        "\n",
        "\n",
        "np.float = np.float64\n",
        "np.int = np.int_\n",
        "\n",
        "transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=200, height=200),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "     ]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "class PBdataset(Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    self.movie_files = X\n",
        "    self.game_files = Y\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #Read the next x frames here\n",
        "    movie_image = np.array(Image.open(os.path.join(\"/content/PATCH_LOCALS/movie\",self.movie_files[index])).convert(\"RGB\"))\n",
        "    game_image = np.array(Image.open(os.path.join(\"/content/PATCH_LOCALS/game\",self.game_files[index])).convert(\"RGB\"))\n",
        "    X=self.transform(image=movie_image)[\"image\"]\n",
        "    Y=self.transform(image=game_image)[\"image\"]\n",
        "    return X,Y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.movie_files)\n",
        "\n",
        "\n",
        "\n",
        "#1. LOAD MOVIE IMAGES\n",
        "movie_files = os.listdir(\"/content/PATCH_LOCALS/movie\")\n",
        "#movie_data = skvideo.io.vread(\"/content/drive/MyDrive/Data/Train/movie/TheSopranos.mp4\",num_frames=2000)\n",
        "print(len(movie_files))\n",
        "\n",
        "#2. LOAD GAME IMAGES\n",
        "game_files = os.listdir(\"/content/PATCH_LOCALS/game\")\n",
        "#game_data = skvideo.io.vread(\"/content/drive/MyDrive/Data/Train/game/MafiaVideogame.mp4\",num_frames=2000)\n",
        "print(len(game_files))\n",
        "random.shuffle(game_files)\n",
        "game_files = game_files[:len(movie_files)]\n",
        "\n",
        "#3. TURN INTO TRAINING AND TESTING DATA\n",
        "movie_train,movie_test,game_train,game_test = train_test_split(movie_files, game_files, test_size=0.2, random_state=42)\n",
        "\n",
        "batch_size = 64\n",
        "trainset = PBdataset(movie_train, game_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testset = PBdataset(movie_test, game_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmCqZV4LNXfB"
      },
      "source": [
        "#### Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srouPrBUDMA_"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
        "            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_channels, num_features = 16, num_residuals=3):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
        "            nn.InstanceNorm2d(num_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.down_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n",
        "                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n",
        "            ]\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
        "        )\n",
        "        self.up_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "                ConvBlock(num_features*2, num_features*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.last = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        for layer in self.down_blocks:\n",
        "            x = layer(x)\n",
        "        x = self.res_blocks(x)\n",
        "        for layer in self.up_blocks:\n",
        "            x = layer(x)\n",
        "        return torch.tanh(self.last(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcG8oGlkNZVC"
      },
      "source": [
        "#### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZehoO2rDLJw"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode=\"reflect\"),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[32, 64]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                features[0],\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(Block(in_channels, feature, stride=1 if feature==features[-1] else 2))\n",
        "            in_channels = feature\n",
        "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        return torch.sigmoid(self.model(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSuSlZYlNTzh"
      },
      "source": [
        "#### Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpybzR2FxsN7"
      },
      "outputs": [],
      "source": [
        "import random, torch, os, numpy as np\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjdxa9BrDFgn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "LEARNING_RATE = 1e-5\n",
        "LAMBDA_IDENTITY = 0.0\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_EPOCHS = 1000\n",
        "LOAD_MODEL = True\n",
        "SAVE_MODEL = True\n",
        "CHECKPOINT_GEN_H = \"/content/drive/MyDrive/PATCHES/cycleGAN/genh.pth.tar\"\n",
        "CHECKPOINT_GEN_Z = \"/content/drive/MyDrive/PATCHES/cycleGAN/genz.pth.tar\"\n",
        "CHECKPOINT_CRITIC_H = \"/content/drive/MyDrive/PATCHES/cycleGAN/critich.pth.tar\"\n",
        "CHECKPOINT_CRITIC_Z = \"/content/drive/MyDrive/PATCHES/cycleGAN/criticz.pth.tar\"\n",
        "\n",
        "def train_fn(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler):\n",
        "    H_reals = 0\n",
        "    H_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (cat, dog) in enumerate(loop):\n",
        "        cat = cat.to(device)\n",
        "        dog = dog.to(device)\n",
        "\n",
        "        # Train Discriminators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_dog = gen_H(cat)\n",
        "            D_H_real = disc_H(dog)\n",
        "            D_H_fake = disc_H(fake_dog.detach())\n",
        "            H_reals += D_H_real.mean().item()\n",
        "            H_fakes += D_H_fake.mean().item()\n",
        "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
        "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
        "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
        "\n",
        "            fake_cat = gen_Z(dog)\n",
        "            D_Z_real = disc_Z(cat)\n",
        "            D_Z_fake = disc_Z(fake_cat.detach())\n",
        "            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
        "            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
        "            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_H_loss + D_Z_loss)/2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_H_fake = disc_H(fake_dog)\n",
        "            D_Z_fake = disc_Z(fake_cat)\n",
        "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
        "            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_cat = gen_Z(fake_dog)\n",
        "            cycle_dog = gen_H(fake_cat)\n",
        "            cycle_cat_loss = l1(cat, cycle_cat)\n",
        "            cycle_dog_loss = l1(dog, cycle_dog)\n",
        "\n",
        "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
        "            identity_cat = gen_Z(cat)\n",
        "            identity_dog = gen_H(dog)\n",
        "            identity_cat_loss = l1(cat, identity_cat)\n",
        "            identity_dog_loss = l1(dog, identity_dog)\n",
        "\n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_Z\n",
        "                + loss_G_H\n",
        "                + cycle_cat_loss * LAMBDA_CYCLE\n",
        "                + cycle_dog_loss * LAMBDA_CYCLE\n",
        "                + identity_dog_loss * LAMBDA_IDENTITY\n",
        "                + identity_cat_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            save_image(fake_dog*0.5+0.5, \"/content/drive/MyDrive/style_transfer/cycleGAN/movie\"+str(idx)+\".png\")\n",
        "            save_image(fake_cat*0.5+0.5, \"/content/drive/MyDrive/style_transfer/cycleGAN/game\"+str(idx)+\".png\")\n",
        "\n",
        "        loop.set_postfix(H_real=H_reals/(idx+1), H_fake=H_fakes/(idx+1))\n",
        "        with open(\"/content/drive/MyDrive/style_transfer/cycleGAN_training.csv\",\"a\") as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerow([H_fakes/(idx+1),H_reals/(idx+1)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pg2Idv0C6Df"
      },
      "source": [
        "#### Main CycleGAN Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1PqIhGxt2bEh",
        "outputId": "123e8f54-f441-49f0-f28c-20ffc578c2cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.494, H_real=0.508]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:27<00:00,  1.33it/s, H_fake=0.449, H_real=0.487]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:27<00:00,  1.32it/s, H_fake=0.437, H_real=0.498]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:27<00:00,  1.33it/s, H_fake=0.429, H_real=0.513]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:28<00:00,  1.32it/s, H_fake=0.416, H_real=0.524]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:28<00:00,  1.32it/s, H_fake=0.404, H_real=0.534]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:28<00:00,  1.32it/s, H_fake=0.391, H_real=0.545]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:27<00:00,  1.33it/s, H_fake=0.376, H_real=0.558]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:27<00:00,  1.33it/s, H_fake=0.358, H_real=0.571]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:27<00:00,  1.33it/s, H_fake=0.341, H_real=0.585]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:28<00:00,  1.32it/s, H_fake=0.325, H_real=0.599]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:28<00:00,  1.32it/s, H_fake=0.311, H_real=0.613]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.297, H_real=0.625]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:28<00:00,  1.32it/s, H_fake=0.297, H_real=0.633]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.31it/s, H_fake=0.389, H_real=0.583]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.413, H_real=0.533]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.398, H_real=0.544]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.387, H_real=0.572]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.379, H_real=0.583]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.375, H_real=0.588]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.379, H_real=0.593]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.383, H_real=0.595]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.391, H_real=0.597]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.395, H_real=0.595]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.32it/s, H_fake=0.397, H_real=0.591]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.394, H_real=0.588]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.39, H_real=0.586]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.386, H_real=0.586]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.383, H_real=0.587]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.381, H_real=0.589]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.379, H_real=0.59]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.375, H_real=0.592]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.371, H_real=0.595]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.367, H_real=0.599]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.362, H_real=0.602]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.359, H_real=0.606]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.355, H_real=0.609]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.351, H_real=0.612]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.348, H_real=0.614]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.345, H_real=0.617]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.31it/s, H_fake=0.342, H_real=0.619]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.341, H_real=0.621]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.338, H_real=0.622]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.337, H_real=0.625]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.334, H_real=0.626]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.332, H_real=0.629]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.33, H_real=0.63]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.328, H_real=0.632]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.326, H_real=0.633]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.324, H_real=0.635]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.322, H_real=0.637]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.32, H_real=0.639]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:31<00:00,  1.30it/s, H_fake=0.319, H_real=0.641]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.31it/s, H_fake=0.317, H_real=0.643]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.31it/s, H_fake=0.315, H_real=0.645]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.31it/s, H_fake=0.314, H_real=0.647]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.313, H_real=0.648]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.312, H_real=0.649]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.312, H_real=0.651]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.312, H_real=0.652]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.31it/s, H_fake=0.311, H_real=0.653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.311, H_real=0.653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.312, H_real=0.653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.313, H_real=0.654]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:29<00:00,  1.31it/s, H_fake=0.314, H_real=0.653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.30it/s, H_fake=0.316, H_real=0.653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [02:30<00:00,  1.31it/s, H_fake=0.317, H_real=0.652]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 136/196 [01:46<00:47,  1.28it/s, H_fake=0.318, H_real=0.652]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-fba3f7525df2>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT_CRITIC_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_Z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT_CRITIC_Z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-fba3f7525df2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_Z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_Z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSAVE_MODEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT_GEN_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-8036fdbdca79>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdog\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-a8e414a48777>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#Read the next x frames here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmovie_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/PATCH_LOCALS/movie\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mgame_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/PATCH_LOCALS/game\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmovie_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgame_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def main():\n",
        "\n",
        "    disc_H = Discriminator(in_channels=3).to(device)\n",
        "    disc_Z = Discriminator(in_channels=3).to(device)\n",
        "    gen_Z = Generator(img_channels=3, num_residuals=4).to(device)\n",
        "    gen_H = Generator(img_channels=3, num_residuals=4).to(device)\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_H, gen_H, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_Z, gen_Z, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_H, disc_H, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_Z, disc_Z, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(disc_H, disc_Z, gen_Z, gen_H, trainloader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)\n",
        "        if SAVE_MODEL:\n",
        "            save_checkpoint(gen_H, opt_gen, filename=CHECKPOINT_GEN_H)\n",
        "            save_checkpoint(gen_Z, opt_gen, filename=CHECKPOINT_GEN_Z)\n",
        "            save_checkpoint(disc_H, opt_disc, filename=CHECKPOINT_CRITIC_H)\n",
        "            save_checkpoint(disc_Z, opt_disc, filename=CHECKPOINT_CRITIC_Z)\n",
        "main()\n",
        "\n",
        "\n",
        "#Tweak parameters to work best\n",
        "#Set up automatic training, with unlimited EPOCHS!\n",
        "#Create a way to analyse this saved model\n",
        "#Run the images through!!!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egerjuQm_cxt"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5BpYqE6_eGm"
      },
      "outputs": [],
      "source": [
        "#Create evaluation function, can use this on the unfinished model!! And also the other model!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNTMm2H-KmED"
      },
      "source": [
        "### 2.2 Local (temporal) Enhancement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdE9BbWRcrBb"
      },
      "source": [
        "### Testing on Model 2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CT1J9fpzKtRT"
      },
      "outputs": [],
      "source": [
        "#1. TEST 2.1 MODEL ON TEST VIDEO\n",
        "#Using the saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlduxgiz_U_i"
      },
      "outputs": [],
      "source": [
        "#2. ADD TEMPORAL ENCHANCEMENT, USING PART 1\n",
        "# Basically, also train it using paired image patches\n",
        "#cGAN\n",
        "#Conditional GAN model using U-Net: Paired Image Translation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dryRpdUccuhl"
      },
      "source": [
        "### Conditional GAN (cGAN): Paired Image Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De652l-Sa1_-"
      },
      "source": [
        "#### Custom Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I7qfcTftGdU",
        "outputId": "6b9b1c23-9cd5-4a55-bd67-e89497018bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We're using => cuda\n",
            "Thu May  2 10:03:16 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              23W / 300W |      2MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import skvideo.io\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"We're using =>\", device)\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmjOG7EPa4B5",
        "outputId": "82250d62-e44a-41c1-8c65-24c7e26bac89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2387\n",
            "2387\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, time, json\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from typing import List, Tuple, Dict\n",
        "from statistics import mean\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "#https://www.kaggle.com/code/kooose/pix2pix-pytorch\n",
        "\n",
        "\n",
        "np.float = np.float64\n",
        "np.int = np.int_\n",
        "\n",
        "transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=64, height=64),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "     ]\n",
        ")\n",
        "\n",
        "class PBdataset(Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    self.movie_files = X\n",
        "    self.game_files = Y\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #Read the next x frames here\n",
        "    movie_image = np.array(Image.open(self.movie_files[index]).convert(\"RGB\"))\n",
        "    game_image = np.array(Image.open(self.game_files[index]).convert(\"RGB\"))\n",
        "    X=self.transform(image=movie_image)[\"image\"]\n",
        "    Y=self.transform(image=game_image)[\"image\"]\n",
        "    return X.to(device),Y.to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.movie_files)\n",
        "\n",
        "\n",
        "\n",
        "#1. LOAD MOVIE AND GAME FILES\n",
        "movie_files=[]\n",
        "game_files=[]\n",
        "#Get lists from pairs\n",
        "with open(\"/content/drive/MyDrive/PATCHES/PAIRS.csv\",\"r\") as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        # Append the value of the first column to column1_values list\n",
        "        movie_files.append(row[0])\n",
        "        # Append the value of the second column to column2_values list\n",
        "        game_files.append(row[1])\n",
        "\n",
        "\n",
        "print(len(movie_files))\n",
        "print(len(game_files))\n",
        "\n",
        "#2. TURN INTO TRAINING AND TESTING DATA\n",
        "movie_train,movie_test,game_train,game_test = train_test_split(movie_files, game_files, test_size=0.2, random_state=42)\n",
        "\n",
        "batch_size = 64\n",
        "trainset = PBdataset(movie_train, game_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testset = PBdataset(movie_test, game_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6AcXbbba4Q1"
      },
      "source": [
        "#### Generator: U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe5fj2oVa7MX"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.enc1 = self.conv2Relu(3, 32, 5)\n",
        "        self.enc2 = self.conv2Relu(32, 64, pool_size=4)\n",
        "        self.enc3 = self.conv2Relu(64, 128, pool_size=2)\n",
        "        self.enc4 = self.conv2Relu(128, 256, pool_size=2)\n",
        "\n",
        "        self.dec1 = self.deconv2Relu(256, 128, pool_size=2)\n",
        "        self.dec2 = self.deconv2Relu(128+128, 64, pool_size=2)\n",
        "        self.dec3 = self.deconv2Relu(64+64, 32, pool_size=4)\n",
        "        self.dec4 = nn.Sequential(\n",
        "            nn.Conv2d(32+32, 3, 5, padding=2),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def conv2Relu(self, in_c, out_c, kernel_size=3, pool_size=None):\n",
        "        layer = []\n",
        "        if pool_size:\n",
        "            # Down width and height\n",
        "            layer.append(nn.AvgPool2d(pool_size))\n",
        "        # Up channel size\n",
        "        layer.append(nn.Conv2d(in_c, out_c, kernel_size, padding=(kernel_size-1)//2))\n",
        "        layer.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        layer.append(nn.BatchNorm2d(out_c))\n",
        "        layer.append(nn.ReLU(inplace=True))\n",
        "        return nn.Sequential(*layer)\n",
        "\n",
        "    def deconv2Relu(self, in_c, out_c, kernel_size=3, stride=1, pool_size=None):\n",
        "        layer = []\n",
        "        if pool_size:\n",
        "            # Up width and height\n",
        "            layer.append(nn.UpsamplingNearest2d(scale_factor=pool_size))\n",
        "        # Down channel size\n",
        "        layer.append(nn.Conv2d(in_c, out_c, kernel_size, stride, padding=1))\n",
        "        layer.append(nn.BatchNorm2d(out_c))\n",
        "        layer.append(nn.ReLU(inplace=True))\n",
        "        return nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.enc1(x)\n",
        "        x2 = self.enc2(x1)\n",
        "        x3 = self.enc3(x2)\n",
        "        x4 = self.enc4(x3) # (b, 256, 4, 4)\n",
        "\n",
        "        out = self.dec1(x4)\n",
        "        out = self.dec2(torch.cat((out, x3), dim=1)) # concat channel\n",
        "        out = self.dec3(torch.cat((out, x2), dim=1))\n",
        "        out = self.dec4(torch.cat((out, x1), dim=1)) # (b, 3, 64, 64)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg-ocUqla7W1"
      },
      "source": [
        "#### Discriminator: patchGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMDhlZ-ka9Ez"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer1 = self.conv2relu(6, 16, 5, cnt=1)\n",
        "        self.layer2 = self.conv2relu(16, 32, pool_size=4)\n",
        "        self.layer3 = self.conv2relu(32, 64, pool_size=2)\n",
        "        self.layer4 = self.conv2relu(64, 128, pool_size=2)\n",
        "        self.layer5 = self.conv2relu(128, 256, pool_size=2)\n",
        "        self.layer6 = nn.Conv2d(256, 1, kernel_size=1)\n",
        "\n",
        "    def conv2relu(self, in_c, out_c, kernel_size=3, pool_size=None, cnt=2):\n",
        "        layer = []\n",
        "        for i in range(cnt):\n",
        "            if i == 0 and pool_size != None:\n",
        "                # Down width and height\n",
        "                layer.append(nn.AvgPool2d(pool_size))\n",
        "            # Down channel size\n",
        "            layer.append(nn.Conv2d(in_c if i == 0 else out_c,\n",
        "                                   out_c,\n",
        "                                   kernel_size,\n",
        "                                   padding=(kernel_size-1)//2))\n",
        "            layer.append(nn.BatchNorm2d(out_c))\n",
        "            layer.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, x, x1):\n",
        "        x = torch.cat((x, x1), dim=1)\n",
        "        out = self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x)))))\n",
        "        return self.layer6(out) # (b, 1, 2, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo5EXTJGa9iq"
      },
      "source": [
        "#### Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP8uD9rCa-sK"
      },
      "outputs": [],
      "source": [
        "def train_fn(train_dl, G, D, criterion_bce, criterion_mae, optimizer_g, optimizer_d):\n",
        "    G.train()\n",
        "    D.train()\n",
        "    LAMBDA = 100.0\n",
        "    total_loss_g, total_loss_d = [], []\n",
        "    for i, (input_img, real_img) in enumerate(tqdm(train_dl)):\n",
        "        input_img = input_img.to(device)\n",
        "        real_img = real_img.to(device)\n",
        "\n",
        "        real_label = torch.ones(input_img.size()[0], 1, 2, 2)\n",
        "        fake_label = torch.zeros(input_img.size()[0], 1, 2, 2)\n",
        "        real_label = real_label.to(device)\n",
        "        fake_label = fake_label.to(device)\n",
        "        #Generate\n",
        "        fake_img = G(input_img)\n",
        "        fake_img_ = fake_img.detach() # commonly using\n",
        "        out_fake = D(fake_img, input_img)\n",
        "        loss_g_bce = criterion_bce(out_fake, real_label) # binaryCrossEntropy\n",
        "        loss_g_mae = criterion_mae(fake_img, real_img) # MSELoss\n",
        "        loss_g = loss_g_bce + LAMBDA * loss_g_mae\n",
        "        total_loss_g.append(loss_g.item())\n",
        "\n",
        "        optimizer_g.zero_grad()\n",
        "        optimizer_d.zero_grad()\n",
        "        loss_g.backward(retain_graph=True)\n",
        "        optimizer_g.step()\n",
        "        # Discriminator\n",
        "        out_real = D(real_img, input_img)\n",
        "        loss_d_real = criterion_bce(out_real, real_label)\n",
        "        out_fake = D(fake_img_, input_img)\n",
        "        loss_d_fake = criterion_bce(out_fake, fake_label)\n",
        "        loss_d = loss_d_real + loss_d_fake\n",
        "        total_loss_d.append(loss_d.item())\n",
        "\n",
        "        optimizer_g.zero_grad()\n",
        "        optimizer_d.zero_grad()\n",
        "        loss_d.backward()\n",
        "        optimizer_d.step()\n",
        "    return mean(total_loss_g), mean(total_loss_d), fake_img.detach().cpu()\n",
        "\n",
        "\n",
        "def saving_img(fake_img, e):\n",
        "    os.makedirs(\"generated\", exist_ok=True)\n",
        "    save_image(fake_img, \"/content/drive/MyDrive/style_transfer/cGAN/fake\"+str(e)+\".png\", normalize=True)\n",
        "\n",
        "def saving_logs(result):\n",
        "    with open(\"train.pkl\", \"wb\") as f:\n",
        "        pickle.dump([result], f)\n",
        "\n",
        "def saving_model(D, G, e):\n",
        "    os.makedirs(\"weight\", exist_ok=True)\n",
        "    torch.save(G.state_dict(), f\"weight/G{str(e+1)}.pth\")\n",
        "    torch.save(D.state_dict(), f\"weight/D{str(e+1)}.pth\")\n",
        "\n",
        "def show_losses(g, d):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
        "    ax = axes.ravel()\n",
        "    ax[0].plot(np.arange(len(g)).tolist(), g)\n",
        "    ax[0].set_title(\"Generator Loss\")\n",
        "    ax[1].plot(np.arange(len(d)).tolist(), d)\n",
        "    ax[1].set_title(\"Discriminator Loss\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_loop(train_dl, G, D, num_epoch, lr=0.0002, betas=(0.5, 0.999)):\n",
        "    optimizer_g = torch.optim.Adam(G.parameters(), lr=lr, betas=betas)\n",
        "    optimizer_d = torch.optim.Adam(D.parameters(), lr=lr, betas=betas)\n",
        "    criterion_mae = nn.L1Loss().to(device)\n",
        "    criterion_bce = nn.BCEWithLogitsLoss().to(device)\n",
        "    total_loss_d, total_loss_g = [], []\n",
        "    result = {}\n",
        "\n",
        "    for e in range(num_epoch):\n",
        "        loss_g, loss_d, fake_img = train_fn(train_dl, G, D, criterion_bce, criterion_mae, optimizer_g, optimizer_d)\n",
        "        total_loss_d.append(loss_d)\n",
        "        total_loss_g.append(loss_g)\n",
        "        saving_img(fake_img, e+1)\n",
        "\n",
        "        if e%10 == 0:\n",
        "            saving_model(D, G, e)\n",
        "    try:\n",
        "        result[\"G\"] = total_loss_d\n",
        "        result[\"D\"] = total_loss_g\n",
        "        saving_logs(result)\n",
        "        show_losses(total_loss_g, total_loss_d)\n",
        "        saving_model(D, G, e)\n",
        "        print(\"successfully save model\")\n",
        "    finally:\n",
        "        return G, D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI0BHYFSa-30"
      },
      "source": [
        "#### Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9vcwWKbBa_6Y",
        "outputId": "4d916296-bd7d-46d8-de2b-194fa0fdf47d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.13it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.37it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.37it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.37it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.38it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.14it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.17it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.17it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.38it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.17it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "100%|██████████| 30/30 [00:09<00:00,  3.16it/s]\n",
            " 60%|██████    | 18/30 [00:05<00:03,  3.11it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-35d7870fef9e>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mEPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrained_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-e8fd7e11fded>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(train_dl, G, D, num_epoch, lr, betas)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mloss_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_bce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_mae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mtotal_loss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mtotal_loss_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-e8fd7e11fded>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_dl, G, D, criterion_bce, criterion_mae, optimizer_g, optimizer_d)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mLAMBDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtotal_loss_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_img\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mreal_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-da28b14fcbff>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#Read the next x frames here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmovie_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mgame_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmovie_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgame_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#PUT ONTO CUDA!!\n",
        "\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "EPOCH = 1000\n",
        "trained_G, trained_D = train_loop(trainloader, G, D, EPOCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7RyPG4vMIb2H",
        "outputId": "f6b0ebee-ec47-4989-a6a0-e25b84b10e36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 1/8 [00:00<00:02,  2.83it/s]WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 2/8 [00:00<00:02,  2.74it/s]WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 3/8 [00:01<00:01,  2.77it/s]WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 4/8 [00:01<00:01,  2.79it/s]WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 5/8 [00:01<00:01,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 6/8 [00:02<00:01,  1.87it/s]WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 7/8 [00:03<00:00,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:03<00:00,  2.46it/s]\n"
          ]
        }
      ],
      "source": [
        "def load_model(name):\n",
        "    G = Generator()\n",
        "    G.load_state_dict(torch.load(f\"weight/G{name}.pth\", map_location={\"cuda:0\": \"cpu\"}))\n",
        "    G.eval()\n",
        "    return G.to(device)\n",
        "\n",
        "#Run on test data!!!\n",
        "def evaluate(val_dl, name, G):\n",
        "    with torch.no_grad():\n",
        "        for input_img, real_img in tqdm(val_dl):\n",
        "            input_img = input_img.to(device)\n",
        "            real_img = real_img.to(device)\n",
        "\n",
        "            fake_img = G(input_img)[0].detach().cpu().numpy()\n",
        "            fake_img = np.transpose(fake_img, (2,1,0))\n",
        "            print(fake_img.shape)\n",
        "            show(fake_img)\n",
        "\n",
        "\n",
        "def show(imgs):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
        "    for i, img in enumerate(imgs):\n",
        "        axs[0, i].imshow(img)\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    plt.show()\n",
        "\n",
        "G=load_model(\"651\")\n",
        "evaluate(testloader,\"na\",G)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bWahx1jsKJyK",
        "NV8CunPyKTfD",
        "0bL2jVbdKQah",
        "QdE9BbWRcrBb",
        "dryRpdUccuhl"
      ],
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
